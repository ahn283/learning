{"cells":[{"cell_type":"markdown","metadata":{"id":"BOHdL-wnSnaZ"},"source":["# Prompt Engineering 파트 실습 1 - 기초 편\n","\n","Prompt Engineering 관련 아래 기본기들을 익힐 예정\n","- 기본 용어 정리\n","  - Prompt, Role, Response\n","- ChatGPT 간단한 원리\n","  - LLM Next Token Prediction\n","- OpenAI API 호출 방법\n","  - Model, Prompt Text, Temperature\n","  - Max Length\n","- 몇 가지 기본 규칙들\n","\n","*Prompt Engineering 실습 파트는 OpenAI, Anthropic Cookbook, 관련 논문들 및 컨퍼런스 등의 다양한 정보들을 취합한 내용과 강사의 경험을 토대로 진행\n","\n","**실습 비용은 프롬프트 엔지니어링 파트 통틀어서 1000원 미만으로 나올 예정"]},{"cell_type":"markdown","metadata":{"id":"ievIxOsWSsrd"},"source":["## 기본 용어 정리\n","\n","- Prompt: ChatGPT의 출력을 원하는 방향으로 유도하기 위한 입력 텍스트. Prompt는 보통 질문 또는 지시 형태를 나타냄\n","\n","| Role | Prompt |\n","| --- | --- |\n","| User | 왜 하늘은 하늘색인가요? |\n","\n","- Role: 역할. 크게는 (1) 사용자를 뜻하는 User (2) ChatGPT를 뜻하는 Assistant 그리고 (3) System이 존재\n","  - System은 사용자 Prompt 이전에 입력하는 성능 개선 용도의 Prompt\n","\n","| Role | Prompt |\n","| --- | --- |\n","| Assistant | 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 흡수하고 산란시키기 때문입니다. 태양으로부터 오는 빛은 다양한 색상을 가지고 있는데, 대기 중의 분자들은 파란색 빛을 더 많이 흡수하고 산란시키기 때문에 하늘은 파란색으로 보이게 됩니다. 이러한 현상을 레이리 산란이라고 합니다. 따라서 하늘은 하늘색으로 보이는 것입니다. |\n","\n","- Response (또는 Output): 사용자의 Prompt에 대한 LLM의 출력값"]},{"cell_type":"markdown","metadata":{"id":"h8V-z7WASwd6"},"source":["## 간단한 원리 설명 - ChatGPT가 말을 하는 방식에 대하여\n","\n","- Next Token Prediction\n","- ChatGPT 같은 Large Language Model(LLM) 또는 대규모 언어 모델들은 기본적으로 정해진 수의 단어들을 알고 있습니다.\n","  - 예를 들어 메타의 라마2 7B는 32000개, 구글의 젬마 7B는 256000개를 알고 있습니다. (단어를 더 많이 안다고 성능이 좋아지는 것은 아닙니다)\n","- ChatGPT가 예를 들어 10만개의 단어를 알고 있다고 했을 때, 10만개 단어 중 다음 1개의 단어를 예측하는 방식입니다.\n","  - 예시 1. 왜 하늘은 하늘색인가요? ___\n","  - 예시 2. 왜 하늘은 하늘색인가요? 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 ___\n","- \"단어\"란 우리가 생각하는 단어는 아닙니다. ChatGPT는 한글이나 영어 문자를 바로 보는게 아니고 이걸 AI모델이 이해 할 수 있는 숫자들로 변환해야하는데 이 숫자들의 수입니다.\n","  - 공식 명칭은 tokens라고 합니다. platform.openai.com/tokenizer 웹사이트에서 tokenizer 기억 나시죠?"]},{"cell_type":"markdown","metadata":{"id":"P8eN4tv3kT7w"},"source":["## Google Colab에 OpenAI API Key 등록\n","- 왼쪽 열쇠 모양 버튼 클릭 (보안 비밀 / Secrets 메뉴)\n","- 이름에는 OPENAI_API_KEY 입력\n","- 값에는 OpenAI API Key 복붙하기"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2629,"status":"ok","timestamp":1714133970511,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"0f29uLK7ktrn"},"outputs":[],"source":["# from google.colab import userdata\n","\n","# OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","import keyring\n","OPENAI_API_KEY = keyring.get_password('openai', 'key_for_mac')"]},{"cell_type":"markdown","metadata":{"id":"C1FWiaLWi5Ui"},"source":["## OpenAI API 호출 방법\n","- OpenAI API 호출 방법이지만 다른 많은 LLM API들도 OpenAI API 형식을 동일하게 따르거나 비슷한 방식의 구조를 채택했습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9612,"status":"ok","timestamp":1714134001770,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"fJxivabOmGc3","outputId":"504fc834-3d8f-4af9-afd1-c731060a3e43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.6\n"]}],"source":["# !pip install openai"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":303,"status":"ok","timestamp":1714134036768,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"brWiz-KGSyqd"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI(\n","    api_key=OPENAI_API_KEY\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4432,"status":"ok","timestamp":1714134265274,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"xv34Hi7wS0Qz","outputId":"b8cdb86c-b77a-4d30-9ea1-01cd29d16c75"},"outputs":[{"name":"stdout","output_type":"stream","text":["하늘은 하늘색인 이유는 대기 중의 분자들이 햇빛을 흡수하고 산란시키는 과정 때문입니다. 태양으로부터 오는 햇빛은 다양한 파장을 가지고 있는데, 대기 중의 분자들은 이 햇빛을 흡수하고 다시 방출하면서 파장이 긴 파장인 파란색과 보라색을 제외한 파장들이 산란되어 우리 눈에는 파란색으로 보이게 됩니다. 이러한 이유로 하늘은 하늘색으로 보이게 되는 것입니다.\n"]}],"source":["completion = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[{'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"WcGwqKOlS7R9"},"source":["### 한 개씩 살펴보기\n","- model: GPT 3.5, GPT-4 버전 별로 선택하실 수 있으며, 보통 더 좋은 성능의 모델일 수록 가격도 그만큼 비싼 편입니다.\n","- messages: Prompt, Role, Response/Output\n","- temperature: 높을 수록 동일한 Prompt에도 매번 다르게 이야기하는 경향이 강해집니다. 0.0으로 셋팅 시 같은 답변으로만 대답합니다.\n"]},{"cell_type":"markdown","metadata":{"id":"HeWKS0Edh8-0"},"source":["### OpenAI API 결과 조금 더 자세히 살펴보기"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1714135237088,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"CjY3LKnQiVMX","outputId":"5e785e22-f5f1-459d-f122-eec7b7ed00be"},"outputs":[{"data":{"text/plain":["ChatCompletion(id='chatcmpl-9pmDiDHOswSelPu0xdcwr6OB87KS7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='하늘은 하늘색인 이유는 대기 중의 분자들이 햇빛을 흡수하고 산란시키는 과정 때문입니다. 태양으로부터 오는 햇빛은 다양한 파장을 가지고 있는데, 대기 중의 분자들은 이 햇빛을 흡수하고 다시 방출하면서 파장이 긴 파장인 파란색과 보라색을 제외한 파장들이 산란되어 우리 눈에는 파란색으로 보이게 됩니다. 이러한 이유로 하늘은 하늘색으로 보이게 되는 것입니다.', role='assistant', function_call=None, tool_calls=None))], created=1722127114, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=186, prompt_tokens=21, total_tokens=207))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["completion"]},{"cell_type":"markdown","metadata":{"id":"ZQcFKE_EiWrI"},"source":["### 호출 시 지정하진 않지만 알아야 하는 내용\n","- max length / context window\n","  - 모델마다 입력 및 출력 최대 길이가 다르며, 보통 각 모델 소개 페이지에서 찾을 수 있습니다.\n","  - OpenAI API의 경우 입력 최대 길이 확인: https://platform.openai.com/tokenizer\n","    - 모델 별로 tokenizer는 다릅니다. \"왜 하늘은 하늘색인가요?\" 문장이 어떤 모델한테는 14토큰, 어떤 모델은 29토큰 일 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"yOedQZ_rigVE"},"source":["### 기본적인 Prompt 구조\n","\n","Prompt에는 2가지 종류가 존재\n","1. 사용자가 ChatGPT한테 실제로 전달하는 Prompt = User Prompt\n","2. 사용자 Prompt 이전에 오는 해당 LLM 어플리케이션에 적합한 메타 Prompt = System Prompt\n","\n","System Prompt란?\n","- 사용자 Prompt를 전달하기 전에 관련 맥락이나 지침을 설정하는 Prompt\n","  - 페르소나, 어조 등도 설정 할 수 있음\n","- System Prompt 예시\n","  - 출력값 지정 (ex. JSON Formatting)\n","  - 페르소나 및 어조 설정\n","  - 외부 정보 주입\n","  - 모델이 지켜야 할 규칙들 설정\n","\n","왠만한 모델들은 Prompt 입력 시 기본 System Prompt가 붙어있습니다. ChatGPT도 그렇습니다!"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5904,"status":"ok","timestamp":1714135806551,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"RPkXvVQIijn_","outputId":"48a0a38d-a86c-4a96-d87c-6976baa47842"},"outputs":[{"name":"stdout","output_type":"stream","text":["하늘은 왜 하늘색일까요? 그 이유는 바로 '태양빛' 때문이에요! 태양은 빛을 내뿜는데, 그 빛은 다양한 색깔을 가지고 있어요. 하지만 그 중에서도 하늘에는 파란색 빛이 가장 많이 닿아요. 이 파란색 빛은 다른 색깔보다 더 많은 에너지를 가지고 있어서 하늘에 반사되는 빛 중에서 파란색이 가장 많이 보이게 되는거죠! 그래서 우리 눈에는 하늘이 파란색으로 보이는 거에요. 신기하죠?\n"]}],"source":["completion = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[\n","        {'role': 'system', 'content': '당신은 물리학 선생님입니다. 초등학교 5학년한테 설명하듯이 아주 쉽고 친근하게 설명해주세요.'},\n","        {'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}\n","    ],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8265,"status":"ok","timestamp":1714135874256,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"pxrRAZGgiktj","outputId":"e4b24ec0-3fb9-406a-b771-a99d6154e76a"},"outputs":[{"name":"stdout","output_type":"stream","text":["하늘은 왜 하늘색인지 궁금하시죠? 그 이유는 바로 태양빛 때문이에요! 태양은 빛을 내뿜는데, 그 빛은 다양한 색깔을 가지고 있어요. 하지만 그 중에서도 하늘에는 파란색 빛이 많이 들어와요. 이 파란색 빛은 더 많은 공기 분자들과 부딪히기 때문에 하늘에 더 많이 퍼져요. 그래서 우리 눈에는 하늘이 파란색으로 보이는 거죠! 이렇게 하늘이 파란색인 이유를 알았다면, 하늘을 보면서 더 행복해질 수 있겠죠? 함께 하늘을 보며 즐거운 시간 보내세요!\n"]}],"source":["completion = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[\n","        {'role': 'user', 'content': '당신은 물리학 선생님입니다. 초등학교 5학년한테 설명하듯이 아주 쉽고 친근하게 설명해주세요. 왜 하늘은 하늘색인가요?'}\n","    ],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"QiyzTtEaio-U"},"source":["### Completion 말고 Stream도 살펴보기\n","- ChatGPT가 문장을 모두 완성하지 않고 각 단어 별로 완성되는데로 바로바로 보여주는 방법입니다."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4026,"status":"ok","timestamp":1714136032685,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"8z_JhYKCipim","outputId":"b1aad268-f0af-4038-d172-f96840b053aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["하늘은 하늘색인 이유는 대기 중의 분자들이 햇빛을 흡수하고 산란시키기 때문입니다. 태양으로부터 오는 햇빛은 다양한 파장을 가지고 있는데, 대기 중의 분자들은 이 햇빛을 흡수하고 다시 방출하면서 파장이 긴 파장인 파란색과 보라색을 제외한 파장들이 산란되어 우리 눈에는 파란색으로 보이게 됩니다. 이러한 현상으로 인해 하늘은 파란색으로 보이게 되는 것입니다."]}],"source":["stream = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[{'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}],\n","    temperature=0.0,\n","    stream=True\n",")\n","\n","for chunk in stream:\n","  if chunk.choices[0].delta.content is not None:\n","    print(chunk.choices[0].delta.content, end='')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714136039814,"user":{"displayName":"Marko","userId":"13892425088441002710"},"user_tz":-540},"id":"m7SLMA1Viqem","outputId":"7aba0ed2-697b-4b5d-be4a-ed33cabba219"},"outputs":[{"data":{"text/plain":["<openai.Stream at 0x1094a6090>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["stream"]},{"cell_type":"markdown","metadata":{"id":"eBixBk2sitNu"},"source":["### 몇 가지 기본 규칙들\n","\n","1. Prompt는 영어로 해야 모델의 제성능을 발휘하는 편\n","   - ChatGPT, Claude 같은 모델들의 학습 데이터 중 큰 비중이 영어로 추정되기 때문\n","   - 학습 데이터가 공개된 라마1의 경우에도 대부분이 영어이며 한글은 극소량만 존재함\n","   - 한글 출력값이 필요하더라도 영어 Prompt를 통해 한글 출력값을 유도하는게 성능이 더 좋을 수 있음\n","2. AI 모델의 출력값은 입력값에 의존도가 매우 높음\n","   - 잘 한 것 같은데 원하는 결과가 안 나오면 입력이 모호하거나 필요한 내용이 빠졌을 수도 있음 (그게 아닌 경우 모델한테 태스크가 너무 어려울 수는 있음)\n","3. Prompt를 이렇게 저렇게 바꿨을 때 \"더 좋아보이는\" 결과보다는 특정 지표에서 유의미하게 더 좋거나 여러 번의 블라인드 테스팅을 통해 더 좋은 Prompt를 정하는 것을 추천\n","   - 다음 챕터인 프롬프트 엔지니어링 라이프사이클에서 자세하게 알려드릴 예정"]},{"cell_type":"markdown","metadata":{"id":"OHN8jbJWiu0V"},"source":["## 정리\n","- Prompt, Role, Output\n","  - Role은 User, Assistant(ex. ChatGPT)\n","  - Prompt는 User, System Prompt\n","- ChatGPT 작동 원리 = Next Token Prediction\n","  - ChatGPT 같은 모든 LLM API는 단어1, 단어2, 단어3이 있을 때 단어3 뒤에 나올 가장 적합한 단어를 선택하는 식으로 출력\n","- OpenAI API 호출 시 model과 messages를 지정해줘야 하며 결과 재현을 위해서는 temperature=0.0 지정을 추천\n","  - 전체 결과값을 한꺼번에 받는 Completions, 실시간으로 바로바로 받을 수 있는 Stream으로 나뉨"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a84WESkhiwnw"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPnRlACkFlhHR4vHynyOum5","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
