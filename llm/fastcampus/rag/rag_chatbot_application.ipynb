{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st      # !pip install streamlit    # for an app in this browser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from decouple import config\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "import os\n",
    "import keyring\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['chat_history', 'question'],\n",
    "    template=\"\"\" \n",
    "You are a AI assistant. You are currently having a conversation with a human. Answer the questions.\n",
    "\n",
    "chat_history: {chat_history},\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "                api_key=OPENAI_API_KEY, \n",
    "                temperature=0, \n",
    "                model='gpt-4-0314'\n",
    "                )\n",
    "\n",
    "# 윈도우 크기 K를 지정하면 최근 K개의 대화만 기억하고 이전 대화는 삭제\n",
    "memory = ConversationBufferWindowMemory(memory_key='chat_history', k=4)     # k개 대화만 기억\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "st.title(\"ChatGPT AI Assistant\")\n",
    "\n",
    "# 세션에서 메시지를 확인하고 존재하지 않는 경우 생성\n",
    "if \"messages\" not in st.session_state.keys():\n",
    "    st.session_state.messages = [\n",
    "        {'role': 'assistant', 'content': '안녕하세요, 저는 AI Assistant입니다.'}\n",
    "    ]\n",
    "\n",
    "# 모든 메시지 표시\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message['role']):\n",
    "        st.write(message['content'])\n",
    "\n",
    "user_prompt = st.chat_input()\n",
    "\n",
    "# 사용자 입력 보여주기\n",
    "if user_prompt is not None:\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})      # append를 통해 대화 내용 계속 축적\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_prompt)\n",
    "\n",
    "# 마지막 메시지가 assistant로부터 받은게 아니라면 새로운 답변 생성\n",
    "if st.session_state.messages[-1]['role'] != 'assistant':        # 가장 최신 message가 누구인지 확인 -> assistant가 아니면 답변 진행\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Loading...\"):\n",
    "            ai_response = llm_chain.predict(question=user_prompt)\n",
    "    new_ai_message = {\"role\": \"assistant\", \"content\": ai_response}\n",
    "    st.session_state.messages.append(new_ai_message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
