{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Huggingface model \n",
    "\n",
    "https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\assistant\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\woojin\\anaconda3\\envs\\assistant\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\woojin\\.cache\\huggingface\\hub\\models--MLP-KTLim--llama-3-Korean-Bllossom-8B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████| 4/4 [05:27<00:00, 81.98s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "c:\\Users\\woojin\\anaconda3\\envs\\assistant\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 서울은 다양한 문화와 역사, 현대적인 건축물들이 조화를 이루는 도시로, 다양한 관광 코스가 많습니다. 여기 몇 가지 추천하는 서울의 유명한 관광 코스를 소개합니다.\n",
      "\n",
      "### 코스 1: 역사와 문화 탐방\n",
      "\n",
      "1. **경복궁**\n",
      "   - **경복궁**: 조선 왕조의 중심지였던 경복궁은 서울의 가장 유명한 궁궐 중 하나입니다. 특히, 경복궁 내에 있는 국립고궁박물관과 옹의를 방문해 조선 시대의 궁궐 생활을 체험해보세요.\n",
      "\n",
      "2. **창덕궁**\n",
      "   - **창덕궁**: 경복궁과 함께 조선 왕조의 두 번째 궁궐입니다. 창덕궁 내에 있는 인현왕후궁과 창덕궁 안향전, 그리고 동화문 등을 방문해 조선 시대의 궁궐 건축과 미술을 감상하세요.\n",
      "\n",
      "3. **북촌 한옥마을**\n",
      "   - **북촌 한옥마을**: 전통 한옥이 잘 보존된 마을로, 조선 시대의 생활상을 느낄 수 있습니다. 다양한 전통 한옥을 둘러보며, 전통 음식과 음료를 즐길 수 있습니다.\n",
      "\n",
      "### 코스 2: 현대와 자연 탐방\n",
      "\n",
      "1. **남산 서울타워 (남산 서울타워 버스)\n",
      "   - **남산 서울타워**: 서울의 대표적인 랜드마크로, 서울의 전경을 한눈에 내려다볼 수 있는 전망대입니다. 버스를 타고 올라가거나, 산책로를 따라 걸어 올라가도 좋습니다.\n",
      "\n",
      "2. **한강공원**\n",
      "   - **한강공원**: 서울의 중심부를 따라 흐르는 한강변에 위치한 공원입니다. 걷기, 자전거 타기, 배타기 등 다양한 활동을 즐길 수 있습니다. 특히, 일몰 때는 한강의 아름다운 일몰을 감상할 수 있습니다.\n",
      "\n",
      "3. **동대문**\n",
      "   - **동대문**: 서울의 대표적인 쇼핑 거리로, 다양한 브랜드 매장과 전통 시장, 그리고 현대적인 쇼핑몰이 혼합된 곳입니다. 특히, 동대문 디자인 플라자(DDP)는 건축적인 아름다움으로 유명합니다.\n",
      "\n",
      "### 코스 3: 먹거리와 문화 탐방\n",
      "\n",
      "1. **명동**\n",
      "   - **명동**: 서울의 대표적인 쇼핑 거리로, 다양한 브랜드 매장과 전통 음식점이 모여 있습니다. 명동의 거리 음식과 전통 가게를 둘러보며, 다양한 먹거리를 즐길 수 있습니다.\n",
      "\n",
      "2. **홍대**\n",
      "   - **홍대**: 젊은 층이 많이 찾는 지역으로, 다양한 카페, 레스토랑, 클럽, 갤러리 등이 모여 있습니다. 특히, 홍대 거리의 스트리트 패션과 아티스트들의 활약을 감상할 수 있습니다.\n",
      "\n",
      "3. **인사동**\n",
      "   - **인사동**: 전통적인 문화와 예술이 풍부한 거리로, 다양한 전통 가게, 갤러리, 찻집이 모여 있습니다. 전통 악기와 전통 한복 등을 구입하거나, 전통 공예품을 감상할 수 있습니다.\n",
      "\n",
      "이러한 코스를 통해 서울의 다양한 면모를 체험해보세요!\n"
     ]
    }
   ],
   "source": [
    "import transformers     # pip install transformers\n",
    "import torch            # using as a data type\n",
    "\n",
    "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "\n",
    "# pipeline 구성\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",      # the purpose of pipeline\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",      # multi-gpu\n",
    ")\n",
    "\n",
    "pipeline.model.eval()\n",
    "\n",
    "PROMPT = '''You are a helpful AI assistant. Please answer the user's questions kindly. 당신은 유능한 AI 어시스턴트 입니다. 사용자의 질문에 대해 친절하게 답변해주세요.'''\n",
    "instruction = \"서울의 유명한 관광 코스를 만들어줄래?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False,         # 메시지를 자르지 않고 입력\n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# 문장의 끝을 확인\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,        # eos : end of sequence\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")      # eot : end of tokens\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,     # 다채로운 단어 선택\n",
    "    temperature=0.6,  \n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
