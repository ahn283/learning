{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatAnthropic, ChatOllama, ChatOpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "import keyring\n",
    "from pykrx import stock     # pip install pykrx\n",
    "from datetime import datetime\n",
    "\n",
    "# api key\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "ANTHROPIC_API_KEY = keyring.get_password('anthropic', 'key_for_windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"기업명\": \"삼성전자\",\n",
    "        \"날짜\": \"2024-03-02\",\n",
    "        \"문서 카테고리\": \"인수합병\",\n",
    "        \"요약\": \"삼성전자가 HVAC(냉난방공조) 사업 인수를 타진 중이며, 이는 기존 가전 사업의 약점 보완을 목적으로 한다.\",\n",
    "        \"주요 이벤트\": [\"기업 인수합병\"]\n",
    "    }, {\n",
    "        \"기업명\": \"삼성전자\",\n",
    "        \"날짜\": \"2024-03-24\",\n",
    "        \"문서 카테고리\": \"인수합병\",\n",
    "        \"요약\": \"테스트 하나 둘 셋\",\n",
    "        \"주요 이벤트\": [\"신제품 출시\"]\n",
    "    }, {\n",
    "        \"기업명\": \"현대차\",\n",
    "        \"날짜\": \"2024-04-02\",\n",
    "        \"문서 카테고리\": \"인수합병\",\n",
    "        \"요약\": \"삼성전자가 HVAC(냉난방공조) 사업 인수를 타진 중이며, 이는 기존 가전 사업의 약점 보완을 목적으로 한다.\",\n",
    "        \"주요 이벤트\": [\"기업 인수합병\", \"신제품 출시\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# data 내에 '요약'만 추출해서 리스트로 반환\n",
    "doc_list = [item['요약'] for item in data]\n",
    "\n",
    "# elastic search based retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    doc_list, metadatas=[{\"source\": i} for i in range(len(data))]\n",
    ")\n",
    "bm25_retriever.k = 1\n",
    "\n",
    "# embedding from openai\n",
    "embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# vector database retriever\n",
    "## FAISS\n",
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    doc_list, embedding=embedding, metadatas=[{'source': i} for i in range(len(data))]\n",
    ")\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(\n",
    "    search_kwargs={'k':1}\n",
    ")\n",
    "## Chroma\n",
    "chroma_vectorstore = Chroma.from_texts(\n",
    "    doc_list, embedding=embedding, metadatas=[{'source': i} for i in range(len(data))]\n",
    ")\n",
    "chroma_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={'k':1}\n",
    ")\n",
    "\n",
    "# ensemble retreiver\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever, chroma_retriever],\n",
    "    weights=[0.2, 0.5, 0.3]\n",
    ")\n",
    "\n",
    "def retrieve(query):\n",
    "    ensemble_docs = ensemble_retriever.invoke(query)\n",
    "    return ensemble_docs\n",
    "    \n",
    "def get_answer(query, model):\n",
    "    if 'gpt' in model:\n",
    "        llm = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        response = llm.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\n",
    "                'role':'system',\n",
    "                'content':'You are a helpful assistant.'\n",
    "            }, {\n",
    "                'role':'user',\n",
    "                'content':query\n",
    "            }]\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "    elif 'claude' in model:\n",
    "        llm = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        response = llm.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=1024,\n",
    "            messages=[\n",
    "                {'role':'user', 'content':query},\n",
    "                {'role':'assistant', 'content':\"Hello!\"},\n",
    "            ]\n",
    "        )\n",
    "        answer = response.content[0].text\n",
    "        \n",
    "    elif 'llama' in model:\n",
    "        llm = ChatOllama(model=model)\n",
    "        response = llm.invoke(query)\n",
    "        answer = response.content\n",
    "        \n",
    "    else:\n",
    "        print(\"Not supported\")\n",
    "        return None\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def prompt_and_generate(query, docs, price, model):\n",
    "    \n",
    "    prompt = f\"\"\"아래 질문을 기반으로 검색된 뉴스를 참고하여 질문에 대한 답변을 생성하시오. 질문과 가장 적절한 뉴스에서 등장한 이벤트까지 출력하세요.\n",
    "    답변 마지막에 오늘의 종가 정보도 포함시켜 답변을 만드시오.\n",
    "    \n",
    "    # 종가 : {price}\n",
    "    \n",
    "    # 질문 : {query}\n",
    "    \n",
    "    # 뉴스\n",
    "    \"\"\"\n",
    "    \n",
    "    # docs가 여러 개인 경우 나눠서 붙임\n",
    "    for i in range(len(docs)):\n",
    "        prompt += f\"뉴스{i+1}\\n\"\n",
    "        prompt += f\"요약: {docs[i].page_content}\\n\"\n",
    "        idx = docs[i].metadata['source']\n",
    "        prompt += f\"카테고리: {data[idx]['문서 카테고리']}\\n\"\n",
    "        prompt += f\"이벤트: {data[idx]['주요 이벤트']}\\n\"\n",
    "        prompt += '\\n'\n",
    "        \n",
    "    print(prompt)\n",
    "    answer = get_answer(prompt, model=model)\n",
    "    return answer\n",
    "\n",
    "# query에서 기업 ticker 추출\n",
    "def first_chain(query, model):\n",
    "    prompt = \"\"\"아래 질문에 기업명이 포함되어 있다면, 기업번호(ticker)를 출력하시오. 반드시 ticker만을 출력하고, 기업명이 포함되어 있지 않은 경우는 0을 출력하시오.\n",
    "    \n",
    "    # 출력 포맷 : {'기업명':'기업번호'}\\n\n",
    "    \"\"\"\n",
    "    prompt += f\"질문: {query}\"\n",
    "    answer = get_answer(prompt, model)\n",
    "    return answer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 질문을 기반으로 검색된 뉴스를 참고하여 질문에 대한 답변을 생성하시오. 질문과 가장 적절한 뉴스에서 등장한 이벤트까지 출력하세요.\n",
      "    답변 마지막에 오늘의 종가 정보도 포함시켜 답변을 만드시오.\n",
      "    \n",
      "    # 종가 : 69000\n",
      "    \n",
      "    # 질문 : 삼성전자가 인수하는 기업은?\n",
      "    \n",
      "    # 뉴스\n",
      "    뉴스1\n",
      "요약: 삼성전자가 HVAC(냉난방공조) 사업 인수를 타진 중이며, 이는 기존 가전 사업의 약점 보완을 목적으로 한다.\n",
      "카테고리: 인수합병\n",
      "이벤트: ['기업 인수합병']\n",
      "\n",
      "뉴스2\n",
      "요약: 테스트 하나 둘 셋\n",
      "카테고리: 인수합병\n",
      "이벤트: ['신제품 출시']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'삼성전자가 인수하는 기업은?\\n \\n삼성전자는 HVAC(냉난방공조) 사업을 인수하기 위한 협상을 진행 중입니다. 이는 기존 가전 사업의 약점을 보완하는 목적을 가지고 있습니다. \\n \\n오늘의 종가 : 69000'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '삼성전자가 인수하는 기업은?'\n",
    "model_first = 'gpt-3.5-turbo'\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "today = '20240905'\n",
    "model_second = 'llama3.1'\n",
    "\n",
    "# 기업 종가 정보 추출\n",
    "companies = first_chain(query, model_first)\n",
    "company_dict = eval(companies)\n",
    "tickers = list(company_dict.values())\n",
    "prices = stock.get_market_ohlcv(today, today, tickers[0])\n",
    "\n",
    "if len(prices) > 0:\n",
    "    # 날짜와 종가 column 가져오기기\n",
    "    price = prices.iloc[0, 3]\n",
    "else:\n",
    "    price = \"unknown\"\n",
    "    \n",
    "retrieved = [doc for doc in retrieve(query)]\n",
    "answer = prompt_and_generate(query, retrieved, price, model_second)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업 종가 정보 통합한 대답 결과\n",
    "\n",
    "def get_answer_final(query, model_first, model_second):\n",
    "    \n",
    "    # 기업명 및 기업번호 추출 후 주식의 종가 획득득\n",
    "    today = datetime.today().strftime('%Y%m%d')\n",
    "    today = '20240905'\n",
    "    companies = first_chain(query, model_first)\n",
    "    company_dict = eval(companies)\n",
    "    tickers = list(company_dict.values())\n",
    "    prices = stock.get_market_ohlcv(today, today, tickers[0])\n",
    "    \n",
    "    if len(prices) > 0:\n",
    "        price = prices.iloc[0, 3]\n",
    "        \n",
    "    else:\n",
    "        price = 'unknown'\n",
    "    \n",
    "    print(price)\n",
    "    \n",
    "    retrieved = [doc for doc in retrieve(query)]\n",
    "    answer = prompt_and_generate(query, retrieved, price, model_second)\n",
    "    return answer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69000\n",
      "아래 질문을 기반으로 검색된 뉴스를 참고하여 질문에 대한 답변을 생성하시오. 질문과 가장 적절한 뉴스에서 등장한 이벤트까지 출력하세요.\n",
      "    답변 마지막에 오늘의 종가 정보도 포함시켜 답변을 만드시오.\n",
      "    \n",
      "    # 종가 : 69000\n",
      "    \n",
      "    # 질문 : 삼성전자가 인수하는 기업은?\n",
      "    \n",
      "    # 뉴스\n",
      "    뉴스1\n",
      "요약: 삼성전자가 HVAC(냉난방공조) 사업 인수를 타진 중이며, 이는 기존 가전 사업의 약점 보완을 목적으로 한다.\n",
      "카테고리: 인수합병\n",
      "이벤트: ['기업 인수합병']\n",
      "\n",
      "뉴스2\n",
      "요약: 테스트 하나 둘 셋\n",
      "카테고리: 인수합병\n",
      "이벤트: ['신제품 출시']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'삼성전자가 인수하는 기업은?\\n\\n뉴스를 검색 결과가 나와 삼성전자 HVAC(냉난방공조) 사업 인수를 타진 중이며, 이는 기존 가전 사업의 약점 보완을 목적으로 한다는 뉴스가 등장합니다. 따라서, 삼성전자의 인수 사례는 기존 가전 사업의 약점을 보완하기 위해 진행하는 것으로 볼 수 있습니다.\\n\\n오늘 종가: 69,000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '삼성전자가 인수하는 기업은?'\n",
    "model_first = 'gpt-3.5-turbo'\n",
    "model_second = 'llama3.1'\n",
    "final_answer = get_answer_final(query, model_first, model_second)\n",
    "final_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
