{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 50개의 평가용 테스트 케이스 확보 예정\n",
    "- 많으면 많을수록 좋지만 평가 비용(돈, 시간 등) 커지는 이슈 존재\n",
    "- 아래 형식의 평가 데이터 리턴하는 함수 제작하는 것이 이번 노트북의 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 50개의 평가용 테스트 케이스 확보 예정\n",
    "## 많으면 많을수록 좋지만 평가 비용(돈, 시간 등) 커지는 이슈 존재\n",
    "## 아래 형식의 평가 데이터 리턴하는 함수 제작하는 것이 이번 노트북의 목표\n",
    "\n",
    "def get_eval_data():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2명의 대화 - 20개\n",
    "# aihub.or.kr\n",
    "\n",
    "conversations = []\n",
    "\n",
    "paths = glob.glob('./res/297.SNS 데이터 고도화/01-1.정식개방데이터/Validation/02.라벨링데이터/VL/*json')\n",
    "target_count = 20\n",
    "count = 0\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        # 하나의 데이터 세션이 하나의 json 파일\n",
    "        conv_dict = json.load(f)\n",
    "        # header에 대화방에 대한 정보, body에 대화 내용 존재\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] == 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                # 대화내용 중복인 경우\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    print('Repeated Conversations')\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                count += 1\n",
    "                if count == target_count:\n",
    "                    break\n",
    "\n",
    "count\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3명 이상의 대화 - 30개\n",
    "\n",
    "target_count = 30\n",
    "count = 0\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] > 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                count += 1\n",
    "                if count == target_count:\n",
    "                    break\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"P02: 안녕하세요 여러분! 오늘 날씨 정말 좋네요~\\nP01: 네 맞아요! 오랜만에 맑은 하늘이에요.\\nP03: 맞아요~ 산책하기 딱 좋은 날씨예요!\\nP02: 그러게요. 요즘 집에만 있어서 답답했는데 좋네요.\\nP01: 저도 그래요. 코로나 때문에 밖에 나가기가 꺼려졌었거든요.\\nP03: 맞아요. 다들 백신 맞으셨나요?\\nP02: 네, 저는 2차까지 다 맞았어요.\\nP01: 저도 2차 맞았어요! 부작용은 없으셨나요?\\nP03: 저는 1차만 맞았는데, 팔이 좀 아팠어요.\\nP02: 저는 괜찮았어요. 그냥 좀 피곤했던 정도?\\nP01: 저도 비슷했어요. 다행히 큰 부작용은 없었네요.\\nP03: 다행이에요. 저도 2차 맞을 때 걱정되네요.\\nP02: 괜찮을 거예요. 사람마다 다르니까요.\\nP01: 그러게요. 그나저나 요즘 뭐하고 지내세요?\\nP03: 저는 요즘 넷플릭스 보면서 시간 보내고 있어요.\\nP02: 오~ 뭐 재밌는 거 있나요?\\nP03: '오징어 게임' 봤어요? 요즘 화제더라고요.\\nP01: 아 저도 봤어요! 정말 재밌더라고요.\\nP02: 저는 아직 못 봤어요. 그렇게 재밌나요?\\nP03: 네, 한번 보세요. 시간 가는 줄 모르고 봤어요.\\nP01: 맞아요. 저도 하루만에 다 봐버렸어요.\\nP02: 와~ 그렇게나요? 저도 한번 봐야겠네요.\\nP03: 그리고 '킹덤'도 추천해요. 한국 좀비물인데 정말 재밌어요.\\nP01: 아 맞아요! '킹덤'도 정말 좋았죠.\\nP02: 오~ 둘 다 한번 봐야겠어요. 요즘 시간도 많이 남고...\\nP03: 네, 한번 보세요. 후회 안 하실 거예요.\\nP01: 그러고 보니 요즘 한국 드라마나 영화가 해외에서도 인기 많더라고요.\\nP02: 맞아요. BTS도 그렇고 정말 대단해요.\\nP03: 맞아요. 우리나라 문화가 세계적으로 인정받는 것 같아 뿌듯해요.\\nP01: 그러게요. 어릴 때는 상상도 못했는데...\\nP02: 네, 정말 놀라운 일이에요. 앞으로가 더 기대되네요.\\nP03: 맞아요. 그나저나 여러분 점심은 드셨나요?\\nP01: 아 맞다! 저는 아직 안 먹었어요.\\nP02: 저도요. 뭐 먹을지 고민 중이에요.\\nP03: 저는 방금 김치찌개 먹었어요. 맛있더라고요.\\nP01: 와~ 김치찌개 좋네요. 저도 그거 먹고 싶어졌어요.\\nP02: 저도요! 김치찌개 어디서 드셨어요?\\nP03: 집 근처 식당에서요. 가격도 괜찮고 맛있어요.\\nP01: 오~ 저도 한번 가봐야겠어요. 위치 좀 알려주세요!\\nP02: 저도요! 맛집 정보 공유 좀 해주세요~\\nP03: 네, 나중에 카톡으로 보내드릴게요.\\nP01: 고마워요! 기대되네요.\\nP02: 네, 감사합니다. 오늘 저녁은 거기서 먹어야겠어요.\\nP03: 그러세요~ 맛있게 드세요!\\nP01: 그나저나 요즘 물가가 많이 올랐더라고요.\\nP02: 맞아요. 장 보러 가면 깜짝 놀라요.\\nP03: 그러게요. 특히 채소 값이 많이 올랐더라고요.\\nP01: 네, 맞아요. 요즘 집에서 요리하는 게 더 비싸질 것 같아요.\\nP02: 그래도 밖에서 사 먹는 것보다는 싸겠죠?\\nP03: 그렇긴 해요. 그래도 가계부 쓰기가 힘들어졌어요.\\nP01: 맞아요. 저도 요즘 지출 관리하기가 힘들더라고요.\\nP02: 다들 어떻게 절약하세요? 팁 좀 알려주세요!\\nP03: 저는 쿠폰이나 할인 이벤트를 많이 활용해요.\\nP01: 오~ 좋은 방법이네요. 저는 대용량으로 사서 나눠 쓰고 있어요.\\nP02: 와~ 다들 현명하시네요. 저도 그렇게 해봐야겠어요.\\nP03: 그리고 불필요한 지출을 줄이는 것도 중요해요.\\nP01: 맞아요. 커피 한 잔이라도 아끼면 큰 도움이 되더라고요.\\nP02: 네, 맞아요. 작은 것부터 시작해야겠어요.\\nP03: 그러다 보면 습관이 될 거예요. 화이팅!\\nP01: 네, 다들 화이팅이에요!\\nP02: 그나저나 요즘 새로 나온 전자기기 소식 들으셨나요?\\nP03: 아, 새로운 스마트폰 말씀하시는 건가요?\\nP01: 아 맞아요! 요즘 제트플립 새로 나와서 난리더라!\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3천자 이상의 대화로 변환\n",
    "\n",
    "# 데이터셋에는 3천자를 넘는 데이터가 단 한개도 존재하지 않음\n",
    "# Anthropic Claude 3.5 sonnet을 사용해서 대화를 주고 앞에 내용을 추측한 내용으로 대화 앞에 붙여서 3천자 이상으로 변환\n",
    "# 변환 prompt 및 코드는 data_long.ipynb \n",
    "\n",
    "with open('./res/conv_long.pickle', 'rb') as f:\n",
    "    conv_long = pickle.load(f)\n",
    "    \n",
    "conv_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations[-2] = '\\n'.join(conv_long) + '\\n' + conversations[-2]\n",
    "\n",
    "with open('./res/eval_data.pickle', 'wb') as f:\n",
    "    pickle.dump(conversations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_data():\n",
    "    with open('./res/eval_data.pickle', 'rb', encoding='UTF-8') as f:\n",
    "        eval_data = pickle.load(f)\n",
    "        \n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 함수를 eval.py에 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
