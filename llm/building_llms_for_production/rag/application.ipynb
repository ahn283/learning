{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai_language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 Google is offering developers access to one of its most advanced AI language models: PaLM. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text generation and editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. (It’s similar to features Google also announced today for its Workspace apps like Google Docs and Gmail.)\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"example_file.text\", \"w\") as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './example_file.text'}, page_content='Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 Google is offering developers access to one of its most advanced AI language models: PaLM. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.”\\n\\nPaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text generation and editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. (It’s similar to features Google also announced today for its Workspace apps like Google Docs and Gmail.)')]\n"
     ]
    }
   ],
   "source": [
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader('./example_file.text')\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(docs_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:23<00:00, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://ahn283/langchain_cource_indexers_retrievers', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f2aacc7f-892f-11ef-b5f0-e0c26439031d',\n",
       " 'f2aacc80-892f-11ef-bbce-e0c26439031d']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keyring\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "ACTIVELOOP_API_KEY = keyring.get_password('activeloop', 'key_for_windows')\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "my_activeloop_org_id = 'ahn283'\n",
    "my_activeloop_dataset_name = 'langchain_cource_indexers_retrievers'\n",
    "data_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=data_path, embedding_function=embeddings, token=ACTIVELOOP_API_KEY)\n",
    "\n",
    "# add documents to our DeepLake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_23016\\3436673030.py:12: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_db.persist()\n"
     ]
    }
   ],
   "source": [
    "# chroma db\n",
    "import keyring\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "\n",
    "embeddings = embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore_path = './vectorstore'\n",
    "chroma_db = Chroma.from_documents(docs, embeddings, persist_directory=vectorstore_path)\n",
    "chroma_db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever from db\n",
    "retriever = db.as_retriever()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_23016\\116210716.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY),\n"
     ]
    }
   ],
   "source": [
    "# create a retrieval chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google plans to challenge OpenAI by offering developers access to its advanced AI language model, PaLM. PaLM is a large language model similar to OpenAI's GPT series and Meta's LLaMA family of models. By providing an API for PaLM and other AI enterprise tools, Google aims to help businesses generate text, images, code, videos, audio, and more from simple natural language prompts. This move allows Google to compete with OpenAI and other companies in the field of AI language models.\n"
     ]
    }
   ],
   "source": [
    "query = \"How Google plans to challenge OpenAI?\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './example_file.text'}, page_content='Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 Google is offering developers access to one of its most advanced AI language models: PaLM. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.”'),\n",
       " Document(metadata={'source': './example_file.text'}, page_content='PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text generation and editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. (It’s similar to features Google also announced today for its Workspace apps like Google Docs and Gmail.)')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chroma db retriever\n",
    "retriever_chroma = chroma_db.as_retriever(\n",
    "    search_kwargs={'k': 3}\n",
    ")\n",
    "docs = retriever_chroma.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google opens up its AI language model PaLM to challenge OpenAI\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# create GPT3 wrapper\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# create compressor for the retriever\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ")\n",
    "\n",
    "# retrieving compressed documents\n",
    "retrieved_docs = compression_retriever.get_relevant_documents(\n",
    "    \"How goolge plant to challenge OpenAI?\"\n",
    ")\n",
    "\n",
    "print(retrieved_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
