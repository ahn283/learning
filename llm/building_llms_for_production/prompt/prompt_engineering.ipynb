{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import keyring\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embark on a quest to find the mythical cheese of legends. He knew it was a dangerous journey, but his determination never wavered.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
    "\n",
    "prompt = \"\"\"Continue the following story. Write no more than 40 words.\n",
    "Once upon a time, in a world where animal could speak, a courageous mouse named Benjamin decided to\"\"\"\n",
    "\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":prompt_system},\n",
    "        {\"role\":\"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indulge in the exquisite craftsmanship of our limited-edition fountain pen, meticulously handcrafted from rich rosewood and decadent gold. Elevate your writing experience with this luxurious instrument that combines elegance and sophistication, perfect for discerning connoisseurs of fine stationery.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt_system = \"\"\"You are a helpful assistant whose goal is to help write product descriptions.\"\"\"\n",
    "prompt = \"\"\"Write a captivating product description for a luxurious, handcrafted, limited-edition fountain pen made from rosewood and gold.\n",
    "Write no more than 50 words\"\"\"\n",
    "\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":prompt_system},\n",
    "        {\"role\":\"user\", \"content\":prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden sun and skies so clear,\n",
      "Summer's warmth is drawing near.\n",
      "Birds are singing, flowers bloom,\n",
      "Nature's beauty fills the room.\n",
      "\n",
      "Lazy days and endless nights,\n",
      "Joyful laughter and fun delights.\n",
      "Beaches, picnics, and ice cream treats,\n",
      "Warm embraces and bare feet.\n",
      "\n",
      "Summer's magic in the air,\n",
      "Moments cherished, memories rare.\n",
      "Let the sunshine kiss your skin,\n",
      "Embrace the season from within.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
    "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
    "\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":prompt_system},\n",
    "        {\"role\":\"user\", \"content\":prompt.format(topic=\"summer\")}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In-Context learning and Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden sunbeams dance,\n",
      "Laughter in the warm breeze,\n",
      "Summer's joy enhance.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt_system = \"You are a helpful assistant whose goal is to write short porms.\"\n",
    "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
    "\n",
    "examples = {\n",
    "    \"nature\": \"\"\"Birdsong fills the air,\\nMountains high and valleys deep,\\nNature's music sweet.\"\"\",\n",
    "    \"winter\": \"\"\"Snow blankets the ground,\\nSilence is the only sound,\\nWinter's beauty found.\"\"\"\n",
    "}\n",
    "\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":prompt_system},\n",
    "        {\"role\":\"user\", \"content\":prompt.format(topic=\"nature\")},\n",
    "        {\"role\":\"assistant\", \"content\":examples[\"nature\"]},\n",
    "        {\"role\":\"user\", \"content\":prompt.format(topic=\"winter\")},\n",
    "        {\"role\":\"assistant\", \"content\":examples[\"winter\"]},\n",
    "        {\"role\":\"user\", \"content\":prompt.format(topic=\"summer\")}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color:purple\n",
      "Emotion: royalty\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "examples = [\n",
    "    {\"color\":\"red\", \"emotion\":\"passion\"},\n",
    "    {\"color\":\"blue\", \"emotion\":\"serenity\"},\n",
    "    {\"color\":\"green\", \"emotion\":\"tranquility\"}\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color:{color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"color\", \"emotion\"],\n",
    "    template=example_formatter_template\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix = \"\"\"Here are some examples of colors and the emotions associated with them:\\n\\n\"\"\",\n",
    "    suffix = \"\"\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor:{input}\\nEmotion:\"\"\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# create the LLM for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "# run the LLMChain to get the AI-generated emotion associated with the input\n",
    "# color\n",
    "response = chain.run({})\n",
    "print(\"Color:purple\")\n",
    "print(\"Emotion:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Role Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \"Galactic Odyssey: Journey Through the Stars in 3030\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# initialize LLM\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "template = \"\"\" \n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# inpout data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# run the LLMChain to get the AI-generated song title\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"These: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein's theory of general relativity is a theory of gravitation that describes the force of gravity as a curvature of spacetime caused by mass and energy. According to this theory, massive objects like planets and stars warp the fabric of spacetime, causing other objects to move along curved paths. General relativity also predicts phenomena such as gravitational time dilation, gravitational waves, and the bending of light around massive objects.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# initalize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer:\"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer:\"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# run the LLMChain for the first prmompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Prompt Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about dogs.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me something about {topic}.\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['topic'],\n",
    "    template=template\n",
    ")\n",
    "prompt.format(topic='dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein's theory of general relativity is a theory of gravitation that describes the force of gravity as a curvature of spacetime caused by mass and energy. According to this theory, massive objects like planets and stars warp the fabric of spacetime, causing other objects to move along curved paths. General relativity also predicts phenomena such as gravitational time dilation, gravitational waves, and the bending of light around massive objects.\n"
     ]
    }
   ],
   "source": [
    "# prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer:\"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# promtp 2\n",
    "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
    "Answer:\"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=['scientist'], template=template_fact)\n",
    "\n",
    "# create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# run the LLMChain for the first prompt with an empty dictionay\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# extract the scientist's nam from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# cretate the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# run the LLMChain for the second prompt\n",
    "response_dact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: Jazz is known for its improvisational nature, pop music is characterized by catchy melodies and hooks, and rock music is often associated with electric guitars and high energy performances.\n"
     ]
    }
   ],
   "source": [
    "# prompt 1\n",
    "template_prompt = \"\"\"What are some musical genres?\n",
    "Answer:\"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# prompt 2\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving without any specific details\n",
    "Answer:\"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=['genre1', 'genre2', 'genre3'], template=template_fact)\n",
    "\n",
    "# create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# assign three hardcoded genre\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "\n",
    "# create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\":genre3}\n",
    "\n",
    "# run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips for Effective Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "All Response: Practice active listening, be mindful of your body language, and work on expressing yourself clearly and confidently.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# initialize LLM\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"\"\"Finding balance in life and learning to enjoy the small moments.\"\"\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"\"\"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\"\"\n",
    "    }\n",
    "]\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI life coach.\n",
    "The assistant provides insightful and practical adive to the users' questions. Here are some examples:\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query},\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['query'],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# create the LLMChain for the few-shot prompt temaplte\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"All Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
