{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Inception\" is a 2010 science fiction action film directed by Christopher Nolan. The movie stars Leonardo DiCaprio as a professional thief who steals information by entering the subconscious minds of his targets through their dreams. The film explores the concept of dream sharing and features a complex narrative that blurs the lines between reality and dreams. \"Inception\" received critical acclaim for its originality, visual effects, and performances. It was also a commercial success, grossing over $800 million worldwide.\n"
     ]
    }
   ],
   "source": [
    "import keyring\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "template = \"You are an assistant that helps users find information about movies.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"Find information about the movie {movie_title}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "response = chat(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization Chain Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The One Page Linux Manual provides a summary of useful Linux commands for starting and stopping processes, accessing and mounting file systems, finding files and text within files, using the X Window System, moving, copying, deleting, and viewing files, installing software, user administration, tips and tricks, configuration files, file permissions, X shortcuts, and printing. It also includes information on how to start and stop the print daemon, display print queue jobs, remove jobs from the queue, and print files.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# initialize language model\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Load the summarization chain\n",
    "summarize_chain = load_summarize_chain(llm)\n",
    "\n",
    "# load the document using PyPDFLoader\n",
    "document_loader = PyPDFLoader(file_path='./data/The One Page Linux Manual.pdf')\n",
    "document = document_loader.load()\n",
    "\n",
    "# summarize the document\n",
    "summary = summarize_chain(document)\n",
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Chain Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The meaning of life is a deeply philosophical question that has been debated for centuries. Different people and cultures have different beliefs about the purpose and meaning of life. Some believe that the meaning of life is to seek happiness and fulfillment, others believe it is to serve a higher power or fulfill a specific destiny, while others believe that life has no inherent meaning and it is up to each individual to create their own meaning. Ultimately, the meaning of life is a personal and subjective question that each person must grapple with and find their own answer to.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "chain.run(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a New Articles Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta claims its new AI supercomputer will set records\n",
      "Text: Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
      "\n",
      "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
      "\n",
      "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
      "\n",
      "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
      "\n",
      "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
      "\n",
      "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
      "\n",
      "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
      "\n",
      "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
      "\n",
      "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
      "\n",
      "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
      "\n",
      "(Image Credit: Meta)\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n"
     ]
    }
   ],
   "source": [
    "import keyring\n",
    "import requests\n",
    "from newspaper import Article\n",
    "\n",
    "heades = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "try:\n",
    "    response = session.get(article_urls, headers=heades, timeout=10)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        article = Article(article_urls)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        print(f\"Title: {article.title}\")\n",
    "        print(f\"Text: {article.text}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to fetch article at {article_urls}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while fetching article at {article_urls}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "# we get the article data from the scraping part\n",
    "article_title = article.title\n",
    "article_text = article.text\n",
    "\n",
    "# prepare template for prompt\n",
    "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
    "\n",
    "Here's the article you want to summarize.\n",
    "\n",
    "==========\n",
    "Title: {article_title}\n",
    "\n",
    "{article_text}\n",
    "==========\n",
    "\n",
    "Write a summary of the previous article.\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "messages = [HumanMessage(content=prompt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta (formerly Facebook) has announced the development of the AI Research SuperCluster (RSC), an AI supercomputer that it claims will be the world's fastest upon its completion in mid-2022. The RSC is designed to train large natural language processing (NLP) and computer vision models, with capabilities to handle models with trillions of parameters. Meta aims to use the RSC for advanced AI applications, such as real-time voice translations for large groups and enhancing the metaverse with AI-driven technologies. The RSC is expected to be significantly faster than Meta's current systems, improving training times and incorporating enhanced security and privacy features to utilize real-world data safely. This development marks a significant step in Meta's AI research, focusing on performance, reliability, security, and privacy at a large scale.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import keyring\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = keyring.get_password('openai', 'key_for_windows')\n",
    "# load the model\n",
    "chat = ChatOpenAI(model_name='gpt-4-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# generate summary\n",
    "summary = chat(messages)\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Meta's New AI Supercomputer**: Meta (formerly Facebook) has announced the development of the AI Research SuperCluster (RSC), which it claims will be the world's fastest AI supercomputer upon completion.\n",
      "  \n",
      "- **Current Status and Capabilities**: The RSC is not yet fully built but is expected to be completed by mid-2022. It is already being used by Meta's researchers to train large natural language processing (NLP) and computer vision models.\n",
      "\n",
      "- **Performance Expectations**: Once fully operational, RSC is projected to be 20x faster than Meta’s current V100-based clusters, 9x faster at running the NVIDIA Collective Communication Library (NCCL), and 3x faster at training large-scale NLP workflows.\n",
      "\n",
      "- **Training Efficiency**: A model with tens of billions of parameters can be trained in three weeks on RSC, a significant improvement from the nine weeks required with previous systems.\n",
      "\n",
      "- **Applications and Goals**: Meta aims to use RSC to develop new AI systems for real-time voice translations and other applications that could facilitate collaborative work and entertainment in the metaverse.\n",
      "\n",
      "- **Security and Privacy**: RSC has been designed with enhanced security and privacy controls, allowing Meta to utilize real-world data from its production systems for training purposes.\n",
      "\n",
      "- **Research and Development**: The supercomputer will enable Meta to advance research in critical areas such as identifying harmful content on its platforms using actual data.\n",
      "\n",
      "- **Industry Impact**: Meta believes that the combination of performance, reliability, security, and privacy at this scale is unprecedented.\n",
      "\n",
      "- **Related Events**: The article also mentions upcoming AI & Big Data Expo events in Santa Clara, Amsterdam, and London, where further discussions on AI and big data will take place.\n"
     ]
    }
   ],
   "source": [
    "# prepare template for prompt\n",
    "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
    "\n",
    "Here's the article you need to summarize.\n",
    "\n",
    "==========\n",
    "Title: {article_title}\n",
    "\n",
    "{article_text}\n",
    "==========\n",
    "\n",
    "Now provide a summarized version of the article in a bulleted list format.\n",
    "\"\"\"\n",
    "\n",
    "# format prompt\n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "# generate summary\n",
    "summary = chat([HumanMessage(content=prompt)])\n",
    "print(summary.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Meta (anciennement Facebook) a dévoilé un superordinateur IA, nommé AI Research SuperCluster (RSC), prétendu être le plus rapide au monde une fois achevé.\n",
      "- Le RSC, qui n'est pas encore totalement construit, devrait être finalisé à mi-2022.\n",
      "- Les chercheurs de Meta utilisent déjà le RSC pour entraîner des modèles de traitement du langage naturel (NLP) et de vision par ordinateur de grande envergure.\n",
      "- Le but du RSC est de permettre la formation de modèles avec des trillions de paramètres.\n",
      "- Meta envisage que le RSC puisse, par exemple, faciliter des traductions vocales en temps réel pour des groupes de personnes parlant différentes langues, afin de collaborer sur des projets de recherche ou de jouer à des jeux en réalité augmentée (AR).\n",
      "- Le RSC devrait être 20 fois plus rapide que les clusters actuels de Meta basés sur V100, 9 fois plus rapide pour exécuter la bibliothèque de communication collective NVIDIA (NCCL) et 3 fois plus rapide pour l'entraînement de workflows NLP à grande échelle.\n",
      "- Un modèle avec des dizaines de milliards de paramètres peut être formé en trois semaines avec le RSC, contre neuf semaines auparavant.\n",
      "- Le RSC a été conçu avec des contrôles de sécurité et de confidentialité, permettant à Meta d'utiliser des exemples réels de ses systèmes de production pour l'entraînement.\n",
      "- Cela permettra à Meta d'avancer dans la recherche pour des tâches essentielles telles que l'identification de contenus nuisibles sur ses plateformes.\n",
      "- Meta affirme que c'est la première fois que performance, fiabilité, sécurité et confidentialité sont abordées à une telle échelle.\n",
      "- Pour en savoir plus sur l'IA et les grandes données, des événements comme l'AI & Big Data Expo auront lieu à Santa Clara, Amsterdam et Londres en 2022.\n"
     ]
    }
   ],
   "source": [
    "# prepare template for prompt\n",
    "template = \"\"\"You are an advanced AI assistant that summarized online articles into bulleted lists in French.\n",
    " \n",
    "\n",
    "{article_text}\n",
    "==================\n",
    "\n",
    "Now, provide a summarized version of the article in a bulleted list format, in French.\n",
    "\"\"\"\n",
    "\n",
    "# format prompt \n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "# generate summary\n",
    "summary = chat([HumanMessage(content=prompt)])\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaHub Wikipedia Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_14192\\1281470272.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  WikipediaReader = download_loader('WikipediaReader')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['ACTIVE_LOOP'] = keyring.get_password('activeloop', 'key_for_windows')\n",
    "WikipediaReader = download_loader('WikipediaReader')\n",
    "loader = WikipediaReader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load_data(pages=['Natural Language Processing', 'Artificial Intelligence'])\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save on DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DeepLakeVectorStore' from 'llama_index.core.vector_stores' (c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\llama_index\\core\\vector_stores\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepLakeVectorStore\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DeepLakeVectorStore' from 'llama_index.core.vector_stores' (c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\llama_index\\core\\vector_stores\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index.core.vector_stores import DeepLakeVectorStore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
