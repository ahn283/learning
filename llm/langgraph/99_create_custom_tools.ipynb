{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create tools\n",
    "\n",
    "When constructing an agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:\n",
    "\n",
    "| Attribute     | Type                            | Description                                                                                                                                                                    |\n",
    "|---------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| name          | str                             | Must be unique within a set of tools provided to an LLM or agent.                                                                                                              |\n",
    "| description   | str                             | Describes what the tool does. Used as context by the LLM or agent.                                                                                                             |\n",
    "| args_schema   | pydantic.BaseModel | Optional but recommended, and required if using callback handlers. It can be used to provide more information (e.g., few-shot examples) or validation for expected parameters. |\n",
    "| return_direct | boolean                         | Only relevant for agents. When True, after invoking the given tool, the agent will stop and return the result direcly to the user.                                             |\n",
    "\n",
    "LangChain supports the creation of tools from:\n",
    "\n",
    "1. Functions;\n",
    "2. LangChain [Runnables](https://python.langchain.com/docs/concepts/runnables/);\n",
    "3. By sub-classing from [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html) -- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.\n",
    "\n",
    "Creating tools from functions may be sufficient for most use cases, and can be done via a simple @tool decorator. If more configuration is needed-- e.g., specification of both sync and async implementations-- one can also use the [StructuredTool.from_function](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.structured.StructuredTool.html#langchain_core.tools.structured.StructuredTool.from_function) class method.\n",
    "\n",
    "In this guide we provide an overview of these methods.\n",
    "\n",
    "<blockquote>\n",
    "Models will perform better if the tools have well chosen names, descriptions and JSON schemas.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tools from functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @tool decorator\n",
    "\n",
    "This `@tool` decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description - so a docstring MUST be provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference: [tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or create an async implementation, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `@tool` supports parsing of annotations, nested schemas, and other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Multiply a by the maximum of b.', 'properties': {'a': {'description': 'scale factor', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'list of ints over which to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}}, 'required': ['a', 'b'], 'title': 'multiply_by_max', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int, \"scale factor\"],\n",
    "    b: Annotated[List[int], \"list of ints over which to take maximum\"],\n",
    ") -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "    return a * max(b)\n",
    "\n",
    "print(multiply_by_max.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also customize the tool name and JSON args by passing them into the tool decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication-tool\n",
      "Multiply two numbers.\n",
      "{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "    \n",
    "@tool(\"multiplication-tool\", args_schema=CalculatorInput, return_direct=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.return_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docstring Parsing\n",
    "\n",
    "`@tool` can optionally parse [Google Style docstrings](https://google.github.io/styleguide/pyguide.html#383-functions-and-methods) and associate the docstring components (such as arg descriptions) to the relevant parts of the tool schema. To toggle this behavior, specify `parse_docstring`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'The foo', 'properties': {'bar': {'description': 'the bar', 'title': 'Bar', 'type': 'string'}, 'baz': {'description': 'the baz', 'title': 'Baz', 'type': 'integer'}}, 'required': ['bar', 'baz'], 'title': 'foo', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def foo(bar: str, baz: int) -> str:\n",
    "    \"\"\"The foo\n",
    "    \n",
    "    Args:\n",
    "        bar: the bar\n",
    "        baz: the baz\n",
    "    \"\"\"\n",
    "    return bar\n",
    "\n",
    "print(foo.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StructureTool\n",
    "\n",
    "The `StructuredTool.from_function` class method provides a bit more configurability than the `@tool` decorator, without requiring much additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Calculator\n",
      "multiplay numbers\n",
      "{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "    \n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    name=\"Calculator\",\n",
    "    description=\"multiplay numbers\",\n",
    "    args_schema=CalculatorInput,\n",
    "    return_direct=True,\n",
    "    # coroutine=... <- you canm specify an async method if desired as well\n",
    ")\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(calculator.name)\n",
    "print(calculator.description)\n",
    "print(calculator.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tools from Runnables\n",
    "\n",
    "LangChain [Runnables](https://python.langchain.com/docs/concepts/runnables/) that accept string or dict input can be converted to tools using the as_tool method, which allows for the specification of names, descriptions, and additional schema information for arguments.\n",
    "\n",
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/_c9pchvx7m9274g3530s1jcw0000gn/T/ipykernel_81366/416616865.py:16: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  as_tool = chain.as_tool(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_style': {'title': 'Answer Style', 'type': 'string'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.language_models import GenericFakeChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\n",
    "        \"human\", \"Hello. Please respond in the style of {answer_style}.\"\n",
    "    )]\n",
    ")\n",
    "\n",
    "# Placeholder LLM\n",
    "llm = GenericFakeChatModel(messages=iter([\"hello matey\"]))\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "as_tool = chain.as_tool(\n",
    "    name=\"Style Responder\", description=\"Description of when to use tool.\"\n",
    ")\n",
    "as_tool.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [this guide](https://python.langchain.com/docs/how_to/convert_runnable_to_tool/) for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclass BaseTool\n",
    "\n",
    "You can define a custom tool by sub-classing from `BaseTool`. This provides maximal control over the tool definition, but requires writing more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun\n",
    ")\n",
    "from langchain_core.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "    \n",
    "# Note: It's important that every field has type hints. BaseTool is a\n",
    "# Pydantic class and not having type hints can lead to unexpected behavior.\n",
    "class CustomCalculatorTool(BaseTool):\n",
    "    name: str = \"Calculator\"\n",
    "    description: str = \"useful for when you need to answer questions about math\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "    return_direct: bool = True\n",
    "    \n",
    "    def _run(\n",
    "        self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return a * b\n",
    "    \n",
    "    async def _arun(\n",
    "        self,\n",
    "        a: int,\n",
    "        b: int,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        # If the calculation is cheap, you can just delegate to the sync implementation\n",
    "        # as hown below.\n",
    "        # If the sync calculation is expensive, you should delete the entire _arun method.\n",
    "        # LangChain will automatically provide a better implemenration that will\n",
    "        # kick off the task in a thread to make sure it doesn't block other async code.\n",
    "        return self._run(a, b, run_manager=run_manager.get_sync())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator\n",
      "useful for when you need to answer questions about math\n",
      "{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\n",
      "True\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "multiply = CustomCalculatorTool()\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.return_direct)\n",
    "\n",
    "print(multiply.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await multiply.ainvoke({\"a\": 2, \"b\": 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create async tools\n",
    "\n",
    "LangChain Tools implement the [Runnable interface](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) 🏃.\n",
    "\n",
    "All Runnables expose the `invoke` and `ainvoke` methods (as well as other methods like `batch`, `abatch`, `astream` etc)\n",
    "\n",
    "So even if you only provide an `sync` implementation of a tool, you could still use the `ainvoke` interface, but there are some important things to know:\n",
    "\n",
    "- LangChain's by default provides an async implementation that assumes that the function is expensive to compute, so it'll delegate execution to another thread.\n",
    "- If you're working in an async codebase, you should create async tools rather than sync tools, to avoid incuring a small overhead due to that thread.\n",
    "- If you need both sync and async implementations, use `StructuredTool.from_function` or sub-class from `BaseTool`.\n",
    "- If implementing both sync and async, and the sync code is fast to run, override the default LangChain async implementation and simply call the sync code.\n",
    "- You CANNOT and SHOULD NOT use the sync invoke with an async tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(\n",
    "    await calculator.ainvoke({\"a\": 2, \"b\": 5})\n",
    ")   # Uses default LangChain async implementation incurs small overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(\n",
    "    await calculator.ainvoke({\"a\": 2, \"b\": 5})\n",
    ")   # Uses use provided amuliply without addtional overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should not and cannot use `.invoke` when providing only an async definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raised not implemented error. You should not be doing this.\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "async def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "try:\n",
    "    multiply.invoke({\"a\": 2, \"b\": 3})\n",
    "except NotImplementedError:\n",
    "    print(\"Raised not implemented error. You should not be doing this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tool Errors\n",
    "\n",
    "If you're using tools with agents, you will likely need an error handling strategy, so the agent can recover from the error and continue execution.\n",
    "\n",
    "A simple strategy is to throw a `ToolException` from inside the tool and specify an error handler using `handle_tool_error`.\n",
    "\n",
    "When the error handler is specified, the exception will be caught and the error handler will decide which output to return from the tool.\n",
    "\n",
    "You can set `handle_tool_error` to `True`, a string value, or a function. If it's a function, the function should take a `ToolException` as a parameter and return a value.\n",
    "\n",
    "Please note that only raising a `ToolException` won't be effective. You need to first set the `handle_tool_error` of the tool because its default value is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "\n",
    "def get_weather(city: str) -> int:\n",
    "    \"\"\"Get weather for the given city.\"\"\"\n",
    "    raise ToolException(f\"Error: There is no city by the name of {city}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference: [ToolException](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.ToolException.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example with the default `handle_tool_error=True` behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: There is no city by the name of foobar.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "get_weather_tool.invoke({\"city\": \"foobar\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set `handle_tool_error` to a string that will always be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ToolException",
     "evalue": "Error: There is no city by the name of foobar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mToolException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m get_weather_tool \u001b[38;5;241m=\u001b[39m StructuredTool\u001b[38;5;241m.\u001b[39mfrom_function(\n\u001b[1;32m      2\u001b[0m     func\u001b[38;5;241m=\u001b[39mget_weather,\n\u001b[1;32m      3\u001b[0m     handle_tool_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is no such city, but it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms probably above 0K there!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mget_weather_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfoobar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/learning/llm/langgraph/agent/lib/python3.9/site-packages/langchain_core/tools/base.py:484\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, ToolCall],\n\u001b[1;32m    480\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    483\u001b[0m     tool_input, kwargs \u001b[38;5;241m=\u001b[39m _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/learning/llm/langgraph/agent/lib/python3.9/site-packages/langchain_core/tools/base.py:725\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    724\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    726\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    727\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/github/learning/llm/langgraph/agent/lib/python3.9/site-packages/langchain_core/tools/base.py:694\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    693\u001b[0m     tool_kwargs \u001b[38;5;241m=\u001b[39m tool_kwargs \u001b[38;5;241m|\u001b[39m {config_param: config}\n\u001b[0;32m--> 694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/github/learning/llm/langgraph/agent/lib/python3.9/site-packages/langchain_core/tools/structured.py:80\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     79\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructuredTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mget_weather\u001b[0;34m(city)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_weather\u001b[39m(city: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get weather for the given city.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ToolException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: There is no city by the name of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mToolException\u001b[0m: Error: There is no city by the name of foobar."
     ]
    }
   ],
   "source": [
    "get_weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    handle_tool_errors=\"There is no such city, but it's probably above 0K there!\"\n",
    ")\n",
    "\n",
    "get_weather_tool.invoke({\"city\": \"foobar\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the error using a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following errors occurred during tool execution: Error: There is no city by the name of foobar.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f\"The following errors occurred during tool execution: {error.args[0]}\"\n",
    "\n",
    "get_weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    handle_tool_error=_handle_error,\n",
    ")\n",
    "\n",
    "get_weather_tool.invoke({\"city\": \"foobar\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning artifacts of Tool execution\n",
    "\n",
    "Sometimes there are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself. For example if a tool returns custom objects like Documents, we may want to pass some view or metadata about this output to the model without passing the raw output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\n",
    "\n",
    "The Tool and ToolMessage interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\n",
    "\n",
    "If we want our tool to distinguish between message content and other artifacts, we need to specify `response_format=\"content_and_artifact\"` when defining our tool and make sure that we return a tuple of (content, artifact):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def generate_random_ints(min: int, max: int, size: int) -> Tuple[str, List[int]]:\n",
    "    \"\"\"Generate size random ints in the range [min, max].\"\"\"\n",
    "    array = [random.randint(min, max) for _ in range(size)]\n",
    "    content = f\"Successfully generated array of {size} random ints in [{min}, {max}].\"\n",
    "    return content, array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we invoke our tool directly with the tool arguments, we'll get back just the content part of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully generated array of 10 random ints in [0, 9].'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke({\"min\": 0, \"max\": 9, \"size\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we invoke our tool with a ToolCall (like the ones generated by tool-calling models), we'll get back a ToolMessage that contains both the content and artifact generated by the Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Successfully generated array of 10 random ints in [0, 9].', name='generate_random_ints', tool_call_id='123', artifact=[7, 4, 3, 0, 0, 1, 6, 7, 0, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(\n",
    "    {\n",
    "        \"name\": \"generate_random_ints\",\n",
    "        \"args\": {\"min\":0, \"max\": 9, \"size\": 10},\n",
    "        \"id\": \"123\",    # required\n",
    "        \"type\": \"tool_call\",    # required\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same when subclassing BaseTool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "class GenerateRandomFloats(BaseTool):\n",
    "    name: str = \"generate_random_ints\"\n",
    "    description: str = \"Generate size random floats in the range [min, max].\"\n",
    "    response_format: str = \"content_and_artifact\"\n",
    "    \n",
    "    ndigits: int = 2\n",
    "    \n",
    "    def _run(self, min: float, max: float, size: int) -> Tuple[str, List[float]]:\n",
    "        range_ = max - min\n",
    "        array = [\n",
    "            round(min + (range_ * random.random()), ndigits=self.ndigits)\n",
    "            for _ in range(size)\n",
    "        ]\n",
    "        content = f\"Generated {size} floats in [{min}, {max}], rounded to {self.ndigits} decimals.\"\n",
    "        return content, array\n",
    "        \n",
    "    # Optionally define an equivalent async method\n",
    "    \n",
    "    # async def _arun(self, min: float, max: float, size: int) -> Tuple[str, List[float]]:\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Generated 3 floats in [0.1, 3.3333], rounded to 4 decimals.', name='generate_random_ints', tool_call_id='123', artifact=[2.8548, 1.3378, 0.3043])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_gen = GenerateRandomFloats(ndigits=4)\n",
    "\n",
    "rand_gen.invoke(\n",
    "    {\n",
    "        \"name\": \"generate_random_floats\",\n",
    "        \"args\": {\"min\": 0.1, \"max\": 3.3333, \"size\": 3},\n",
    "        \"id\": \"123\",\n",
    "        \"type\": \"tool_call\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
