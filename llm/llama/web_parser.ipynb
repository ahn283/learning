{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_web_url(text):\n",
    "    pattern = r\"https?://\\S+\"\n",
    "    if re.search(pattern, text):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def extract_urls(text):\n",
    "    url_regex = r\"(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&\\/\\/=]*)\"\n",
    "    reg = re.compile(url_regex)\n",
    "    res = reg.search(text)\n",
    "    if res == None:\n",
    "        return text\n",
    "    else:\n",
    "        indices = res.span()\n",
    "        url_txt = text[indices[0]:indices[1]]\n",
    "        \n",
    "        return url_txt\n",
    "\n",
    "text_kr = \"나는 https://www.naver.com와 http://www.google.com을 좋아한다. 그리고 https://www.daum.net도 좋다.\"\n",
    "text_en = text = \"Check out my website at https://example.com and follow the blog at http://blog.example.com/page.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_web_url(text_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_web_url(text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.naver.com'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_urls(text_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://example.com'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_urls(text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use SimpleWebPageReader\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='https://uni-datastudy.tistory.com/m/81', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='#  티스토리\\n\\n**[남디윤 로그 데이터](/m)**\\n\\n[검색하기](/m/search)\\n\\n## Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\\n\\n[Development/etc.](/m/category/Development/etc.)\\n\\n### Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\\n\\n남디윤 2024\\\\. 8. 4. 15:03\\n\\n![](https://blog.kakaocdn.net/dn/b6zeF5/btsIUjIPcEJ/RkkgJA6YFVA1j0Mg9bUrV1/img.png)\\n\\n\\n\\n> **목차**  \\n>\\n>\\n> 0\\\\. Ollama 다운 및 설치\\n>\\n> 1\\\\. 깃 클론\\n>\\n> 2\\\\. \"Llama-3.1-8B-Instruct\" 폴더 생성\\n>\\n> 3\\\\. Modelfile 복제 및 수정\\n>\\n> 4\\\\. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운\\n>\\n> 5\\\\. ollama serve\\n>\\n> 6\\\\. ollama create llama3.1-instruct-8b -f Modelfile\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n최근에 라마3.1이 공개되었죠\\n\\n저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다\\n\\n(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ)\\n\\n\\n\\n아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ\\n\\n기본적으로 테디노트 \"#llama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\" 영상을 따라가며 진행됩니다 (아래 영상 첨부)\\n\\n다만 이 내용을 그대로 _**llama3.1로 적용하고 리눅스 서버**_ 에서 올라마를 사용해볼게요\\n\\n<https://www.youtube.com/watch?v=12CuUQIPdM4>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n* * *\\n\\n\\n\\n\\n\\n\\n\\n#### **0\\\\. Ollama 다운 및 설치**\\n\\n아래 명령어로 설치해주세요 (다운하고 실행되는 명령어)\\n\\n\\n\\n<https://ollama.com/download/linux>\\n\\n[   Download Ollama on Linux Download Ollama on Linux ollama.com\\n](https://ollama.com/download/linux)\\n\\n    \\n    \\n    curl -fsSL https://ollama.com/install.sh | sh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n#### **1\\\\. 깃 클론**\\n\\n아래 레퍼지토리를 클론해주세요 (가장 간단한 것 같습니다)\\n\\n<https://github.com/teddylee777/langserve_ollama>\\n\\n[   GitHub - teddylee777/langserve_ollama: 무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅.\\nLangServe 무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅. LangServe, Ollama, streamlit + RAG\\n- teddylee777/langserve_ollama github.com\\n](https://github.com/teddylee777/langserve_ollama)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n#### **2.  \"Llama-3.1-8B-Instruct\" 폴더 생성 **\\n\\n클론해준 레퍼지토리의 ollama-modelfile 폴더에 \"Llama-3.1-8B-Instruct\" 폴더를 생성해줍니다\\n\\n저는 아래와 같은 위치에 생성해두었어요\\n\\n![](https://blog.kakaocdn.net/dn/saT8H/btsIUSqo1uV/OxHAXnZIDhDCvDlKcWeqSK/img.png)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n#### **3\\\\. Modelfile 복제 및 수정**\\n\\n저는 Llama-3-8B-Instruct를 사용했었어서 이 폴더에 있는 Modelfile을 복제해서\\n\"Llama3.1-8B-Instruct\"폴더에 이동시켜주었습니다.\\n\\n그 다음 Modelfile의 가장 윗 줄을 수정해주었습니다. ( 3 -> 3.1)\\n\\n![](https://blog.kakaocdn.net/dn/kUb3H/btsITRyYTtj/N1f6WIbdTpf1e9VaMNeba0/img.png)\\n![](https://blog.kakaocdn.net/dn/bA9qY0/btsITTKpBH3/ERfNz99XuwwXzlOFEAX28k/img.png)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n#### **4\\\\. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운**\\n\\n영상에 나온 같은 작성자의 GGUF 파일을 다운하였습니다.\\n\\n이미 올려두셨더라구요. (아래 링크 첨부)\\n\\n\\n\\n다운 위치는 \"Llama3.1-8B-Instruct\"폴더입니다\\n\\n터미널을 사용해서 다운하셔도됩니다\\n\\n저의 경우 Q8을 사용했습니다.\\n\\n\\n\\n(Q8_0: 8비트 양자화된 모델을 의미.)\\n\\n저도 정확히는 아직까지 양자화 Quantization 개념이 확실치 않는데.. Q8은 8비트로 양자화에서 작고, 더 빠른 대신 정확도가 살짝\\n손실될 수도 있다는 것으로 알고 있습니다.\\n\\n원본 모델은 16비트 또는 32비트이구용\\n\\n아래 양자화에 대해 설명해주신 분이 계셔서 첨부해봅니당\\n\\n\\n\\n\\n\\n<https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-\\nGGUF/tree/main>\\n\\n[   QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF at main   huggingface.co\\n](https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-\\nGGUF/tree/main)\\n\\n![](https://blog.kakaocdn.net/dn/bxuhGt/btsIUVHrsdr/slRRs2LM173KbGMH66nxpk/img.png)\\n\\n    \\n    \\n    wget https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf\\n\\n\\n\\n<https://data-newbie.tistory.com/992>\\n\\n[   LLM) Quantization 방법론 알아보기 (GPTQ | QAT | AWQ | GGUF | GGML | PTQ) 양자화 기술은 모델을 압축하여 빠르고 효율적으로 만드는 기술입니다. 모델의 가중치와 활성화 값을 줄여 메모리를 절약하고 연산 속도를 높입니다. 이 글은 여러 양자화 기술 data-newbie.tistory.com ](https://data-newbie.tistory.com/992)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n#### **5\\\\. ollama serve**\\n\\n로컬에다가 설치할 경우, 그냥 바로 ollama create ~ 해도 되는데 서버에다가 설치할 경우에는, serve 과정이 필요합니다.\\n\\n(Ollama 애플리케이션이 클라이언트 요청을 수신하고 처리할 수 있도록 서버를 실행 필요)\\n\\n\\n\\n저는 Ollama 서버가 백그라운드에서 실행되도록 아래 명령어를 사용하여 가동시켜주었습니다.\\n\\n![](https://blog.kakaocdn.net/dn/bQL2BY/btsIUy6LzTC/5ikh05p9gQAPJnsgymDKkK/img.png)\\n\\n    \\n    \\n    nohup ollama serve &\\n\\n![](https://blog.kakaocdn.net/dn/yRWRf/btsIUScQK2t/KfFtXkXK1ThWBwysLaQ8qK/img.png)\\n\\n\\n\\n\\n\\n\\n\\n#### **6\\\\. ollama create llama3.1-instruct-8b -f Modelfile**\\n\\n그 다음 ollama create ~를 입력하면 잘 실행되고 있는 모습\\n\\n이를 클론해둔 langserve_ollama의 eample폴더 안에 있는 00-ollama-test 파일로 테스트도 해볼 수 있습니다.\\n\\n보면 ChatOllama에서 3.1 로 모델명을 바꿔주시면 새로 설치한 3.1 모델이 잘 돌아가는 것을 확인하실 수 있습니다.\\n\\n![](https://blog.kakaocdn.net/dn/pQ7Z6/btsITSED5nZ/Cz9iJDjKlcUkNBDEIKcThK/img.png)\\n![](https://blog.kakaocdn.net/dn/bEXxep/btsIUJmH493/JJkO3wrU9Jt8N9RaBgJko0/img.png)\\n![](https://blog.kakaocdn.net/dn/beUj0Z/btsITQ7WqmD/xijFk5F7P09VHPFef9EMSk/img.png)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n### 태그목록\\n\\n**글뷰관련 태그목록**\\n\\n[llama](/tag/llama), [llama3.1](/tag/llama3.1),\\n[llama리눅스](/tag/llama%EB%A6%AC%EB%88%85%EC%8A%A4),\\n[llama리눅스서버](/tag/llama%EB%A6%AC%EB%88%85%EC%8A%A4%EC%84%9C%EB%B2%84),\\n[ollama](/tag/ollama), [ollama serve](/tag/ollama%20serve),\\n[ollama리눅스](/tag/ollama%EB%A6%AC%EB%88%85%EC%8A%A4)\\n\\n### 블로그 정보\\n\\n**[남디윤 로그 데이터](/m)**\\n\\n[데이터사이언티스트를 꿈꾸는 대학원생](/m)\\n\\n[ ![프로필\\n사진](https://img1.daumcdn.net/thumb/S56x56/?scode=mtistory2&fname=https://tistory1.daumcdn.net/tistory/5489331/attach/b6d3fd5087eb4ffaa8fe57e9f134bd06)\\n](/m)\\n\\n**문의안내**\\n\\n  * [티스토리](https://tistory.com/m)\\n  * 로그인\\n  * [고객센터](https://cs.kakao.com/requests?service=175&locale=ko)\\n\\n티스토리는 카카오에서 사랑을 담아 만듭니다.\\n\\n[© Kakao Corp.](https://www.kakaocorp.com/)\\n\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "\n",
    "# NOTE : the html_to_text=True option requires html2text to be installed\n",
    "\n",
    "url = 'https://uni-datastudy.tistory.com/m/81'\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [url]\n",
    ")\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"ko\">\n",
       "<head>\n",
       "<script type=\"text/javascript\">if (!window.T) { window.T = {} }\n",
       "window.T.config = {\"TOP_SSL_URL\":\"https://www.tistory.com\",\"PREVIEW\":false,\"ROLE\":\"guest\",\"PREV_PAGE\":\"\",\"NEXT_PAGE\":\"\",\"BLOG\":{\"id\":5489331,\"name\":\"uni-datastudy\",\"title\":\"남디윤 로그 데이터\",\"isDormancy\":false,\"nickName\":\"남디윤\",\"status\":\"open\",\"profileStatus\":\"normal\"},\"NEED_COMMENT_LOGIN\":false,\"COMMENT_LOGIN_CONFIRM_MESSAGE\":\"\",\"LOGIN_URL\":\"https://www.tistory.com/auth/login/?redirectUrl=https://uni-datastudy.tistory.com/m/81\",\"DEFAULT_URL\":\"https://uni-datastudy.tistory.com\",\"USER\":{\"name\":null,\"homepage\":null,\"id\":0,\"profileImage\":null},\"SUBSCRIPTION\":{\"status\":\"none\",\"isConnected\":false,\"isPending\":false,\"isWait\":false,\"isProcessing\":false,\"isNone\":true},\"IS_LOGIN\":false,\"HAS_BLOG\":false,\"IS_SUPPORT\":false,\"IS_SCRAPABLE\":false,\"TOP_URL\":\"http://www.tistory.com\",\"JOIN_URL\":\"https://www.tistory.com/member/join\",\"PHASE\":\"prod\",\"ROLE_GROUP\":\"visitor\"};\n",
       "window.T.entryInfo = {\"entryId\":81,\"isAuthor\":false,\"categoryId\":1132962,\"categoryLabel\":\"Development/etc.\"};\n",
       "window.appInfo = {\"domain\":\"tistory.com\",\"topUrl\":\"https://www.tistory.com\",\"loginUrl\":\"https://www.tistory.com/auth/login\",\"logoutUrl\":\"https://www.tistory.com/auth/logout\"};\n",
       "window.initData = {};\n",
       "\n",
       "window.TistoryBlog = {\n",
       "    basePath: \"\",\n",
       "    url: \"https://uni-datastudy.tistory.com\",\n",
       "    tistoryUrl: \"https://uni-datastudy.tistory.com\",\n",
       "    manageUrl: \"https://uni-datastudy.tistory.com/manage\",\n",
       "    token: \"c1KDF9sQZU5nj6qBDX3LD4gCHDg/iT0ULhK1cKRQiHVd4nO/V2ycbBsE7RYQ7SEJ\"\n",
       "};\n",
       "var servicePath = \"\";\n",
       "var blogURL = \"\";window.T.gnbContext = {\"userId\":0,\"userName\":\"\",\"profileSrc\":\"https://t1.daumcdn.net/tistory_admin/blog/admin/profile_default_03.png\",\"storyServiceURI\":{\"storyHome\":\"https://storyhome.kakao.com/\",\"brunchStory\":\"https://brunch.co.kr/\",\"kakaoStory\":\"https://story.kakao.com/\"},\"blogs\":[],\"tryAutoLogin\":false};</script>\n",
       "<!-- System - START -->\n",
       "<!-- System - END -->\n",
       "<meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"telephone=no\" name=\"format-detection\"/>\n",
       "<script crossorigin=\"anonymous\" integrity=\"sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=\" src=\"//t1.daumcdn.net/tistory_admin/lib/jquery/jquery-3.5.1.min.js\"></script>\n",
       "<script src=\"//t1.daumcdn.net/tiara/js/v1/tiara.min.js\" type=\"text/javascript\"></script><meta content=\"always\" name=\"referrer\">\n",
       "<meta content=\"ca-host-pub-9691043933427338\" name=\"google-adsense-platform-account\">\n",
       "<meta content=\"tistory.com\" name=\"google-adsense-platform-domain\"/>\n",
       "<meta content='목차0. Ollama 다운 및 설치1. 깃 클론2. \"Llama-3.1-8B-Instruct\" 폴더 생성3. Modelfile 복제 및 수정4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운5. ollama serve6. ollama create llama3.1-instruct-8b -f Modelfile       최근에 라마3.1이 공개되었죠저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ) 아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ기본적으로 테디노트 \"#llama3 출시🔥 로컬에서 Llama3-8B..' name=\"description\"/>\n",
       "<meta content=\"article\" property=\"og:type\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/m/81\" property=\"og:url\"/>\n",
       "<meta content=\"남디윤\" property=\"og.article.author\"/>\n",
       "<meta content=\"남디윤 로그 데이터\" property=\"og:site_name\"/>\n",
       "<meta content=\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\" property=\"og:title\"/>\n",
       "<meta content=\"남디윤\" name=\"by\"/>\n",
       "<meta content='목차0. Ollama 다운 및 설치1. 깃 클론2. \"Llama-3.1-8B-Instruct\" 폴더 생성3. Modelfile 복제 및 수정4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운5. ollama serve6. ollama create llama3.1-instruct-8b -f Modelfile       최근에 라마3.1이 공개되었죠저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ) 아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ기본적으로 테디노트 \"#llama3 출시🔥 로컬에서 Llama3-8B..' property=\"og:description\"/>\n",
       "<meta content=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6zeF5%2FbtsIUjIPcEJ%2FRkkgJA6YFVA1j0Mg9bUrV1%2Fimg.png\" property=\"og:image\"/>\n",
       "<meta content=\"'IT 인터넷'\" property=\"article:section\"/>\n",
       "<meta content=\"summary_large_image\" name=\"twitter:card\"/>\n",
       "<meta content=\"@TISTORY\" name=\"twitter:site\"/>\n",
       "<meta content=\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\" name=\"twitter:title\"/>\n",
       "<meta content='목차0. Ollama 다운 및 설치1. 깃 클론2. \"Llama-3.1-8B-Instruct\" 폴더 생성3. Modelfile 복제 및 수정4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운5. ollama serve6. ollama create llama3.1-instruct-8b -f Modelfile       최근에 라마3.1이 공개되었죠저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ) 아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ기본적으로 테디노트 \"#llama3 출시🔥 로컬에서 Llama3-8B..' name=\"twitter:description\"/>\n",
       "<meta content=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6zeF5%2FbtsIUjIPcEJ%2FRkkgJA6YFVA1j0Mg9bUrV1%2Fimg.png\" property=\"twitter:image\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/81\" property=\"dg:plink\"/>\n",
       "<meta name=\"plink\"/>\n",
       "<meta content=\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\" name=\"title\"/>\n",
       "<meta content=\"남디윤 로그 데이터\" name=\"article:media_name\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/m/81\" property=\"article:mobile_url\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/81\" property=\"article:pc_url\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/m/81\" property=\"article:mobile_view_url\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/81\" property=\"article:pc_view_url\"/>\n",
       "<meta content=\"https://uni-datastudy.tistory.com/m/81\" property=\"article:talk_channel_view_url\"/>\n",
       "<meta content=\"https://www.tistory.com\" property=\"article:pc_service_home\"/>\n",
       "<meta content=\"https://www.tistory.com/m\" property=\"article:mobile_service_home\"/>\n",
       "<meta content=\"5489331_81\" property=\"article:txid\"/>\n",
       "<meta content=\"2024-08-04T15:03:28+09:00\" property=\"article:published_time\"/>\n",
       "<meta content=\"20240804030328\" property=\"og:regDate\"/>\n",
       "<meta content=\"2024-08-04T15:06:19+09:00\" property=\"article:modified_time\"/>\n",
       "<link href=\"https://tistory1.daumcdn.net/tistory_admin/userblog/tistory-63bdce1cc5f38c1f1ff0ada25a9a5edf6b8e0fc4/static/mobile/dist/index.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<script defer=\"\" src=\"https://tistory1.daumcdn.net/tistory_admin/userblog/tistory-63bdce1cc5f38c1f1ff0ada25a9a5edf6b8e0fc4/static/mobile/dist/index.js\" type=\"module\"></script>\n",
       "<script defer=\"\" nomodule=\"true\" src=\"https://tistory1.daumcdn.net/tistory_admin/userblog/tistory-63bdce1cc5f38c1f1ff0ada25a9a5edf6b8e0fc4/static/mobile/dist/index-legacy.js\" type=\"text/javascript\"></script>\n",
       "<script defer=\"\" nomodule=\"true\" src=\"https://tistory1.daumcdn.net/tistory_admin/userblog/tistory-63bdce1cc5f38c1f1ff0ada25a9a5edf6b8e0fc4/static/mobile/dist/polyfills-legacy.js\" type=\"text/javascript\"></script>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"user-scalable=no, initial-scale=1.0, maximum-scale=1.0 ,minimum-scale=1.0, width=device-width, viewport-fit=cover\" name=\"viewport\"/>\n",
       "<meta content=\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트) :: 남디윤 로그 데이터\" name=\"title\">\n",
       "<meta content=\"데이터사이언티스트를 꿈꾸는 대학원생\" name=\"description\">\n",
       "<title>Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)</title>\n",
       "<link href=\"https://tistory1.daumcdn.net/tistory_admin/userblog/tistory-63bdce1cc5f38c1f1ff0ada25a9a5edf6b8e0fc4/static/style/revenue.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"https://uni-datastudy.tistory.com/81\" rel=\"canonical\"/>\n",
       "<!-- BEGIN STRUCTURED_DATA -->\n",
       "<script type=\"application/ld+json\">\n",
       "    {\"@context\":\"http://schema.org\",\"@type\":\"BlogPosting\",\"mainEntityOfPage\":{\"@id\":\"https://uni-datastudy.tistory.com/m/81\",\"name\":null},\"url\":\"https://uni-datastudy.tistory.com/m/81\",\"headline\":\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\",\"description\":\"목차0. Ollama 다운 및 설치1. 깃 클론2. &quot;Llama-3.1-8B-Instruct&quot; 폴더 생성3. Modelfile 복제 및 수정4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운5. ollama serve6. ollama create llama3.1-instruct-8b -f Modelfile&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;최근에 라마3.1이 공개되었죠저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ)&nbsp;아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ기본적으로 테디노트 &quot;#llama3 출시🔥 로컬에서 Llama3-8B..\",\"author\":{\"@type\":\"Person\",\"name\":\"남디윤\",\"logo\":null},\"image\":{\"@type\":\"ImageObject\",\"url\":\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6zeF5%2FbtsIUjIPcEJ%2FRkkgJA6YFVA1j0Mg9bUrV1%2Fimg.png\",\"width\":\"800px\",\"height\":\"800px\"},\"datePublished\":\"2024-08-04T15:03:28+09:00\",\"dateModified\":\"2024-08-04T15:06:19+09:00\",\"publisher\":{\"@type\":\"Organization\",\"name\":\"TISTORY\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://t1.daumcdn.net/tistory_admin/static/images/openGraph/opengraph.png\",\"width\":\"800px\",\"height\":\"800px\"}}}\n",
       "</script>\n",
       "<!-- END STRUCTURED_DATA -->\n",
       "</meta></meta></meta></meta></head>\n",
       "<body data-agent-type=\"web_desktop\" data-role=\"visitor\">\n",
       "<!-- 게시글 뷰 -->\n",
       "<div class=\"container-doc blog_view ios-safe-area-h b_scroll_retern\" id=\"entry-view\">\n",
       "<header class=\"doc-header\">\n",
       "<h1 class=\"doc-title\">\n",
       "<a class=\"link_logo\" href=\"#\" id=\"tistory-home-link\"><span class=\"tit_logo\">티스토리</span></a>\n",
       "<div data-react-app=\"StoryServices\"></div>\n",
       "</h1>\n",
       "<strong class=\"tit_blog\" style=\"display:block;\"><a href=\"/m\">남디윤 로그 데이터</a></strong>\n",
       "<div class=\"header_right\">\n",
       "<a class=\"link_search\" data-tiara-action-name=\"GNB&gt; 검색 버튼 클릭\" data-tiara-layer=\"search\" href=\"/m/search\"><span class=\"ico_search\">검색하기</span></a>\n",
       "<div data-react-app=\"Profile\" style=\"display:inline-flex\"></div>\n",
       "</div>\n",
       "</header>\n",
       "<main class=\"doc-main h-full border-box\">\n",
       "<section class=\"inner-main h-full\">\n",
       "<h2 class=\"screen_out\">Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)</h2>\n",
       "<div class=\"main-content h-full\">\n",
       "<article class=\"content-article mobile-article\" id=\"mainContent\">\n",
       "<div class=\"blogview_tit\">\n",
       "<a class=\"txt_category\" href=\"/m/category/Development/etc.\"><span class=\"inner_g\">Development/etc.</span></a>\n",
       "<h3 class=\"tit_blogview\">Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)</h3>\n",
       "</div>\n",
       "<div class=\"blogview_info\">\n",
       "<cite class=\"by_blog\">남디윤</cite>\n",
       "<span class=\"txt_date\"> 2024. 8. 4. 15:03</span>\n",
       "</div>\n",
       "<!-- System - START -->\n",
       "<!-- System - END -->\n",
       "<div class=\"blogview_content useless_p_margin editor_ke\" style=\"height:auto!important\"><p><figure class=\"imageblock alignCenter\" data-filename=\"파이토치-트랜스포머-001.png\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"640\" data-origin-width=\"640\"><span data-phocus=\"https://blog.kakaocdn.net/dn/b6zeF5/btsIUjIPcEJ/RkkgJA6YFVA1j0Mg9bUrV1/img.png\" data-url=\"https://blog.kakaocdn.net/dn/b6zeF5/btsIUjIPcEJ/RkkgJA6YFVA1j0Mg9bUrV1/img.png\"><img data-filename=\"파이토치-트랜스포머-001.png\" data-origin-height=\"640\" data-origin-width=\"640\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/b6zeF5/btsIUjIPcEJ/RkkgJA6YFVA1j0Mg9bUrV1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6zeF5%2FbtsIUjIPcEJ%2FRkkgJA6YFVA1j0Mg9bUrV1%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<blockquote data-ke-style=\"style3\"><b>목차</b><br/>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a0\">0. Ollama 다운 및 설치</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a1\">1. 깃 클론</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a2\">2. \"Llama-3.1-8B-Instruct\" 폴더 생성</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a3\">3. Modelfile 복제 및 수정</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a4\">4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a5\">5. ollama serve</a></p>\n",
       "<p data-ke-size=\"size16\"><a href=\"#a6\">6. ollama create llama3.1-instruct-8b -f Modelfile</a></p>\n",
       "</blockquote>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\">최근에 라마3.1이 공개되었죠</p>\n",
       "<p data-ke-size=\"size16\">저도 지금 진행 중인 연구에 활용하기 위해서 라마3.1을 사용해보려고 합니다</p>\n",
       "<p data-ke-size=\"size16\">(서버 세션을 다시 띄우면서 올라마 설치 및 라마3.1 설치 등을 전반적으로 다시 해야하는 겸..해서 포스팅을 합니다 ㅎㅎ)</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\">아직 저도 잘 모르지만,, 과정을 작성해보려고 해요 ㅎㅎ</p>\n",
       "<p data-ke-size=\"size16\">기본적으로 테디노트 \"#llama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\" 영상을 따라가며 진행됩니다 (아래 영상 첨부)</p>\n",
       "<p data-ke-size=\"size16\">다만 이 내용을 그대로 <u><b>llama3.1로 적용하고 리눅스 서버</b></u>에서 올라마를 사용해볼게요</p>\n",
       "<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/watch?v=12CuUQIPdM4\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.youtube.com/watch?v=12CuUQIPdM4</a></p>\n",
       "<figure data-ke-mobilestyle=\"widthContent\" data-ke-style=\"alignCenter\" data-ke-type=\"video\" data-original-url=\"\" data-video-height=\"484\" data-video-host=\"youtube\" data-video-origin-height=\"484\" data-video-origin-width=\"860\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cJhXsm/hyWKJ7q30Q/yNkBKakwwrnOdcdMmncQkk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-title=\"#llama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\" data-video-url=\"https://www.youtube.com/watch?v=12CuUQIPdM4\" data-video-width=\"860\"><iframe allowfullscreen=\"true\" frameborder=\"\" height=\"484\" src=\"https://www.youtube.com/embed/12CuUQIPdM4\" width=\"860\"></iframe>\n",
       "<figcaption style=\"display: none;\"></figcaption>\n",
       "</figure>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<hr contenteditable=\"false\" data-ke-style=\"style2\" data-ke-type=\"horizontalRule\"/>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a0\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>0. Ollama 다운 및 설치</b></h4>\n",
       "<p data-ke-size=\"size16\">아래 명령어로 설치해주세요 (다운하고 실행되는 명령어)</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"><a href=\"https://ollama.com/download/linux\" rel=\"noopener noreferrer\" target=\"_blank\">https://ollama.com/download/linux</a></p>\n",
       "<figure contenteditable=\"false\" data-ke-align=\"alignCenter\" data-ke-type=\"opengraph\" data-og-description=\"Download Ollama on Linux\" data-og-host=\"ollama.com\" data-og-image=\"https://scrap.kakaocdn.net/dn/86OyJ/hyWGRF246H/JCfPmrhJFKkJojWRo1ZlzK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630\" data-og-source-url=\"https://ollama.com/download/linux\" data-og-title=\"Download Ollama on Linux\" data-og-type=\"website\" data-og-url=\"https://ollama.com/download/linux\" id=\"og_1722748719192\"><a data-source-url=\"https://ollama.com/download/linux\" href=\"https://ollama.com/download/linux\" rel=\"noopener\" target=\"_blank\">\n",
       "<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/86OyJ/hyWGRF246H/JCfPmrhJFKkJojWRo1ZlzK/img.png?width=1200&amp;height=630&amp;face=0_0_1200_630');\"> </div>\n",
       "<div class=\"og-text\">\n",
       "<p class=\"og-title\" data-ke-size=\"size16\">Download Ollama on Linux</p>\n",
       "<p class=\"og-desc\" data-ke-size=\"size16\">Download Ollama on Linux</p>\n",
       "<p class=\"og-host\" data-ke-size=\"size16\">ollama.com</p>\n",
       "</div>\n",
       "</a></figure>\n",
       "<pre class=\"bash\" data-ke-language=\"bash\" data-ke-type=\"codeblock\" id=\"code_1722748796159\"><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a1\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>1. 깃 클론</b></h4>\n",
       "<p data-ke-size=\"size16\">아래 레퍼지토리를 클론해주세요 (가장 간단한 것 같습니다)</p>\n",
       "<p data-ke-size=\"size16\"><a href=\"https://github.com/teddylee777/langserve_ollama\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/teddylee777/langserve_ollama</a></p>\n",
       "<figure contenteditable=\"false\" data-ke-align=\"alignCenter\" data-ke-type=\"opengraph\" data-og-description=\"무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅. LangServe, Ollama, streamlit + RAG - teddylee777/langserve_ollama\" data-og-host=\"github.com\" data-og-image=\"https://scrap.kakaocdn.net/dn/6vTQV/hyWGRMQoTS/f2F12TLW0UKocRDGOXo9zk/img.png?width=1200&amp;height=600&amp;face=978_135_1045_208\" data-og-source-url=\"https://github.com/teddylee777/langserve_ollama\" data-og-title=\"GitHub - teddylee777/langserve_ollama: 무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅. LangServe\" data-og-type=\"object\" data-og-url=\"https://github.com/teddylee777/langserve_ollama\" id=\"og_1722748079112\"><a data-source-url=\"https://github.com/teddylee777/langserve_ollama\" href=\"https://github.com/teddylee777/langserve_ollama\" rel=\"noopener\" target=\"_blank\">\n",
       "<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/6vTQV/hyWGRMQoTS/f2F12TLW0UKocRDGOXo9zk/img.png?width=1200&amp;height=600&amp;face=978_135_1045_208');\"> </div>\n",
       "<div class=\"og-text\">\n",
       "<p class=\"og-title\" data-ke-size=\"size16\">GitHub - teddylee777/langserve_ollama: 무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅. LangServe</p>\n",
       "<p class=\"og-desc\" data-ke-size=\"size16\">무료로 한국어🇰🇷 파인튜닝 모델 받아서 로컬 LLM 호스팅. LangServe, Ollama, streamlit + RAG - teddylee777/langserve_ollama</p>\n",
       "<p class=\"og-host\" data-ke-size=\"size16\">github.com</p>\n",
       "</div>\n",
       "</a></figure>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a2\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>2. <span style=\"color: #333333; text-align: start;\"><span> </span>\"Llama-3.1-8B-Instruct\" 폴더 생성</span> </b></h4>\n",
       "<p data-ke-size=\"size16\">클론해준 레퍼지토리의 ollama-modelfile 폴더에 \"Llama-3.1-8B-Instruct\" 폴더를 생성해줍니다</p>\n",
       "<p data-ke-size=\"size16\">저는 아래와 같은 위치에 생성해두었어요</p>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"384\" data-origin-width=\"849\"><span data-phocus=\"https://blog.kakaocdn.net/dn/saT8H/btsIUSqo1uV/OxHAXnZIDhDCvDlKcWeqSK/img.png\" data-url=\"https://blog.kakaocdn.net/dn/saT8H/btsIUSqo1uV/OxHAXnZIDhDCvDlKcWeqSK/img.png\"><img data-origin-height=\"384\" data-origin-width=\"849\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/saT8H/btsIUSqo1uV/OxHAXnZIDhDCvDlKcWeqSK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsaT8H%2FbtsIUSqo1uV%2FOxHAXnZIDhDCvDlKcWeqSK%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a3\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>3. Modelfile 복제 및 수정</b></h4>\n",
       "<p data-ke-size=\"size16\">저는 Llama-3-8B-Instruct를 사용했었어서 이 폴더에 있는 Modelfile을 복제해서 \"Llama3.1-8B-Instruct\"폴더에 이동시켜주었습니다.</p>\n",
       "<p data-ke-size=\"size16\">그 다음 Modelfile의 가장 윗 줄을 수정해주었습니다. ( <span style=\"color: #333333; text-align: start;\">3 -&gt; 3.1)</span></p>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"349\" data-origin-width=\"1043\"><span data-phocus=\"https://blog.kakaocdn.net/dn/kUb3H/btsITRyYTtj/N1f6WIbdTpf1e9VaMNeba0/img.png\" data-url=\"https://blog.kakaocdn.net/dn/kUb3H/btsITRyYTtj/N1f6WIbdTpf1e9VaMNeba0/img.png\"><img data-origin-height=\"349\" data-origin-width=\"1043\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/kUb3H/btsITRyYTtj/N1f6WIbdTpf1e9VaMNeba0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkUb3H%2FbtsITRyYTtj%2FN1f6WIbdTpf1e9VaMNeba0%2Fimg.png\"/></span></figure>\n",
       "<figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"582\" data-origin-width=\"1745\"><span data-phocus=\"https://blog.kakaocdn.net/dn/bA9qY0/btsITTKpBH3/ERfNz99XuwwXzlOFEAX28k/img.png\" data-url=\"https://blog.kakaocdn.net/dn/bA9qY0/btsITTKpBH3/ERfNz99XuwwXzlOFEAX28k/img.png\"><img data-origin-height=\"582\" data-origin-width=\"1745\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/bA9qY0/btsITTKpBH3/ERfNz99XuwwXzlOFEAX28k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbA9qY0%2FbtsITTKpBH3%2FERfNz99XuwwXzlOFEAX28k%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a4\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>4. QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF 다운</b></h4>\n",
       "<p data-ke-size=\"size16\">영상에 나온 같은 작성자의 GGUF 파일을 다운하였습니다.</p>\n",
       "<p data-ke-size=\"size16\">이미 올려두셨더라구요. (아래 링크 첨부)</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\">다운 위치는 \"Llama3.1-8B-Instruct\"폴더입니다</p>\n",
       "<p data-ke-size=\"size16\">터미널을 사용해서 다운하셔도됩니다</p>\n",
       "<p data-ke-size=\"size16\">저의 경우 Q8을 사용했습니다.</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\">(Q8_0: 8비트 양자화된 모델을 의미.)</p>\n",
       "<p data-ke-size=\"size16\">저도 정확히는 아직까지 양자화 Quantization 개념이 확실치 않는데.. Q8은 8비트로 양자화에서 작고, 더 빠른 대신 정확도가 살짝 손실될 수도 있다는 것으로 알고 있습니다.</p>\n",
       "<p data-ke-size=\"size16\">원본 모델은 16비트 또는 32비트이구용</p>\n",
       "<p data-ke-size=\"size16\">아래 양자화에 대해 설명해주신 분이 계셔서 첨부해봅니당</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"><a href=\"https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\" rel=\"noopener noreferrer\" target=\"_blank\">https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main</a></p>\n",
       "<figure contenteditable=\"false\" data-ke-align=\"alignCenter\" data-ke-type=\"opengraph\" data-og-description=\"\" data-og-host=\"huggingface.co\" data-og-image=\"https://scrap.kakaocdn.net/dn/ceR2WA/hyWKwNNKiW/8p4PqvgEY6nxbnYK1fHTm0/img.png?width=1200&amp;height=648&amp;face=0_0_1200_648\" data-og-source-url=\"https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\" data-og-title=\"QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF at main\" data-og-type=\"website\" data-og-url=\"https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\" id=\"og_1722748435210\"><a data-source-url=\"https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\" href=\"https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\" rel=\"noopener\" target=\"_blank\">\n",
       "<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ceR2WA/hyWKwNNKiW/8p4PqvgEY6nxbnYK1fHTm0/img.png?width=1200&amp;height=648&amp;face=0_0_1200_648');\"> </div>\n",
       "<div class=\"og-text\">\n",
       "<p class=\"og-title\" data-ke-size=\"size16\">QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF at main</p>\n",
       "<p class=\"og-desc\" data-ke-size=\"size16\"> </p>\n",
       "<p class=\"og-host\" data-ke-size=\"size16\">huggingface.co</p>\n",
       "</div>\n",
       "</a></figure>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"311\" data-origin-width=\"1707\"><span data-phocus=\"https://blog.kakaocdn.net/dn/bxuhGt/btsIUVHrsdr/slRRs2LM173KbGMH66nxpk/img.png\" data-url=\"https://blog.kakaocdn.net/dn/bxuhGt/btsIUVHrsdr/slRRs2LM173KbGMH66nxpk/img.png\"><img data-origin-height=\"311\" data-origin-width=\"1707\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/bxuhGt/btsIUVHrsdr/slRRs2LM173KbGMH66nxpk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbxuhGt%2FbtsIUVHrsdr%2FslRRs2LM173KbGMH66nxpk%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<pre class=\"bash\" data-ke-language=\"bash\" data-ke-type=\"codeblock\" id=\"code_1722748522800\"><code>wget https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf</code></pre>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"><a href=\"https://data-newbie.tistory.com/992\" rel=\"noopener noreferrer\" target=\"_blank\">https://data-newbie.tistory.com/992</a></p>\n",
       "<figure contenteditable=\"false\" data-ke-align=\"alignCenter\" data-ke-type=\"opengraph\" data-og-description=\"양자화 기술은 모델을 압축하여 빠르고 효율적으로 만드는 기술입니다. 모델의 가중치와 활성화 값을 줄여 메모리를 절약하고 연산 속도를 높입니다. 이 글은 여러 양자화 기술\" data-og-host=\"data-newbie.tistory.com\" data-og-image=\"https://scrap.kakaocdn.net/dn/CLoNh/hyWKACGll1/jlCKPKwmnGeJcoFwUqrEXK/img.png?width=721&amp;height=377&amp;face=0_0_721_377,https://scrap.kakaocdn.net/dn/brYR1c/hyWKE580Oo/eKdKaABGCIdxnZ9UfzICfk/img.png?width=721&amp;height=377&amp;face=0_0_721_377,https://scrap.kakaocdn.net/dn/PZEFq/hyWG0iHiFq/QiNGPk5rIO4iql1Kdzrrp0/img.png?width=700&amp;height=444&amp;face=0_0_700_444\" data-og-source-url=\"https://data-newbie.tistory.com/992\" data-og-title=\"LLM) Quantization 방법론 알아보기 (GPTQ | QAT | AWQ | GGUF | GGML | PTQ)\" data-og-type=\"article\" data-og-url=\"https://data-newbie.tistory.com/992\" id=\"og_1722751096622\"><a data-source-url=\"https://data-newbie.tistory.com/992\" href=\"https://data-newbie.tistory.com/992\" rel=\"noopener\" target=\"_blank\">\n",
       "<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/CLoNh/hyWKACGll1/jlCKPKwmnGeJcoFwUqrEXK/img.png?width=721&amp;height=377&amp;face=0_0_721_377,https://scrap.kakaocdn.net/dn/brYR1c/hyWKE580Oo/eKdKaABGCIdxnZ9UfzICfk/img.png?width=721&amp;height=377&amp;face=0_0_721_377,https://scrap.kakaocdn.net/dn/PZEFq/hyWG0iHiFq/QiNGPk5rIO4iql1Kdzrrp0/img.png?width=700&amp;height=444&amp;face=0_0_700_444');\"> </div>\n",
       "<div class=\"og-text\">\n",
       "<p class=\"og-title\" data-ke-size=\"size16\">LLM) Quantization 방법론 알아보기 (GPTQ | QAT | AWQ | GGUF | GGML | PTQ)</p>\n",
       "<p class=\"og-desc\" data-ke-size=\"size16\">양자화 기술은 모델을 압축하여 빠르고 효율적으로 만드는 기술입니다. 모델의 가중치와 활성화 값을 줄여 메모리를 절약하고 연산 속도를 높입니다. 이 글은 여러 양자화 기술</p>\n",
       "<p class=\"og-host\" data-ke-size=\"size16\">data-newbie.tistory.com</p>\n",
       "</div>\n",
       "</a></figure>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a5\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>5. ollama serve</b></h4>\n",
       "<p data-ke-size=\"size16\">로컬에다가 설치할 경우, 그냥 바로 ollama create ~ 해도 되는데 서버에다가 설치할 경우에는, serve 과정이 필요합니다.</p>\n",
       "<p data-ke-size=\"size16\">(Ollama 애플리케이션이 클라이언트 요청을 수신하고 처리할 수 있도록 서버를 실행 필요)</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\">저는 Ollama 서버가 백그라운드에서 실행되도록 아래 명령어를 사용하여 가동시켜주었습니다.</p>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"144\" data-origin-width=\"1701\"><span data-phocus=\"https://blog.kakaocdn.net/dn/bQL2BY/btsIUy6LzTC/5ikh05p9gQAPJnsgymDKkK/img.png\" data-url=\"https://blog.kakaocdn.net/dn/bQL2BY/btsIUy6LzTC/5ikh05p9gQAPJnsgymDKkK/img.png\"><img data-origin-height=\"144\" data-origin-width=\"1701\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/bQL2BY/btsIUy6LzTC/5ikh05p9gQAPJnsgymDKkK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbQL2BY%2FbtsIUy6LzTC%2F5ikh05p9gQAPJnsgymDKkK%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<pre class=\"bash\" data-ke-language=\"bash\" data-ke-type=\"codeblock\" id=\"code_1722749082488\"><code>nohup ollama serve &amp;</code></pre>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"228\" data-origin-width=\"1703\"><span data-phocus=\"https://blog.kakaocdn.net/dn/yRWRf/btsIUScQK2t/KfFtXkXK1ThWBwysLaQ8qK/img.png\" data-url=\"https://blog.kakaocdn.net/dn/yRWRf/btsIUScQK2t/KfFtXkXK1ThWBwysLaQ8qK/img.png\"><img data-origin-height=\"228\" data-origin-width=\"1703\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/yRWRf/btsIUScQK2t/KfFtXkXK1ThWBwysLaQ8qK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FyRWRf%2FbtsIUScQK2t%2FKfFtXkXK1ThWBwysLaQ8qK%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\" id=\"a6\"> </p>\n",
       "<h4 data-ke-size=\"size20\"><b>6. ollama create llama3.1-instruct-8b -f Modelfile</b></h4>\n",
       "<p data-ke-size=\"size16\">그 다음 ollama create ~를 입력하면 잘 실행되고 있는 모습</p>\n",
       "<p data-ke-size=\"size16\">이를 클론해둔 langserve_ollama의 eample폴더 안에 있는 00-ollama-test 파일로 테스트도 해볼 수 있습니다.</p>\n",
       "<p data-ke-size=\"size16\">보면 ChatOllama에서 3.1 로 모델명을 바꿔주시면 새로 설치한 3.1 모델이 잘 돌아가는 것을 확인하실 수 있습니다.</p>\n",
       "<p><figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"278\" data-origin-width=\"1714\"><span data-phocus=\"https://blog.kakaocdn.net/dn/pQ7Z6/btsITSED5nZ/Cz9iJDjKlcUkNBDEIKcThK/img.png\" data-url=\"https://blog.kakaocdn.net/dn/pQ7Z6/btsITSED5nZ/Cz9iJDjKlcUkNBDEIKcThK/img.png\"><img data-origin-height=\"278\" data-origin-width=\"1714\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/pQ7Z6/btsITSED5nZ/Cz9iJDjKlcUkNBDEIKcThK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpQ7Z6%2FbtsITSED5nZ%2FCz9iJDjKlcUkNBDEIKcThK%2Fimg.png\"/></span></figure>\n",
       "<figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"96\" data-origin-width=\"1500\"><span data-phocus=\"https://blog.kakaocdn.net/dn/bEXxep/btsIUJmH493/JJkO3wrU9Jt8N9RaBgJko0/img.png\" data-url=\"https://blog.kakaocdn.net/dn/bEXxep/btsIUJmH493/JJkO3wrU9Jt8N9RaBgJko0/img.png\"><img data-origin-height=\"96\" data-origin-width=\"1500\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/bEXxep/btsIUJmH493/JJkO3wrU9Jt8N9RaBgJko0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbEXxep%2FbtsIUJmH493%2FJJkO3wrU9Jt8N9RaBgJko0%2Fimg.png\"/></span></figure>\n",
       "<figure class=\"imageblock alignCenter\" data-ke-mobilestyle=\"widthOrigin\" data-origin-height=\"720\" data-origin-width=\"1131\"><span data-phocus=\"https://blog.kakaocdn.net/dn/beUj0Z/btsITQ7WqmD/xijFk5F7P09VHPFef9EMSk/img.png\" data-url=\"https://blog.kakaocdn.net/dn/beUj0Z/btsITQ7WqmD/xijFk5F7P09VHPFef9EMSk/img.png\"><img data-origin-height=\"720\" data-origin-width=\"1131\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" src=\"https://blog.kakaocdn.net/dn/beUj0Z/btsITQ7WqmD/xijFk5F7P09VHPFef9EMSk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeUj0Z%2FbtsITQ7WqmD%2FxijFk5F7P09VHPFef9EMSk%2Fimg.png\"/></span></figure>\n",
       "</p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p>\n",
       "<p data-ke-size=\"size16\"> </p></div>\n",
       "<!-- System - START -->\n",
       "<!-- System - END -->\n",
       "</article>\n",
       "<aside class=\"content-aside cont_tag\">\n",
       "<h3 class=\"screen_out\">태그목록</h3>\n",
       "<div class=\"tag_comm\">\n",
       "<strong class=\"screen_out\">글뷰관련 태그목록</strong>\n",
       "<div class=\"list_tag\"><a href=\"/tag/llama\" rel=\"tag\">llama</a>, <a href=\"/tag/llama3.1\" rel=\"tag\">llama3.1</a>, <a href=\"/tag/llama%EB%A6%AC%EB%88%85%EC%8A%A4\" rel=\"tag\">llama리눅스</a>, <a href=\"/tag/llama%EB%A6%AC%EB%88%85%EC%8A%A4%EC%84%9C%EB%B2%84\" rel=\"tag\">llama리눅스서버</a>, <a href=\"/tag/ollama\" rel=\"tag\">ollama</a>, <a href=\"/tag/ollama%20serve\" rel=\"tag\">ollama serve</a>, <a href=\"/tag/ollama%EB%A6%AC%EB%88%85%EC%8A%A4\" rel=\"tag\">ollama리눅스</a></div>\n",
       "</div>\n",
       "</aside>\n",
       "<div data-react-app=\"Supporters\"></div>\n",
       "<aside class=\"content-aside cont_blog_info\">\n",
       "<h3 class=\"screen_out\">블로그 정보</h3>\n",
       "<div class=\"box_blog_info\">\n",
       "<strong class=\"tit_blog\"><a href=\"/m\">남디윤 로그 데이터</a></strong>\n",
       "<p class=\"desc_blog\"><a href=\"/m\">데이터사이언티스트를 꿈꾸는 대학원생</a></p>\n",
       "<div data-react-app=\"Subscribe\"></div>\n",
       "<div class=\"thumb_g\">\n",
       "<a href=\"/m\">\n",
       "<img alt=\"프로필 사진\" class=\"thumb_profile\" src=\"https://img1.daumcdn.net/thumb/S56x56/?scode=mtistory2&amp;fname=https://tistory1.daumcdn.net/tistory/5489331/attach/b6d3fd5087eb4ffaa8fe57e9f134bd06\"/>\n",
       "</a>\n",
       "</div>\n",
       "</div>\n",
       "</aside>\n",
       "<div data-react-app=\"CategoryRelated\"></div>\n",
       "<div id=\"story-contents-box-root-container\"></div>\n",
       "<div data-react-app=\"SearchKeyword\"></div>\n",
       "<div data-react-app=\"Popular\"></div>\n",
       "<footer class=\"doc-footer\">\n",
       "<div class=\"inner_foot\">\n",
       "<div class=\"wrap_etc\"><strong class=\"screen_out\">문의안내</strong>\n",
       "<ul class=\"list_etcinfo\">\n",
       "<li><a class=\"link_txt\" href=\"https://tistory.com/m\" id=\"tistory-home-link\">티스토리</a></li>\n",
       "<li><a class=\"link_txt\" href=\"#\" id=\"login-link\">로그인</a></li>\n",
       "<li><a class=\"link_txt\" href=\"https://cs.kakao.com/requests?service=175&amp;locale=ko\">고객센터</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<p class=\"desc_g\">티스토리는 카카오에서 <span class=\"ico_heart\">사랑</span>을 담아 만듭니다.</p>\n",
       "<small><a class=\"link_corp\" href=\"https://www.kakaocorp.com/\" target=\"_blank\">©\n",
       "                                    Kakao Corp.</a></small>\n",
       "</div>\n",
       "</footer>\n",
       "</div>\n",
       "</section>\n",
       "</main>\n",
       "</div>\n",
       "<div class=\"bottomBar\" data-react-app=\"BottomBar\"></div>\n",
       "<div class=\"StoryBanner\" data-react-app=\"StoryBanner\"></div>\n",
       "<!-- 공지사항 본문 -->\n",
       "<!-- 보호글 본문 -->\n",
       "<!-- SyntaxHighlight - START -->\n",
       "<link href=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/styles/darcula.min.css\" rel=\"stylesheet\"/><script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/highlight.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/delphi.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/php.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/python.min.js\"></script>\n",
       "<script defer=\"\" src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/r.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/ruby.min.js\"></script>\n",
       "<script defer=\"\" src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/scala.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/shell.min.js\"></script>\n",
       "<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/sql.min.js\"></script>\n",
       "<script defer=\"\" src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/swift.min.js\"></script>\n",
       "<script defer=\"\" src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/typescript.min.js\"></script>\n",
       "<script defer=\"\" src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/languages/vbnet.min.js\"></script>\n",
       "<script>hljs.initHighlightingOnLoad();</script>\n",
       "<!-- SyntaxHighlight - END -->\n",
       "<script>window.tiara = {\"svcDomain\":\"user.tistory.com\",\"section\":\"글뷰\",\"trackPage\":\"글뷰_보기\",\"page\":\"글뷰\",\"key\":\"5489331-81\",\"customProps\":{\"userId\":\"0\",\"blogId\":\"5489331\",\"entryId\":\"81\",\"role\":\"guest\",\"trackPage\":\"글뷰_보기\",\"filterTarget\":false},\"entry\":{\"entryId\":\"81\",\"entryTitle\":\"Ollama를 이용해서 llama3.1 8B(양자화 모델)을 리눅스 서버에서 사용하기 (feat. 테디노트)\",\"entryType\":\"POST\",\"categoryName\":\"Development/etc.\",\"categoryId\":\"1132962\",\"serviceCategoryName\":\"IT 인터넷\",\"serviceCategoryId\":401,\"author\":\"5486686\",\"authorNickname\":\"남디윤\",\"blogNmae\":\"남디윤 로그 데이터\",\"image\":\"kage@b6zeF5/btsIUjIPcEJ/RkkgJA6YFVA1j0Mg9bUrV1\",\"plink\":\"/m/81\",\"tags\":[\"llama\",\"llama3.1\",\"llama리눅스\",\"llama리눅스서버\",\"ollama\",\"ollama serve\",\"ollama리눅스\"]},\"kakaoAppKey\":\"3e6ddd834b023f24221217e370daed18\",\"appUserId\":\"null\"}</script>\n",
       "<script src=\"https://t1.daumcdn.net/tistory_admin/frontend/tiara/v1.0.5/index.js\" type=\"module\"></script>\n",
       "<script defer=\"true\" nomodule=\"true\" src=\"https://t1.daumcdn.net/tistory_admin/frontend/tiara/v1.0.5/polyfills-legacy.js\"></script>\n",
       "<script defer=\"true\" nomodule=\"true\" src=\"https://t1.daumcdn.net/tistory_admin/frontend/tiara/v1.0.5/index-legacy.js\"></script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sleep',\n",
       " 'wolfram-alpha',\n",
       " 'google-search',\n",
       " 'google-search-results-json',\n",
       " 'searx-search-results-json',\n",
       " 'bing-search',\n",
       " 'metaphor-search',\n",
       " 'ddg-search',\n",
       " 'google-lens',\n",
       " 'google-serper',\n",
       " 'google-scholar',\n",
       " 'google-finance',\n",
       " 'google-trends',\n",
       " 'google-jobs',\n",
       " 'google-serper-results-json',\n",
       " 'searchapi',\n",
       " 'searchapi-results-json',\n",
       " 'serpapi',\n",
       " 'dalle-image-generator',\n",
       " 'twilio',\n",
       " 'searx-search',\n",
       " 'merriam-webster',\n",
       " 'wikipedia',\n",
       " 'arxiv',\n",
       " 'golden-query',\n",
       " 'pubmed',\n",
       " 'human',\n",
       " 'awslambda',\n",
       " 'stackexchange',\n",
       " 'sceneXplain',\n",
       " 'graphql',\n",
       " 'openweathermap-api',\n",
       " 'dataforseo-api-search',\n",
       " 'dataforseo-api-search-json',\n",
       " 'eleven_labs_text2speech',\n",
       " 'google_cloud_texttospeech',\n",
       " 'read_file',\n",
       " 'reddit_search',\n",
       " 'news-api',\n",
       " 'tmdb-api',\n",
       " 'podcast-api',\n",
       " 'memorize',\n",
       " 'llm-math',\n",
       " 'open-meteo-api',\n",
       " 'requests',\n",
       " 'requests_get',\n",
       " 'requests_post',\n",
       " 'requests_patch',\n",
       " 'requests_put',\n",
       " 'requests_delete',\n",
       " 'terminal']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.load_tools import load_tools, get_all_tool_names\n",
    "from typing import List\n",
    "\n",
    "# def get_all_tool_names() -> List[str]:\n",
    "#     \"\"\"Get a list of all possible tool names.\"\"\"\n",
    "#     return (\n",
    "#         list(_BASE_TOOLS)\n",
    "#         + list(_EXTRA_OPTIONAL_TOLLS)\n",
    "#         + list(_EXTRA_LLM_TOOLS)\n",
    "#         + list(_LLM_TOOLS)\n",
    "#         + list(DANGEROUS_TOOLS)\n",
    "#     )\n",
    "tools = get_all_tool_names()\n",
    "tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
