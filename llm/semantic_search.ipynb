{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nChapter 2: Launching an Application with Proprietary MOdels\\n    Overview of Proprietary Models\\n    Introduction to OpenAI + Embeddings / GPT3 / ChatGPT\\n    Introduction to Vector Databases\\n    Building a Neural/Semantic information retrieval system with vector databases, BERT & GPT3\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Chapter 2: Launching an Application with Proprietary MOdels\n",
    "    Overview of Proprietary Models\n",
    "    Introduction to OpenAI + Embeddings / GPT3 / ChatGPT\n",
    "    Introduction to Vector Databases\n",
    "    Building a Neural/Semantic information retrieval system with vector databases, BERT & GPT3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, timezone\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import keyring\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_key = keyring.get_password('pinecone', 'ahn283')\n",
    "openai_api_key = keyring.get_password('openai', 'key_for_windows')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "INDEX_NAME = 'semantic-search'\n",
    "NAMESPACE = 'default'\n",
    "ENGINE = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import Pinecone       # !pip install pinecone-client\n",
    "# from pinecone import ServerlessSpec\n",
    "# https://docs.pinecone.io/guides/get-started/quickstart\n",
    "\n",
    "from pinecone import Pinecone \n",
    "from pinecone import ServerlessSpec, PodSpec\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=pinecone_key, \n",
    "    # environment='us-west1-gcp'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper functions to get lists of embeddings from the OpenAI API\n",
    "def get_embeddings(texts, engine=ENGINE):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=engine\n",
    "    )\n",
    "    \n",
    "    return [d.embedding for d in list(response.data)]\n",
    "\n",
    "def get_embedding(text):\n",
    "    return get_embeddings([text])[0]\n",
    "\n",
    "\n",
    "len(get_embedding('hi')), len(get_embeddings(['hi','hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1536,), (2, 1536))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(get_embedding('hi')).shape, np.array(get_embeddings(['hi', 'hello'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INDEX_NAME in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,         # the name of the index\n",
    "        dimension=1536,     # The dimensionality of the vectors\n",
    "        metric='cosine',    # The similarity metric to use when searching the index\n",
    "        # pod_type = 'p1'     # the type of Pinecone pod  # deprecated\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "        # spec=PodSpec(\n",
    "        #     environment='us-west1-gcp',\n",
    "        #     pod_type='p1.x1',\n",
    "        #     pods=1\n",
    "        # )\n",
    "    )\n",
    "    \n",
    "# store the index as a variable\n",
    "index = pc.Index(INDEX_NAME)      # resource already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27c3e2ecf64fd7081f80bc0837dfbeb8'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_hash(s):\n",
    "    # return the WD5 hash of the input string as a hexadecimal string\n",
    "    return hashlib.md5(s.encode()).hexdigest()\n",
    "\n",
    "my_hash('I love to hash it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_pinecone(texts, engine=ENGINE):\n",
    "    # get the current UTC date and time\n",
    "    now = datetime.now(timezone.utc)\n",
    "    \n",
    "    # generate vector embeddings for each string in the input list, using the specified engine\n",
    "    embeddings = get_embeddings(texts, engine=engine)\n",
    "    \n",
    "    # create tuples of (hash, embedding, metadata) for each input string and its corresponding vector embedding\n",
    "    # The my_hash() function is used to generate a unique hash for each string, and the datetime.utcnow() function is used to generate the current UTC date and time\n",
    "    return [\n",
    "        (\n",
    "            my_hash(text),      # A unique 1D for each string, generated using the my_hash() function\n",
    "            embedding,          # the vector embedding of the string\n",
    "            dict(text=text, date_upload=now)    # a dictionary of metadata, including the original text and the current UTC date and time\n",
    "        )\n",
    "        for text, embedding in zip(texts, embeddings)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('49f68a5c8493ec2c0bf489821c21fc3b',\n",
       " [-0.030913319438695908,\n",
       "  -0.020414210855960846,\n",
       "  -0.019505759701132774,\n",
       "  -0.04178878664970398,\n",
       "  -0.024813713505864143,\n",
       "  0.024307576939463615,\n",
       "  -0.0179743692278862,\n",
       "  -0.017701834440231323,\n",
       "  -0.0065019200555980206,\n",
       "  -0.015910886228084564,\n",
       "  0.025890879333019257,\n",
       "  -0.006949656642973423,\n",
       "  -0.01790948025882244,\n",
       "  -0.011848808266222477,\n",
       "  0.011465960182249546,\n",
       "  0.01648191176354885,\n",
       "  0.038751959800720215,\n",
       "  0.0005187098286114633,\n",
       "  0.03221110627055168,\n",
       "  -0.008701670914888382,\n",
       "  -0.019635537639260292,\n",
       "  -0.0049056401476264,\n",
       "  -0.009298654273152351,\n",
       "  -0.014327583834528923,\n",
       "  -0.022867031395435333,\n",
       "  0.002483642427250743,\n",
       "  0.010051371529698372,\n",
       "  -0.01176445186138153,\n",
       "  0.0026069325394928455,\n",
       "  -0.026020657271146774,\n",
       "  0.014535229653120041,\n",
       "  0.0006987779634073377,\n",
       "  -0.035767048597335815,\n",
       "  -0.014963500201702118,\n",
       "  -0.009486833587288857,\n",
       "  -0.024748824536800385,\n",
       "  0.006988590583205223,\n",
       "  -0.02111501805484295,\n",
       "  0.01918131299316883,\n",
       "  -0.005687557626515627,\n",
       "  0.006128805689513683,\n",
       "  -0.0007223003776744008,\n",
       "  0.0014072892954573035,\n",
       "  -0.014392473734915257,\n",
       "  -0.023022765293717384,\n",
       "  -0.0060898722149431705,\n",
       "  0.0009684746037237346,\n",
       "  0.004071811214089394,\n",
       "  -0.012361434288322926,\n",
       "  0.01984318532049656,\n",
       "  0.015897907316684723,\n",
       "  0.007066457998007536,\n",
       "  -0.02974531054496765,\n",
       "  -0.01138809323310852,\n",
       "  -0.02006380818784237,\n",
       "  -0.007630995940417051,\n",
       "  -0.01513221301138401,\n",
       "  0.011238847859203815,\n",
       "  -0.010551019571721554,\n",
       "  -0.022659385576844215,\n",
       "  -0.010771643370389938,\n",
       "  0.005499378312379122,\n",
       "  -0.004879684187471867,\n",
       "  0.006060671992599964,\n",
       "  0.010421240702271461,\n",
       "  -0.008461580611765385,\n",
       "  0.023567836731672287,\n",
       "  -0.0010195750510320067,\n",
       "  0.00443843612447381,\n",
       "  0.0007908397819846869,\n",
       "  0.02142648585140705,\n",
       "  0.033820364624261856,\n",
       "  -0.004989996552467346,\n",
       "  -0.014249716885387897,\n",
       "  0.012062943540513515,\n",
       "  -0.007326015271246433,\n",
       "  -0.003565673716366291,\n",
       "  -0.00121748773381114,\n",
       "  -0.006187206134200096,\n",
       "  -0.00689125619828701,\n",
       "  0.025138162076473236,\n",
       "  -0.03138052299618721,\n",
       "  -0.016001731157302856,\n",
       "  0.017481209710240364,\n",
       "  0.008312334306538105,\n",
       "  0.016793381422758102,\n",
       "  -0.005077597219496965,\n",
       "  0.012854593805968761,\n",
       "  -0.01565132848918438,\n",
       "  -0.031873684376478195,\n",
       "  0.006398096680641174,\n",
       "  0.022996811196208,\n",
       "  0.013574866577982903,\n",
       "  0.01382144633680582,\n",
       "  -0.01108311302959919,\n",
       "  0.018324771896004677,\n",
       "  -0.011569783091545105,\n",
       "  0.01849348470568657,\n",
       "  -0.007403882686048746,\n",
       "  0.006284540519118309,\n",
       "  0.0008086843881756067,\n",
       "  0.008870383724570274,\n",
       "  0.0013967447448521852,\n",
       "  -0.005502622574567795,\n",
       "  -0.027902450412511826,\n",
       "  -0.020647812634706497,\n",
       "  -0.017416320741176605,\n",
       "  -0.01382144633680582,\n",
       "  0.016806360334157944,\n",
       "  -0.0015021900180727243,\n",
       "  -0.002910290379077196,\n",
       "  0.036519765853881836,\n",
       "  0.005548045504838228,\n",
       "  -0.034261614084243774,\n",
       "  -0.010401774197816849,\n",
       "  -0.007955443114042282,\n",
       "  0.0032201374415308237,\n",
       "  -0.0034066946245729923,\n",
       "  -0.0122056994587183,\n",
       "  -0.023204457014799118,\n",
       "  0.0045455037616193295,\n",
       "  0.0002054155629593879,\n",
       "  0.01550857163965702,\n",
       "  0.003345049684867263,\n",
       "  0.015690261498093605,\n",
       "  0.008072244003415108,\n",
       "  -0.02404801920056343,\n",
       "  -0.0052430653013288975,\n",
       "  0.0075790840201079845,\n",
       "  0.005009463056921959,\n",
       "  0.04817390441894531,\n",
       "  0.011751473881304264,\n",
       "  0.005191153381019831,\n",
       "  -0.007209214381873608,\n",
       "  -0.03356080874800682,\n",
       "  0.035403668880462646,\n",
       "  -0.024891581386327744,\n",
       "  0.02307467721402645,\n",
       "  -0.02397015132009983,\n",
       "  -0.032392799854278564,\n",
       "  -0.0056616016663610935,\n",
       "  0.03828475624322891,\n",
       "  -7.472422294085845e-05,\n",
       "  -0.017403341829776764,\n",
       "  -0.01382144633680582,\n",
       "  -0.01344508770853281,\n",
       "  0.015106257051229477,\n",
       "  -0.0029313794802874327,\n",
       "  -0.0014948899624869227,\n",
       "  -0.002105661667883396,\n",
       "  0.0015938463620841503,\n",
       "  0.0018509706715121865,\n",
       "  0.020102743059396744,\n",
       "  -0.0005466933362185955,\n",
       "  0.029304061084985733,\n",
       "  0.02067376859486103,\n",
       "  -0.012945439666509628,\n",
       "  -0.010765154846012592,\n",
       "  -0.010914400219917297,\n",
       "  -0.008760071359574795,\n",
       "  -0.0008090899791568518,\n",
       "  -0.003038447117432952,\n",
       "  0.023801438510417938,\n",
       "  -0.01062888652086258,\n",
       "  -0.003760341787710786,\n",
       "  0.01766289956867695,\n",
       "  0.01227707788348198,\n",
       "  0.027357378974556923,\n",
       "  0.012841615825891495,\n",
       "  -0.0018379928078502417,\n",
       "  0.013354242779314518,\n",
       "  0.019635537639260292,\n",
       "  -0.03039420396089554,\n",
       "  0.00531768798828125,\n",
       "  0.00046436491538770497,\n",
       "  0.01105066854506731,\n",
       "  0.015768129378557205,\n",
       "  0.01362677849829197,\n",
       "  -0.03042015992105007,\n",
       "  -0.04404693841934204,\n",
       "  -0.015313902869820595,\n",
       "  0.017351431772112846,\n",
       "  0.03273022174835205,\n",
       "  0.02958957478404045,\n",
       "  -0.009233764372766018,\n",
       "  0.014314605854451656,\n",
       "  0.029823176562786102,\n",
       "  0.004863461945205927,\n",
       "  0.01662466861307621,\n",
       "  -0.020258476957678795,\n",
       "  0.01550857163965702,\n",
       "  0.02899259328842163,\n",
       "  0.01685827039182186,\n",
       "  -0.006527875550091267,\n",
       "  -0.7010133862495422,\n",
       "  -0.031198833137750626,\n",
       "  -0.0045455037616193295,\n",
       "  -0.0019061267375946045,\n",
       "  0.020725680515170097,\n",
       "  0.043112531304359436,\n",
       "  0.026760397478938103,\n",
       "  0.021452441811561584,\n",
       "  -0.018259882926940918,\n",
       "  0.01596279814839363,\n",
       "  -0.007864597253501415,\n",
       "  -0.004506570287048817,\n",
       "  0.008247445337474346,\n",
       "  -0.014859677292406559,\n",
       "  0.005625912919640541,\n",
       "  0.007423349656164646,\n",
       "  -0.00034290002076886594,\n",
       "  -0.007494728080928326,\n",
       "  -0.011238847859203815,\n",
       "  0.002081328071653843,\n",
       "  -0.004146433901041746,\n",
       "  -0.003916076384484768,\n",
       "  -0.023399123921990395,\n",
       "  0.020777592435479164,\n",
       "  0.00929216481745243,\n",
       "  -0.005486400332301855,\n",
       "  -0.0022484182845801115,\n",
       "  -0.009298654273152351,\n",
       "  -0.019544692710042,\n",
       "  0.010239550843834877,\n",
       "  -0.013717623427510262,\n",
       "  0.011985075660049915,\n",
       "  0.012017520144581795,\n",
       "  -0.01029795128852129,\n",
       "  0.05985400080680847,\n",
       "  0.005129508674144745,\n",
       "  -0.004292435012757778,\n",
       "  0.020388254895806313,\n",
       "  0.006495431065559387,\n",
       "  0.049160223454236984,\n",
       "  -0.0007113502360880375,\n",
       "  -0.019337046891450882,\n",
       "  0.005252798553556204,\n",
       "  0.006274806801229715,\n",
       "  0.005768669303506613,\n",
       "  0.016871249303221703,\n",
       "  -0.009078029543161392,\n",
       "  -0.0015313903568312526,\n",
       "  0.009512788616120815,\n",
       "  -0.0009911858942359686,\n",
       "  0.010804088786244392,\n",
       "  -0.006703076884150505,\n",
       "  -0.012328989803791046,\n",
       "  0.018843887373805046,\n",
       "  0.00932460930198431,\n",
       "  -0.0027302224189043045,\n",
       "  0.02194560132920742,\n",
       "  -0.024385444819927216,\n",
       "  -0.005960093345493078,\n",
       "  0.02397015132009983,\n",
       "  0.00038690317887812853,\n",
       "  0.003088736440986395,\n",
       "  -0.01415887102484703,\n",
       "  -0.019233224913477898,\n",
       "  -0.013977181166410446,\n",
       "  0.01977829448878765,\n",
       "  -0.02195858024060726,\n",
       "  -0.009603634476661682,\n",
       "  -0.0008897961815819144,\n",
       "  -0.005937382113188505,\n",
       "  -0.013081707060337067,\n",
       "  0.019337046891450882,\n",
       "  -0.027435246855020523,\n",
       "  -0.016352133825421333,\n",
       "  0.002018061000853777,\n",
       "  0.02389228530228138,\n",
       "  0.012393878772854805,\n",
       "  -0.0060704052448272705,\n",
       "  -0.009142919443547726,\n",
       "  0.010070838034152985,\n",
       "  0.0013204996939748526,\n",
       "  -0.0024138863664120436,\n",
       "  -0.005505867302417755,\n",
       "  -0.011498405598104,\n",
       "  0.02419077605009079,\n",
       "  -0.026487860828638077,\n",
       "  -0.03363867476582527,\n",
       "  0.014366517774760723,\n",
       "  -0.0067290328443050385,\n",
       "  -0.0025631319731473923,\n",
       "  0.005489645060151815,\n",
       "  0.035844914615154266,\n",
       "  0.013062240555882454,\n",
       "  -0.020349321886897087,\n",
       "  0.006167739164084196,\n",
       "  0.009454388171434402,\n",
       "  -0.02051803469657898,\n",
       "  0.0029265128541737795,\n",
       "  -0.0032428486738353968,\n",
       "  -0.012711836956441402,\n",
       "  -0.007877575233578682,\n",
       "  0.0029394906014204025,\n",
       "  -0.0016603580443188548,\n",
       "  -0.0056388904340565205,\n",
       "  0.01670253649353981,\n",
       "  -0.003903098637238145,\n",
       "  -0.014444384723901749,\n",
       "  0.03984210267663002,\n",
       "  0.027513114735484123,\n",
       "  -0.020427189767360687,\n",
       "  -0.00248039816506207,\n",
       "  -0.001167198410257697,\n",
       "  -0.00781917478889227,\n",
       "  0.005408532917499542,\n",
       "  0.008240955881774426,\n",
       "  -0.03301573544740677,\n",
       "  -0.012121343985199928,\n",
       "  0.031562212854623795,\n",
       "  0.021608177572488785,\n",
       "  -0.015210079960525036,\n",
       "  0.005330665968358517,\n",
       "  -0.0036662521306425333,\n",
       "  0.02103715017437935,\n",
       "  -0.01648191176354885,\n",
       "  0.0014567674370482564,\n",
       "  0.01858432963490486,\n",
       "  -0.010447196662425995,\n",
       "  -0.0035624292213469744,\n",
       "  -0.031640082597732544,\n",
       "  0.007890553213655949,\n",
       "  0.013899313285946846,\n",
       "  -0.01138809323310852,\n",
       "  0.017792679369449615,\n",
       "  -0.020569946616888046,\n",
       "  0.014210782945156097,\n",
       "  -0.005976315587759018,\n",
       "  0.0012239767238497734,\n",
       "  -0.010797599330544472,\n",
       "  -0.00816957838833332,\n",
       "  -0.005165197886526585,\n",
       "  -0.002081328071653843,\n",
       "  0.0046915048733353615,\n",
       "  0.00011284675565548241,\n",
       "  -0.004626615438610315,\n",
       "  0.0019872384145855904,\n",
       "  -0.032237064093351364,\n",
       "  -0.0197004284709692,\n",
       "  -0.005090575199574232,\n",
       "  -0.01269885990768671,\n",
       "  0.004947818350046873,\n",
       "  0.0006780944531783462,\n",
       "  -0.0018574596615508199,\n",
       "  -0.010849511250853539,\n",
       "  0.018778998404741287,\n",
       "  0.03550748899579048,\n",
       "  -0.022049425169825554,\n",
       "  -0.0035040287766605616,\n",
       "  -0.021283729001879692,\n",
       "  -0.011303736828267574,\n",
       "  -2.144392601621803e-05,\n",
       "  0.003455361584201455,\n",
       "  0.022490672767162323,\n",
       "  -0.014937544241547585,\n",
       "  0.0020277942530810833,\n",
       "  0.0017763478681445122,\n",
       "  -0.027616936713457108,\n",
       "  -0.0016506245592609048,\n",
       "  0.023412102833390236,\n",
       "  0.0030546693596988916,\n",
       "  -0.038310714066028595,\n",
       "  0.01722165197134018,\n",
       "  -0.015833018347620964,\n",
       "  -0.006164494901895523,\n",
       "  0.0026945332065224648,\n",
       "  0.017779700458049774,\n",
       "  0.006167739164084196,\n",
       "  -0.0074493056163191795,\n",
       "  0.007462283130735159,\n",
       "  -0.001555723836645484,\n",
       "  -0.032911915332078934,\n",
       "  0.010771643370389938,\n",
       "  0.0021527064964175224,\n",
       "  -0.01066782046109438,\n",
       "  0.010129238478839397,\n",
       "  0.02105012722313404,\n",
       "  0.00805277656763792,\n",
       "  0.008870383724570274,\n",
       "  0.02560536563396454,\n",
       "  -0.01273130439221859,\n",
       "  0.010927378199994564,\n",
       "  0.007507706061005592,\n",
       "  0.020543990656733513,\n",
       "  -0.01714378409087658,\n",
       "  -0.0012961662141606212,\n",
       "  0.008208511397242546,\n",
       "  0.011329692788422108,\n",
       "  0.002527442993596196,\n",
       "  0.002790244994685054,\n",
       "  0.009201319888234138,\n",
       "  0.02389228530228138,\n",
       "  0.0420743003487587,\n",
       "  0.009441410191357136,\n",
       "  0.034339480102062225,\n",
       "  -0.011193424463272095,\n",
       "  -0.00970096793025732,\n",
       "  -0.026267237961292267,\n",
       "  0.001176120713353157,\n",
       "  -0.005703779868781567,\n",
       "  0.020543990656733513,\n",
       "  0.0162483099848032,\n",
       "  -0.005200887098908424,\n",
       "  -0.015249013900756836,\n",
       "  0.00868220441043377,\n",
       "  0.003932298626750708,\n",
       "  0.019142378121614456,\n",
       "  0.017727790400385857,\n",
       "  -0.008078732527792454,\n",
       "  0.012964906170964241,\n",
       "  -0.021024171262979507,\n",
       "  0.010343373753130436,\n",
       "  0.011933164671063423,\n",
       "  -0.011063646525144577,\n",
       "  0.014145893976092339,\n",
       "  -0.00013180663518141955,\n",
       "  0.004899151157587767,\n",
       "  0.016196399927139282,\n",
       "  0.023996107280254364,\n",
       "  0.033820364624261856,\n",
       "  0.013315308839082718,\n",
       "  -0.008351268246769905,\n",
       "  -0.0016490024281665683,\n",
       "  -0.0036824746057391167,\n",
       "  0.008669226430356503,\n",
       "  0.004665549378842115,\n",
       "  -0.00846806913614273,\n",
       "  0.0025712433271110058,\n",
       "  0.0013480776688084006,\n",
       "  -0.025267940014600754,\n",
       "  0.026228303089737892,\n",
       "  -0.010888444259762764,\n",
       "  0.0026653329841792583,\n",
       "  0.02756502479314804,\n",
       "  0.02920023910701275,\n",
       "  -0.026916131377220154,\n",
       "  0.00689125619828701,\n",
       "  0.019726384431123734,\n",
       "  0.009798302315175533,\n",
       "  0.0041561671532690525,\n",
       "  0.01918131299316883,\n",
       "  0.02524198405444622,\n",
       "  0.006323473993688822,\n",
       "  0.011180447414517403,\n",
       "  -0.0015808684984222054,\n",
       "  0.005960093345493078,\n",
       "  0.01849348470568657,\n",
       "  -0.004811550490558147,\n",
       "  -0.016832316294312477,\n",
       "  0.004798572510480881,\n",
       "  0.009123452007770538,\n",
       "  0.01828583888709545,\n",
       "  0.004415724892169237,\n",
       "  0.01841561682522297,\n",
       "  0.015158168040215969,\n",
       "  -0.023801438510417938,\n",
       "  0.018597308546304703,\n",
       "  0.0008881739340722561,\n",
       "  -0.005084086209535599,\n",
       "  0.0021754177287220955,\n",
       "  0.00823446735739708,\n",
       "  0.0009782080305740237,\n",
       "  -0.00529822101816535,\n",
       "  -0.0025971990544348955,\n",
       "  0.026786351576447487,\n",
       "  -0.016819337382912636,\n",
       "  0.031717948615550995,\n",
       "  0.013055751100182533,\n",
       "  -0.0008751960704103112,\n",
       "  0.0016084464732557535,\n",
       "  0.0005284431972540915,\n",
       "  -0.010122749954462051,\n",
       "  -0.020842481404542923,\n",
       "  -0.03480668365955353,\n",
       "  0.015599416568875313,\n",
       "  0.010505597107112408,\n",
       "  -0.004704482853412628,\n",
       "  -0.023554859682917595,\n",
       "  -0.03916725516319275,\n",
       "  0.008935272693634033,\n",
       "  0.009052074514329433,\n",
       "  0.006119072437286377,\n",
       "  -0.004779105540364981,\n",
       "  0.022815119475126266,\n",
       "  0.030316336080431938,\n",
       "  -0.02246471680700779,\n",
       "  0.0020699724555015564,\n",
       "  0.0020245499908924103,\n",
       "  0.03929703310132027,\n",
       "  -0.0077218408696353436,\n",
       "  0.0012004543095827103,\n",
       "  0.007780241314321756,\n",
       "  0.000997674884274602,\n",
       "  0.004178878851234913,\n",
       "  0.005486400332301855,\n",
       "  -0.005307954736053944,\n",
       "  -0.005973071325570345,\n",
       "  0.017507165670394897,\n",
       "  -0.008299357257783413,\n",
       "  -0.021153951063752174,\n",
       "  -0.007397393696010113,\n",
       "  0.016365110874176025,\n",
       "  -0.0041756341233849525,\n",
       "  0.03275617957115173,\n",
       "  -0.009493322111666203,\n",
       "  0.01523603592067957,\n",
       "  0.0005134375533089042,\n",
       "  0.007689396385103464,\n",
       "  -0.009259720332920551,\n",
       "  -0.002154328627511859,\n",
       "  0.02007678709924221,\n",
       "  -0.010551019571721554,\n",
       "  -0.02547558583319187,\n",
       "  -0.008584870025515556,\n",
       "  -0.018337750807404518,\n",
       "  -0.0015338236698880792,\n",
       "  0.054039910435676575,\n",
       "  0.022049425169825554,\n",
       "  -0.006132049951702356,\n",
       "  0.0018055480904877186,\n",
       "  0.010875467211008072,\n",
       "  0.01931109093129635,\n",
       "  -0.00021352674230001867,\n",
       "  -0.014223760925233364,\n",
       "  -0.013276374898850918,\n",
       "  -0.014392473734915257,\n",
       "  0.010213594883680344,\n",
       "  -0.017429297789931297,\n",
       "  -0.01358784455806017,\n",
       "  0.003721408313140273,\n",
       "  0.004526037257164717,\n",
       "  0.001683880458585918,\n",
       "  0.02023252099752426,\n",
       "  -0.006806900259107351,\n",
       "  0.01258854754269123,\n",
       "  -0.0029021792579442263,\n",
       "  -0.006355918478220701,\n",
       "  0.0028843346517533064,\n",
       "  0.011589250527322292,\n",
       "  0.025813011452555656,\n",
       "  0.015365814790129662,\n",
       "  0.012011031620204449,\n",
       "  0.022802142426371574,\n",
       "  0.018921755254268646,\n",
       "  0.010213594883680344,\n",
       "  -0.026020657271146774,\n",
       "  -0.008526469580829144,\n",
       "  -0.0023554859217256308,\n",
       "  0.013613800518214703,\n",
       "  0.006352674216032028,\n",
       "  -0.0011469204910099506,\n",
       "  0.02772076055407524,\n",
       "  -0.010966312140226364,\n",
       "  0.010518575087189674,\n",
       "  0.022503651678562164,\n",
       "  -0.012218677438795567,\n",
       "  0.006800411269068718,\n",
       "  0.016949117183685303,\n",
       "  0.00535337720066309,\n",
       "  -0.01701400615274906,\n",
       "  0.018091170117259026,\n",
       "  -0.01938895881175995,\n",
       "  -0.019648516550660133,\n",
       "  0.0323408879339695,\n",
       "  -0.009791813790798187,\n",
       "  -0.009188341908156872,\n",
       "  0.028499433770775795,\n",
       "  0.000983074656687677,\n",
       "  -0.01610555313527584,\n",
       "  -0.010505597107112408,\n",
       "  -0.001756881014443934,\n",
       "  0.006024982780218124,\n",
       "  -0.02015465311706066,\n",
       "  -0.011316714808344841,\n",
       "  -0.009136429987847805,\n",
       "  0.007663440424948931,\n",
       "  -0.010862489230930805,\n",
       "  -0.02014167606830597,\n",
       "  0.007728329859673977,\n",
       "  -0.00649867532774806,\n",
       "  -0.028369653970003128,\n",
       "  -0.03192559629678726,\n",
       "  -0.027616936713457108,\n",
       "  -0.011809874325990677,\n",
       "  -0.015677284449338913,\n",
       "  0.00368896359577775,\n",
       "  -0.016144488006830215,\n",
       "  -0.0013383443001657724,\n",
       "  -0.01194614265114069,\n",
       "  -0.005603201221674681,\n",
       "  0.001844481797888875,\n",
       "  0.01737738586962223,\n",
       "  0.004860217683017254,\n",
       "  -0.013756557367742062,\n",
       "  0.024437354877591133,\n",
       "  0.007066457998007536,\n",
       "  -0.012264099903404713,\n",
       "  -0.03054993972182274,\n",
       "  0.002128372900187969,\n",
       "  -0.01835072785615921,\n",
       "  0.0131076630204916,\n",
       "  0.009869680739939213,\n",
       "  -0.009597145020961761,\n",
       "  -0.0048861731775105,\n",
       "  -0.008734116330742836,\n",
       "  0.0008297734311781824,\n",
       "  0.02560536563396454,\n",
       "  0.01100524514913559,\n",
       "  0.01094035618007183,\n",
       "  -0.008623803965747356,\n",
       "  0.0027350890450179577,\n",
       "  -0.012893527746200562,\n",
       "  0.01918131299316883,\n",
       "  0.0002557048574090004,\n",
       "  -0.01111555751413107,\n",
       "  -0.015002434141933918,\n",
       "  0.003945276606827974,\n",
       "  0.0028210675809532404,\n",
       "  -0.0028843346517533064,\n",
       "  -0.010946844704449177,\n",
       "  0.01588493026793003,\n",
       "  0.0017731033731251955,\n",
       "  0.011660628952085972,\n",
       "  0.009110474959015846,\n",
       "  -0.018454551696777344,\n",
       "  -0.011465960182249546,\n",
       "  0.033508896827697754,\n",
       "  -0.010518575087189674,\n",
       "  0.010810577310621738,\n",
       "  -0.0005235765129327774,\n",
       "  -0.0014462228864431381,\n",
       "  0.017169740051031113,\n",
       "  0.003883631667122245,\n",
       "  0.026384038850665092,\n",
       "  0.0004874817677773535,\n",
       "  -0.03519602119922638,\n",
       "  0.008305845782160759,\n",
       "  -0.0395565889775753,\n",
       "  0.03010869026184082,\n",
       "  -0.004208079073578119,\n",
       "  0.007676418405026197,\n",
       "  0.0033109826035797596,\n",
       "  0.014431406743824482,\n",
       "  -0.01074568834155798,\n",
       "  -0.003491050796583295,\n",
       "  0.001743903150781989,\n",
       "  -0.007215703371912241,\n",
       "  0.021102039143443108,\n",
       "  0.008967718109488487,\n",
       "  -0.015703240409493446,\n",
       "  -0.025800032541155815,\n",
       "  -0.01415887102484703,\n",
       "  -0.02712377719581127,\n",
       "  0.011699561960995197,\n",
       "  -0.00018027091573458165,\n",
       "  -0.027513114735484123,\n",
       "  -0.021011194214224815,\n",
       "  -0.01134915929287672,\n",
       "  0.002897312631830573,\n",
       "  -0.014171849004924297,\n",
       "  -0.023464014753699303,\n",
       "  -0.04360568895936012,\n",
       "  -0.011985075660049915,\n",
       "  0.009817768819630146,\n",
       "  -0.010233061388134956,\n",
       "  0.010382306762039661,\n",
       "  -0.00526253180578351,\n",
       "  0.0025469097308814526,\n",
       "  -0.02417779713869095,\n",
       "  -0.04046504199504852,\n",
       "  -0.007981399074196815,\n",
       "  -0.02689017541706562,\n",
       "  -0.01633915677666664,\n",
       "  0.0014008003054186702,\n",
       "  0.03402801230549812,\n",
       "  0.021699022501707077,\n",
       "  0.01850646175444126,\n",
       "  0.0014665009221062064,\n",
       "  0.0029865356627851725,\n",
       "  0.0008261234033852816,\n",
       "  0.017701834440231323,\n",
       "  0.016378089785575867,\n",
       "  -0.007916509173810482,\n",
       "  0.010758665390312672,\n",
       "  -0.017416320741176605,\n",
       "  0.022581517696380615,\n",
       "  0.03286000341176987,\n",
       "  0.020258476957678795,\n",
       "  0.0037311415653675795,\n",
       "  0.009603634476661682,\n",
       "  0.02201049029827118,\n",
       "  0.018311794847249985,\n",
       "  0.00246093119494617,\n",
       "  -0.012536635622382164,\n",
       "  -0.009480344131588936,\n",
       "  -0.036364030092954636,\n",
       "  -0.006145027931779623,\n",
       "  -0.010985778644680977,\n",
       "  -0.01149191614240408,\n",
       "  0.008189044892787933,\n",
       "  0.008299357257783413,\n",
       "  -0.009551722556352615,\n",
       "  0.0328080914914608,\n",
       "  0.01947980374097824,\n",
       "  0.037246525287628174,\n",
       "  0.00946736615151167,\n",
       "  0.021776888519525528,\n",
       "  0.004577948711812496,\n",
       "  0.028629211708903313,\n",
       "  0.016053643077611923,\n",
       "  0.016053643077611923,\n",
       "  0.016196399927139282,\n",
       "  -0.004182123113423586,\n",
       "  -0.008007354103028774,\n",
       "  -0.009564700536429882,\n",
       "  0.020349321886897087,\n",
       "  -0.0037149193231016397,\n",
       "  0.007624506950378418,\n",
       "  -0.020284432917833328,\n",
       "  0.009408965706825256,\n",
       "  -0.011783918365836143,\n",
       "  0.015742173418402672,\n",
       "  -0.006531120277941227,\n",
       "  -0.019505759701132774,\n",
       "  -0.015158168040215969,\n",
       "  -0.006232628598809242,\n",
       "  -0.01685827039182186,\n",
       "  -0.014574163593351841,\n",
       "  -0.001784458989277482,\n",
       "  -0.021984536200761795,\n",
       "  0.010778132826089859,\n",
       "  -0.01105066854506731,\n",
       "  -0.010719732381403446,\n",
       "  0.01766289956867695,\n",
       "  -0.018817931413650513,\n",
       "  -0.026176391169428825,\n",
       "  0.0015038122655823827,\n",
       "  -0.013256908394396305,\n",
       "  0.027824582532048225,\n",
       "  0.0003463472821749747,\n",
       "  0.014885633252561092,\n",
       "  0.01344508770853281,\n",
       "  -0.025813011452555656,\n",
       "  -0.020712703466415405,\n",
       "  -0.005732980091124773,\n",
       "  0.007351971231400967,\n",
       "  -0.003711674828082323,\n",
       "  0.018830910325050354,\n",
       "  -0.002933001844212413,\n",
       "  -0.0057848915457725525,\n",
       "  -0.021608177572488785,\n",
       "  0.008260423317551613,\n",
       "  -0.002420375356450677,\n",
       "  0.005035419017076492,\n",
       "  -0.015768129378557205,\n",
       "  0.013717623427510262,\n",
       "  0.018454551696777344,\n",
       "  -0.005294976755976677,\n",
       "  -0.020699724555015564,\n",
       "  -0.008448602631688118,\n",
       "  -0.02389228530228138,\n",
       "  0.008312334306538105,\n",
       "  0.007280592806637287,\n",
       "  0.004454658832401037,\n",
       "  -0.009162385948002338,\n",
       "  -0.009551722556352615,\n",
       "  -0.003802519990131259,\n",
       "  0.02637105993926525,\n",
       "  -0.026838263496756554,\n",
       "  0.017130807042121887,\n",
       "  0.021296707913279533,\n",
       "  -0.015923863276839256,\n",
       "  -0.011414049193263054,\n",
       "  0.007864597253501415,\n",
       "  -0.015352836810052395,\n",
       "  0.025553453713655472,\n",
       "  0.0020115720108151436,\n",
       "  0.017559077590703964,\n",
       "  -0.022347915917634964,\n",
       "  0.023619748651981354,\n",
       "  0.01579408533871174,\n",
       "  0.002525820629671216,\n",
       "  -0.020946305245161057,\n",
       "  -0.00017804033996071666,\n",
       "  -0.0011469204910099506,\n",
       "  0.029771266505122185,\n",
       "  -0.007566106505692005,\n",
       "  0.004483859054744244,\n",
       "  0.0006651165313087404,\n",
       "  0.011057157069444656,\n",
       "  0.010421240702271461,\n",
       "  -0.0018493484240025282,\n",
       "  -0.013328286819159985,\n",
       "  -0.022140270099043846,\n",
       "  -0.020466122776269913,\n",
       "  -0.0024966204073280096,\n",
       "  0.04241172596812248,\n",
       "  0.012108366005122662,\n",
       "  -0.019285134971141815,\n",
       "  -0.01344508770853281,\n",
       "  -0.021893689408898354,\n",
       "  -0.01932406984269619,\n",
       "  -0.03174390271306038,\n",
       "  0.006037960294634104,\n",
       "  0.0015411237254738808,\n",
       "  0.0018428595503792167,\n",
       "  -0.018675174564123154,\n",
       "  -0.02247769571840763,\n",
       "  0.0009392743231728673,\n",
       "  0.013730601407587528,\n",
       "  0.01587195135653019,\n",
       "  -0.008494025096297264,\n",
       "  -0.006858811713755131,\n",
       "  0.019337046891450882,\n",
       "  -0.02133564092218876,\n",
       "  0.009597145020961761,\n",
       "  -0.00485048396512866,\n",
       "  -0.0011947763850912452,\n",
       "  -0.04303466156125069,\n",
       "  0.019285134971141815,\n",
       "  -0.009408965706825256,\n",
       "  -0.015547504648566246,\n",
       "  0.009447899647057056,\n",
       "  -0.008403180167078972,\n",
       "  -0.03529984503984451,\n",
       "  -0.002287351991981268,\n",
       "  0.014444384723901749,\n",
       "  0.017585033550858498,\n",
       "  0.02193262428045273,\n",
       "  -0.00842913519591093,\n",
       "  0.023269345983862877,\n",
       "  0.008442113175988197,\n",
       "  -0.010129238478839397,\n",
       "  -0.0056583574041724205,\n",
       "  -0.025203051045536995,\n",
       "  0.006446763873100281,\n",
       "  -0.023476991802453995,\n",
       "  -0.002814578590914607,\n",
       "  -0.010888444259762764,\n",
       "  0.001679013716056943,\n",
       "  0.02717568911612034,\n",
       "  -0.014042070135474205,\n",
       "  0.019869139418005943,\n",
       "  -0.0038317202124744654,\n",
       "  -0.020323365926742554,\n",
       "  -0.019142378121614456,\n",
       "  -0.005625912919640541,\n",
       "  0.026409992948174477,\n",
       "  -0.014703942462801933,\n",
       "  0.024164820089936256,\n",
       "  0.001468934235163033,\n",
       "  -0.0106353759765625,\n",
       "  -0.016598714515566826,\n",
       "  0.008935272693634033,\n",
       "  0.0030222246423363686,\n",
       "  -0.00691072316840291,\n",
       "  0.0163261778652668,\n",
       "  0.006995079573243856,\n",
       "  -0.010453685186803341,\n",
       "  0.004337857943028212,\n",
       "  -0.005408532917499542,\n",
       "  -0.012614503502845764,\n",
       "  0.0034066946245729923,\n",
       "  -0.027746716514229774,\n",
       "  -0.010174660943448544,\n",
       "  0.006742010824382305,\n",
       "  -0.007098902482539415,\n",
       "  0.016040664166212082,\n",
       "  0.022503651678562164,\n",
       "  -0.030238470062613487,\n",
       "  -0.017559077590703964,\n",
       "  0.0021121506579220295,\n",
       "  -0.026760397478938103,\n",
       "  -0.007871086709201336,\n",
       "  -0.00013515249884221703,\n",
       "  0.013393175788223743,\n",
       "  0.027954362332820892,\n",
       "  0.009240253828465939,\n",
       "  -0.0021478398703038692,\n",
       "  0.014055048115551472,\n",
       "  0.003119558794423938,\n",
       "  0.014016115106642246,\n",
       "  -0.005632401444017887,\n",
       "  -0.010207105427980423,\n",
       "  0.005158708896487951,\n",
       "  -0.004425458610057831,\n",
       "  0.017117828130722046,\n",
       "  0.0024885092861950397,\n",
       "  -0.0357930026948452,\n",
       "  -0.025436652824282646,\n",
       "  0.01693613827228546,\n",
       "  -0.0017714811256155372,\n",
       "  -0.016287244856357574,\n",
       "  0.02006380818784237,\n",
       "  -0.0057848915457725525,\n",
       "  -0.008591359481215477,\n",
       "  -0.01519710198044777,\n",
       "  0.006349429953843355,\n",
       "  -0.00861082598567009,\n",
       "  -0.0018315038178116083,\n",
       "  0.011855296790599823,\n",
       "  -0.007708862889558077,\n",
       "  -3.067039142479189e-05,\n",
       "  0.019817229360342026,\n",
       "  -0.025592386722564697,\n",
       "  0.0020391501020640135,\n",
       "  -0.006505164317786694,\n",
       "  -0.003126047784462571,\n",
       "  -0.001990482909604907,\n",
       "  0.0006172605790197849,\n",
       "  -0.018480507656931877,\n",
       "  -0.004788839258253574,\n",
       "  0.015249013900756836,\n",
       "  -0.024294598028063774,\n",
       "  0.016352133825421333,\n",
       "  0.004636349156498909,\n",
       "  -0.021737955510616302,\n",
       "  0.03960850089788437,\n",
       "  -0.010739198885858059,\n",
       "  -0.00041346726357005537,\n",
       "  -0.021673066541552544,\n",
       "  0.003812253475189209,\n",
       "  -0.010466663166880608,\n",
       "  -0.011141513474285603,\n",
       "  0.022957876324653625,\n",
       "  -0.0011104202130809426,\n",
       "  -0.011362137272953987,\n",
       "  -0.019427891820669174,\n",
       "  -0.007124858442693949,\n",
       "  -0.029537664726376534,\n",
       "  -0.0025696209631860256,\n",
       "  -0.03345698490738869,\n",
       "  -0.005509111564606428,\n",
       "  -0.014548207633197308,\n",
       "  0.026993999257683754,\n",
       "  -0.006839344743639231,\n",
       "  -0.003546206746250391,\n",
       "  -0.0021202617790549994,\n",
       "  -0.01015519443899393,\n",
       "  -0.014444384723901749,\n",
       "  -0.00781917478889227,\n",
       "  -0.008481047116219997,\n",
       "  0.01850646175444126,\n",
       "  0.012608014047145844,\n",
       "  -0.004824528470635414,\n",
       "  -0.004694749601185322,\n",
       "  -0.004091277718544006,\n",
       "  -0.028888769447803497,\n",
       "  -0.005583734717220068,\n",
       "  0.01828583888709545,\n",
       "  -0.0014624452451243997,\n",
       "  0.024073975160717964,\n",
       "  0.2023511677980423,\n",
       "  3.7615584005834535e-05,\n",
       "  -0.003015735885128379,\n",
       "  0.041814740747213364,\n",
       "  0.00700156856328249,\n",
       "  0.0032655601389706135,\n",
       "  0.015988752245903015,\n",
       "  0.02120586298406124,\n",
       "  -0.02097226120531559,\n",
       "  0.019752338528633118,\n",
       "  -0.019895095378160477,\n",
       "  0.013432109728455544,\n",
       "  -0.021283729001879692,\n",
       "  0.0012077543651685119,\n",
       "  0.014976478181779385,\n",
       "  -0.005771914031356573,\n",
       "  -0.03122478909790516,\n",
       "  -0.008117666468024254,\n",
       "  -0.03519602119922638,\n",
       "  -0.012828637845814228,\n",
       "  -0.012134321965277195,\n",
       "  -0.002681555226445198,\n",
       "  -0.017546098679304123,\n",
       "  -0.0020277942530810833,\n",
       "  0.036208298057317734,\n",
       "  0.01382144633680582,\n",
       "  0.003028713632375002,\n",
       "  0.006806900259107351,\n",
       "  0.018065214157104492,\n",
       "  0.006904234178364277,\n",
       "  -0.012166766449809074,\n",
       "  -0.034650951623916626,\n",
       "  0.013899313285946846,\n",
       "  0.012711836956441402,\n",
       "  -0.0010009192628785968,\n",
       "  -0.007961931638419628,\n",
       "  -0.007643973454833031,\n",
       "  0.0017406586557626724,\n",
       "  0.017247607931494713,\n",
       "  -0.003020602511242032,\n",
       "  -0.0019304602174088359,\n",
       "  0.01265992596745491,\n",
       "  0.015482615679502487,\n",
       "  -0.01519710198044777,\n",
       "  -0.01676742546260357,\n",
       "  0.007488239090889692,\n",
       "  ...],\n",
       " {'text': 'hi',\n",
       "  'date_upload': datetime.datetime(2024, 8, 12, 9, 23, 10, 562789, tzinfo=datetime.timezone.utc)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['hi']\n",
    "prepare_for_pinecone(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  49f68a5c8493ec2c0bf489821c21fc3b \n",
      "LEN:  1536 \n",
      "META: {'text': 'hi', 'date_upload': datetime.datetime(2024, 8, 12, 9, 23, 10, 822889, tzinfo=datetime.timezone.utc)}\n"
     ]
    }
   ],
   "source": [
    "_id, embedding, metadata = prepare_for_pinecone(texts)[0]\n",
    "print('ID: ', _id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_texts_to_pinecone(texts, namespace=NAMESPACE, batch_size=None, show_progress_bar=False):\n",
    "    # call the prepare_for_pinecone function to prepare input texts for indexing\n",
    "    total_upserted = 0\n",
    "    if not batch_size:\n",
    "        batch_size = len(texts)\n",
    "    \n",
    "    _range = range(0, len(texts), batch_size)\n",
    "    for i in tqdm(_range) if show_progress_bar else _range:\n",
    "        batch = texts[i : i + batch_size]\n",
    "        prepared_texts = prepare_for_pinecone(batch)\n",
    "        \n",
    "        # use the upsert() method of the index object to upload the prepared texts to Pinecone\n",
    "        total_upserted += index.upsert(\n",
    "            prepared_texts,\n",
    "            namespace=namespace\n",
    "        )['upserted_count']\n",
    "        \n",
    "    return total_upserted\n",
    "\n",
    "# call the upload_texts_to_pinecone() function with the input texts\n",
    "upload_texts_to_pinecone(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '49f68a5c8493ec2c0bf489821c21fc3b',\n",
       "  'metadata': {'date_upload': '2024-08-11T15:12:11.606184+00:00', 'text': 'hi'},\n",
       "  'score': 0.932166,\n",
       "  'values': []},\n",
       " {'id': '093601540a641d12a6f734a9fa624ce5',\n",
       "  'metadata': {'date_uploaded': '2024-07-20T00:07:10.001249+00:00',\n",
       "               'text': \"Alexander Graham Bell originally suggested 'ahoy-hoy' \"\n",
       "                       'be adopted as the standard greeting when answering a '\n",
       "                       \"telephone, before 'hello' (suggested by Thomas Edison) \"\n",
       "                       'became common.'},\n",
       "  'score': 0.780908227,\n",
       "  'values': []},\n",
       " {'id': '9588c26cecaaf486eae14858827a6699',\n",
       "  'metadata': {'date_uploaded': '2024-07-20T00:06:57.790296+00:00',\n",
       "               'text': 'The Abbott family -- wife Evelyn, husband Lee, '\n",
       "                       'congenitally deaf daughter Regan, and sons Marcus and '\n",
       "                       'Beau -- silently scavenge for supplies in a deserted '\n",
       "                       'town. While out in the open, the family communicates '\n",
       "                       'with American Sign Language (ASL). Four-year-old Beau '\n",
       "                       'is drawn to a battery-powered space shuttle toy, but '\n",
       "                       'Lee takes it away due to the noise it makes. Regan '\n",
       "                       'returns the toy to Beau, who also takes the batteries '\n",
       "                       'that his father removed from it. Beau activates the toy '\n",
       "                       'when the family is walking home and crossing a bridge, '\n",
       "                       'giving away his location to a nearby creature which '\n",
       "                       'kills him before Lee can save him.'},\n",
       "  'score': 0.773736954,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_from_pinecone(query, top_k=3):\n",
    "    # get embedding from THE SAME embedder as the documents\n",
    "    query_embedding = get_embeddings(query, engine=ENGINE)\n",
    "    \n",
    "    return index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        namespace=NAMESPACE,\n",
    "        include_metadata=True   # gets the metadata (dates, text, etc)\n",
    "    ).get('matches')\n",
    "    \n",
    "query_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def delete_texts_from_pinecone(texts, namespace=NAMESPACE):\n",
    "    # compute the hash (id) for each text\n",
    "    hashes = [hashlib.md5(text.encode()).hexdigest() for text in texts]\n",
    "    \n",
    "    # the ids parameter is used to specify the list of IDs (hashes) to delete.\n",
    "    return index.delete(ids=hashes, namespace=namespace)\n",
    "\n",
    "# delete our text\n",
    "delete_texts_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36661, 1070]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the tiktoken library\n",
    "import tiktoken\n",
    "\n",
    "# initialize a tokenizer for the 'cl100k_base' model\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# using the tokenizer to encode the text 'hey there' \n",
    "# the resulting output is a list of integers representing the encoded text\n",
    "# this is the input format required for embedding using the 'ada-002' model\n",
    "tokenizer.encode('hey there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the text into chunks of a maximum of tokens, inspired by OpenAI\n",
    "def overlapping_chunks(text, max_tokens=500, overlapping_factor=5):\n",
    "    '''\n",
    "    max_tokens : tokens we want per chunk\n",
    "    overlapping_factor : number of sentences to start each chink with that overlaps with the previous chunk\n",
    "    '''\n",
    "    \n",
    "    # split the text using punctuation\n",
    "    sentences = re.split(r'[.?!]', text)\n",
    "    \n",
    "    # get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks, tokens_so_far, chunk = [], 0, []\n",
    "    \n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "        \n",
    "        # if the number of tokens so far plus number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chinks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            if overlapping_factor > 0:\n",
    "                chunk = chunk[-overlapping_factor:]\n",
    "                tokens_so_far = sum([len(tokenizer.encode(c)) for c in chunk])\n",
    "            else:\n",
    "                chunk = []\n",
    "                tokens_so_far = 0\n",
    "        \n",
    "        \n",
    "        # if the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "        \n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "    \n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb98b5d41b74b60bf8ba9ceb66d2669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575490\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# open the PDF file in read-binary mode\n",
    "with open('./data/pds2.pdf', 'rb') as file:\n",
    "    \n",
    "    # create a PDF reader object\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    \n",
    "    # initialize an empty string to hold the text\n",
    "    principles_of_ds = ''\n",
    "    # Loop throught each page in the PDF file\n",
    "    for page in tqdm(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        principles_of_ds += '\\n\\n' + text[text.find(' ]')+2:]\n",
    "    \n",
    "# print the final string containing all the text from the PDF file\n",
    "principles_of_ds = principles_of_ds.strip()\n",
    "\n",
    "print(len(principles_of_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# a textbook about insects\n",
    "text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-overlapping chunking approach has 286 documents with average length 474.1 tokens\n"
     ]
    }
   ],
   "source": [
    "split = overlapping_chunks(principles_of_ds, overlapping_factor=0)\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'non-overlapping chunking approach has {len(split)} documents with average length {avg_length:.1f} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping chunking approach has 392 documents with average length\n"
     ]
    }
   ],
   "source": [
    "split = overlapping_chunks(principles_of_ds)\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'overlapping chunking approach has {len(split)} documents with average length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 82259), ('\\n', 9220), ('  ', 1592), ('\\n\\n', 333), ('\\n   ', 250), ('\\n\\n\\n', 82), ('\\n    ', 73), ('\\n ', 46), (' \\n', 39), ('     ', 34)]\n"
     ]
    }
   ],
   "source": [
    "# importing the Counter and re libraries\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# find all occurances of one or more spaces in 'principle_of_ds'\n",
    "matches = re.findall(r'[\\s]{1,}', principles_of_ds)\n",
    "\n",
    "# The 10 most frequent spaces that occur in the document\n",
    "most_common_spaces = Counter(matches).most_common(10)\n",
    "\n",
    "# print the most common spaces and their frequencies\n",
    "print(most_common_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom delimiter approach has 426 documents with average length 316.3 tokens\n"
     ]
    }
   ],
   "source": [
    "# only keep documents of at least 100 characters split by a custom delimiter\n",
    "split = list(filter(lambda x: len(x) > 50, principles_of_ds.split('\\n\\n')))\n",
    "\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'custom delimiter approach has {len(split)} documents with average length {avg_length:.1f} tokens') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82cd5144e3b4062aef40b55ab717bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = None\n",
    "for s in tqdm(range(0, len(split), 100)):\n",
    "    if embeddings is None:\n",
    "        embeddings = np.array(get_embeddings(split[s:s+100], engine=ENGINE))\n",
    "    else:\n",
    "        embeddings = np.vstack([embeddings, np.array(get_embeddings(split[s:s+100], engine=ENGINE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 2 embeddings\n",
      "Cluster 1: 3 embeddings\n",
      "Cluster 2: 2 embeddings\n",
      "Cluster 3: 2 embeddings\n",
      "Cluster 4: 2 embeddings\n",
      "Cluster 5: 2 embeddings\n",
      "Cluster 6: 4 embeddings\n",
      "Cluster 7: 2 embeddings\n",
      "Cluster 8: 2 embeddings\n",
      "Cluster 9: 2 embeddings\n",
      "Cluster 10: 2 embeddings\n",
      "Cluster 11: 2 embeddings\n",
      "Cluster 12: 2 embeddings\n",
      "Cluster 13: 2 embeddings\n",
      "Cluster 14: 2 embeddings\n",
      "Cluster 15: 2 embeddings\n",
      "Cluster 16: 2 embeddings\n",
      "Cluster 17: 2 embeddings\n",
      "Cluster 18: 2 embeddings\n",
      "Cluster 19: 2 embeddings\n",
      "Cluster 20: 2 embeddings\n",
      "Cluster 21: 2 embeddings\n",
      "Cluster 22: 2 embeddings\n",
      "Cluster 23: 2 embeddings\n",
      "Cluster 24: 2 embeddings\n",
      "Cluster 25: 2 embeddings\n",
      "Cluster 26: 2 embeddings\n",
      "Cluster 27: 2 embeddings\n",
      "Cluster 28: 3 embeddings\n",
      "Cluster 29: 2 embeddings\n",
      "Cluster 30: 2 embeddings\n",
      "Cluster 31: 2 embeddings\n",
      "Cluster 32: 2 embeddings\n",
      "Cluster 33: 2 embeddings\n",
      "Cluster 34: 1 embeddings\n",
      "Cluster 35: 2 embeddings\n",
      "Cluster 36: 2 embeddings\n",
      "Cluster 37: 2 embeddings\n",
      "Cluster 38: 2 embeddings\n",
      "Cluster 39: 2 embeddings\n",
      "Cluster 40: 2 embeddings\n",
      "Cluster 41: 2 embeddings\n",
      "Cluster 42: 2 embeddings\n",
      "Cluster 43: 2 embeddings\n",
      "Cluster 44: 1 embeddings\n",
      "Cluster 45: 2 embeddings\n",
      "Cluster 46: 1 embeddings\n",
      "Cluster 47: 1 embeddings\n",
      "Cluster 48: 2 embeddings\n",
      "Cluster 49: 2 embeddings\n",
      "Cluster 50: 2 embeddings\n",
      "Cluster 51: 2 embeddings\n",
      "Cluster 52: 2 embeddings\n",
      "Cluster 53: 3 embeddings\n",
      "Cluster 54: 2 embeddings\n",
      "Cluster 55: 2 embeddings\n",
      "Cluster 56: 2 embeddings\n",
      "Cluster 57: 2 embeddings\n",
      "Cluster 58: 1 embeddings\n",
      "Cluster 59: 3 embeddings\n",
      "Cluster 60: 2 embeddings\n",
      "Cluster 61: 2 embeddings\n",
      "Cluster 62: 1 embeddings\n",
      "Cluster 63: 1 embeddings\n",
      "Cluster 64: 2 embeddings\n",
      "Cluster 65: 1 embeddings\n",
      "Cluster 66: 2 embeddings\n",
      "Cluster 67: 1 embeddings\n",
      "Cluster 68: 3 embeddings\n",
      "Cluster 69: 1 embeddings\n",
      "Cluster 70: 1 embeddings\n",
      "Cluster 71: 2 embeddings\n",
      "Cluster 72: 1 embeddings\n",
      "Cluster 73: 2 embeddings\n",
      "Cluster 74: 1 embeddings\n",
      "Cluster 75: 1 embeddings\n",
      "Cluster 76: 1 embeddings\n",
      "Cluster 77: 1 embeddings\n",
      "Cluster 78: 1 embeddings\n",
      "Cluster 79: 2 embeddings\n",
      "Cluster 80: 1 embeddings\n",
      "Cluster 81: 1 embeddings\n",
      "Cluster 82: 2 embeddings\n",
      "Cluster 83: 2 embeddings\n",
      "Cluster 84: 2 embeddings\n",
      "Cluster 85: 1 embeddings\n",
      "Cluster 86: 1 embeddings\n",
      "Cluster 87: 1 embeddings\n",
      "Cluster 88: 1 embeddings\n",
      "Cluster 89: 1 embeddings\n",
      "Cluster 90: 1 embeddings\n",
      "Cluster 91: 3 embeddings\n",
      "Cluster 92: 2 embeddings\n",
      "Cluster 93: 1 embeddings\n",
      "Cluster 94: 1 embeddings\n",
      "Cluster 95: 1 embeddings\n",
      "Cluster 96: 1 embeddings\n",
      "Cluster 97: 1 embeddings\n",
      "Cluster 98: 1 embeddings\n",
      "Cluster 99: 1 embeddings\n",
      "Cluster 100: 2 embeddings\n",
      "Cluster 101: 2 embeddings\n",
      "Cluster 102: 1 embeddings\n",
      "Cluster 103: 2 embeddings\n",
      "Cluster 104: 2 embeddings\n",
      "Cluster 105: 1 embeddings\n",
      "Cluster 106: 1 embeddings\n",
      "Cluster 107: 2 embeddings\n",
      "Cluster 108: 2 embeddings\n",
      "Cluster 109: 1 embeddings\n",
      "Cluster 110: 1 embeddings\n",
      "Cluster 111: 1 embeddings\n",
      "Cluster 112: 1 embeddings\n",
      "Cluster 113: 1 embeddings\n",
      "Cluster 114: 1 embeddings\n",
      "Cluster 115: 1 embeddings\n",
      "Cluster 116: 1 embeddings\n",
      "Cluster 117: 1 embeddings\n",
      "Cluster 118: 1 embeddings\n",
      "Cluster 119: 2 embeddings\n",
      "Cluster 120: 1 embeddings\n",
      "Cluster 121: 2 embeddings\n",
      "Cluster 122: 1 embeddings\n",
      "Cluster 123: 1 embeddings\n",
      "Cluster 124: 1 embeddings\n",
      "Cluster 125: 1 embeddings\n",
      "Cluster 126: 1 embeddings\n",
      "Cluster 127: 1 embeddings\n",
      "Cluster 128: 1 embeddings\n",
      "Cluster 129: 1 embeddings\n",
      "Cluster 130: 1 embeddings\n",
      "Cluster 131: 1 embeddings\n",
      "Cluster 132: 1 embeddings\n",
      "Cluster 133: 1 embeddings\n",
      "Cluster 134: 1 embeddings\n",
      "Cluster 135: 1 embeddings\n",
      "Cluster 136: 1 embeddings\n",
      "Cluster 137: 1 embeddings\n",
      "Cluster 138: 2 embeddings\n",
      "Cluster 139: 1 embeddings\n",
      "Cluster 140: 1 embeddings\n",
      "Cluster 141: 1 embeddings\n",
      "Cluster 142: 1 embeddings\n",
      "Cluster 143: 1 embeddings\n",
      "Cluster 144: 1 embeddings\n",
      "Cluster 145: 1 embeddings\n",
      "Cluster 146: 1 embeddings\n",
      "Cluster 147: 1 embeddings\n",
      "Cluster 148: 1 embeddings\n",
      "Cluster 149: 1 embeddings\n",
      "Cluster 150: 1 embeddings\n",
      "Cluster 151: 1 embeddings\n",
      "Cluster 152: 1 embeddings\n",
      "Cluster 153: 1 embeddings\n",
      "Cluster 154: 1 embeddings\n",
      "Cluster 155: 1 embeddings\n",
      "Cluster 156: 1 embeddings\n",
      "Cluster 157: 1 embeddings\n",
      "Cluster 158: 1 embeddings\n",
      "Cluster 159: 1 embeddings\n",
      "Cluster 160: 1 embeddings\n",
      "Cluster 161: 1 embeddings\n",
      "Cluster 162: 1 embeddings\n",
      "Cluster 163: 1 embeddings\n",
      "Cluster 164: 1 embeddings\n",
      "Cluster 165: 1 embeddings\n",
      "Cluster 166: 1 embeddings\n",
      "Cluster 167: 1 embeddings\n",
      "Cluster 168: 1 embeddings\n",
      "Cluster 169: 1 embeddings\n",
      "Cluster 170: 2 embeddings\n",
      "Cluster 171: 1 embeddings\n",
      "Cluster 172: 1 embeddings\n",
      "Cluster 173: 1 embeddings\n",
      "Cluster 174: 1 embeddings\n",
      "Cluster 175: 1 embeddings\n",
      "Cluster 176: 1 embeddings\n",
      "Cluster 177: 1 embeddings\n",
      "Cluster 178: 1 embeddings\n",
      "Cluster 179: 1 embeddings\n",
      "Cluster 180: 1 embeddings\n",
      "Cluster 181: 1 embeddings\n",
      "Cluster 182: 1 embeddings\n",
      "Cluster 183: 1 embeddings\n",
      "Cluster 184: 1 embeddings\n",
      "Cluster 185: 1 embeddings\n",
      "Cluster 186: 1 embeddings\n",
      "Cluster 187: 1 embeddings\n",
      "Cluster 188: 1 embeddings\n",
      "Cluster 189: 1 embeddings\n",
      "Cluster 190: 1 embeddings\n",
      "Cluster 191: 1 embeddings\n",
      "Cluster 192: 1 embeddings\n",
      "Cluster 193: 1 embeddings\n",
      "Cluster 194: 1 embeddings\n",
      "Cluster 195: 1 embeddings\n",
      "Cluster 196: 1 embeddings\n",
      "Cluster 197: 1 embeddings\n",
      "Cluster 198: 1 embeddings\n",
      "Cluster 199: 1 embeddings\n",
      "Cluster 200: 1 embeddings\n",
      "Cluster 201: 1 embeddings\n",
      "Cluster 202: 1 embeddings\n",
      "Cluster 203: 1 embeddings\n",
      "Cluster 204: 1 embeddings\n",
      "Cluster 205: 1 embeddings\n",
      "Cluster 206: 1 embeddings\n",
      "Cluster 207: 1 embeddings\n",
      "Cluster 208: 1 embeddings\n",
      "Cluster 209: 1 embeddings\n",
      "Cluster 210: 1 embeddings\n",
      "Cluster 211: 1 embeddings\n",
      "Cluster 212: 1 embeddings\n",
      "Cluster 213: 1 embeddings\n",
      "Cluster 214: 1 embeddings\n",
      "Cluster 215: 1 embeddings\n",
      "Cluster 216: 1 embeddings\n",
      "Cluster 217: 1 embeddings\n",
      "Cluster 218: 1 embeddings\n",
      "Cluster 219: 1 embeddings\n",
      "Cluster 220: 1 embeddings\n",
      "Cluster 221: 1 embeddings\n",
      "Cluster 222: 1 embeddings\n",
      "Cluster 223: 1 embeddings\n",
      "Cluster 224: 1 embeddings\n",
      "Cluster 225: 1 embeddings\n",
      "Cluster 226: 1 embeddings\n",
      "Cluster 227: 1 embeddings\n",
      "Cluster 228: 1 embeddings\n",
      "Cluster 229: 1 embeddings\n",
      "Cluster 230: 1 embeddings\n",
      "Cluster 231: 1 embeddings\n",
      "Cluster 232: 1 embeddings\n",
      "Cluster 233: 1 embeddings\n",
      "Cluster 234: 1 embeddings\n",
      "Cluster 235: 1 embeddings\n",
      "Cluster 236: 1 embeddings\n",
      "Cluster 237: 1 embeddings\n",
      "Cluster 238: 1 embeddings\n",
      "Cluster 239: 1 embeddings\n",
      "Cluster 240: 1 embeddings\n",
      "Cluster 241: 1 embeddings\n",
      "Cluster 242: 1 embeddings\n",
      "Cluster 243: 1 embeddings\n",
      "Cluster 244: 1 embeddings\n",
      "Cluster 245: 1 embeddings\n",
      "Cluster 246: 1 embeddings\n",
      "Cluster 247: 1 embeddings\n",
      "Cluster 248: 1 embeddings\n",
      "Cluster 249: 1 embeddings\n",
      "Cluster 250: 1 embeddings\n",
      "Cluster 251: 1 embeddings\n",
      "Cluster 252: 1 embeddings\n",
      "Cluster 253: 1 embeddings\n",
      "Cluster 254: 1 embeddings\n",
      "Cluster 255: 1 embeddings\n",
      "Cluster 256: 1 embeddings\n",
      "Cluster 257: 1 embeddings\n",
      "Cluster 258: 1 embeddings\n",
      "Cluster 259: 1 embeddings\n",
      "Cluster 260: 1 embeddings\n",
      "Cluster 261: 1 embeddings\n",
      "Cluster 262: 1 embeddings\n",
      "Cluster 263: 1 embeddings\n",
      "Cluster 264: 1 embeddings\n",
      "Cluster 265: 1 embeddings\n",
      "Cluster 266: 1 embeddings\n",
      "Cluster 267: 1 embeddings\n",
      "Cluster 268: 1 embeddings\n",
      "Cluster 269: 1 embeddings\n",
      "Cluster 270: 1 embeddings\n",
      "Cluster 271: 1 embeddings\n",
      "Cluster 272: 1 embeddings\n",
      "Cluster 273: 1 embeddings\n",
      "Cluster 274: 1 embeddings\n",
      "Cluster 275: 1 embeddings\n",
      "Cluster 276: 1 embeddings\n",
      "Cluster 277: 1 embeddings\n",
      "Cluster 278: 1 embeddings\n",
      "Cluster 279: 1 embeddings\n",
      "Cluster 280: 1 embeddings\n",
      "Cluster 281: 1 embeddings\n",
      "Cluster 282: 1 embeddings\n",
      "Cluster 283: 1 embeddings\n",
      "Cluster 284: 1 embeddings\n",
      "Cluster 285: 1 embeddings\n",
      "Cluster 286: 1 embeddings\n",
      "Cluster 287: 1 embeddings\n",
      "Cluster 288: 1 embeddings\n",
      "Cluster 289: 1 embeddings\n",
      "Cluster 290: 1 embeddings\n",
      "Cluster 291: 1 embeddings\n",
      "Cluster 292: 1 embeddings\n",
      "Cluster 293: 1 embeddings\n",
      "Cluster 294: 1 embeddings\n",
      "Cluster 295: 1 embeddings\n",
      "Cluster 296: 1 embeddings\n",
      "Cluster 297: 1 embeddings\n",
      "Cluster 298: 1 embeddings\n",
      "Cluster 299: 1 embeddings\n",
      "Cluster 300: 1 embeddings\n",
      "Cluster 301: 1 embeddings\n",
      "Cluster 302: 1 embeddings\n",
      "Cluster 303: 1 embeddings\n",
      "Cluster 304: 1 embeddings\n",
      "Cluster 305: 1 embeddings\n",
      "Cluster 306: 1 embeddings\n",
      "Cluster 307: 1 embeddings\n",
      "Cluster 308: 1 embeddings\n",
      "Cluster 309: 1 embeddings\n",
      "Cluster 310: 1 embeddings\n",
      "Cluster 311: 1 embeddings\n",
      "Cluster 312: 1 embeddings\n",
      "Cluster 313: 1 embeddings\n",
      "Cluster 314: 1 embeddings\n",
      "Cluster 315: 1 embeddings\n",
      "Cluster 316: 1 embeddings\n",
      "Cluster 317: 1 embeddings\n",
      "Cluster 318: 1 embeddings\n",
      "Cluster 319: 1 embeddings\n",
      "Cluster 320: 1 embeddings\n",
      "Cluster 321: 1 embeddings\n",
      "Cluster 322: 1 embeddings\n",
      "Cluster 323: 1 embeddings\n",
      "Cluster 324: 1 embeddings\n",
      "Cluster 325: 1 embeddings\n",
      "Cluster 326: 1 embeddings\n",
      "Cluster 327: 1 embeddings\n",
      "Cluster 328: 1 embeddings\n",
      "Cluster 329: 1 embeddings\n",
      "Cluster 330: 1 embeddings\n",
      "Cluster 331: 1 embeddings\n",
      "Cluster 332: 1 embeddings\n",
      "Cluster 333: 1 embeddings\n",
      "Cluster 334: 1 embeddings\n",
      "Cluster 335: 1 embeddings\n",
      "Cluster 336: 1 embeddings\n",
      "Cluster 337: 1 embeddings\n",
      "Cluster 338: 1 embeddings\n",
      "Cluster 339: 1 embeddings\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# assume you have a list of text embeddings called 'embeddings' \n",
    "# first, compute the cosine similarity between all pairs of embeddings\n",
    "cosine_sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# instantiate the AgglomerativeClustering model\n",
    "agg_clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,            # the algorithm will determine the optimal number of clusters based on the data\n",
    "    distance_threshold=0.1,     # clusters will be formed untill all pairwise distances between clusters are greater than 0.1\n",
    "    # affinity='precomputed',   # we are providing a precimputed distance matrix (1 - similarity matrix) as input\n",
    "    metric='precomputed',       \n",
    "    linkage='complete'          # form clusters by iteratively merging the smallest clusters based on the maximum distance between their components\n",
    ")\n",
    "\n",
    "# fit the model to the cosine distnace matrix (1 - similarity matrix)\n",
    "agg_clustering.fit(1 - cosine_sim_matrix)\n",
    "\n",
    "# get the cluster labels for each embedding\n",
    "cluster_labels = agg_clustering.labels_\n",
    "\n",
    "# print the number of embeddings in each cluster\n",
    "unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f'Cluster {label}: {count} embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking and Retrieved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our pruning apporach has 340 documents with average length 396.3705882352941 tokens\n"
     ]
    }
   ],
   "source": [
    "pruned_documents = []\n",
    "for _label, count in zip(unique_labels, counts):\n",
    "    pruned_documents.append('\\n\\n'.join([text for text, label in zip(split, cluster_labels) if label == _label]))\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in pruned_documents]) / len(pruned_documents)\n",
    "print(f'Our pruning apporach has {len(pruned_documents)} documents with average length {avg_length} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How to Sound Like a Data\n",
      "Scientist\n",
      "No matter which industry you work in —IT, fashion, food, or finance —there is no doubt\n",
      "that data affects your life and work. At some point this week, you will either have or hear a\n",
      "conversation about data. News outlets are covering more and more stories about data leaks,\n",
      "cybercrimes, and how data can give us a glimpse into our lives. But why now? What makes\n",
      "this era such a hotbed of data-related industries?\n",
      "In the nineteenth century, the world was in the grip of the I ndustrial Age . Mankind was\n",
      "exploring its place in the industrial world, working with giant mechanical inventions.\n",
      "Captains of industry, such as Henry Ford, recognized that using these machines could open\n",
      "major market opportunities, enabling industries to achieve previously unimaginable\n",
      "profits. Of course, the Industrial Age had its pros and cons. While mass production placed\n",
      "goods in the hands of more consumers, our battle with pollution also began at around this\n",
      "time.\n",
      "By the twentie th century, we were quite skilled at making huge machines; the goal now\n",
      "was to make them smaller and faster. The Industrial Age was over and was replaced by\n",
      "what we now refer to as the I nformation Age . We started using machines to gather and\n",
      "store information (data) about ourselves and our environment for the purpose of\n",
      "understanding our universe.\n",
      "\n",
      "That's right —the Information Age, in its quest to procure data, has exploded the production\n",
      "of electronic data. Estimates show that we created about 1.8 trillion gigabytes of data in\n",
      "2011 (take a moment to just think about how much that is). Just one year later, in 2012, we\n",
      "created over 2.8 trillion gigabytes of data! This number is only going to explode further to\n",
      "hit an estimated 40 trillion gigabytes of created data in just one year by 2020. People\n",
      "contribute to this every time they tweet, post on Facebook, save a new resume on Microsoft\n",
      "Word, or just send their mom a picture by text message.\n",
      "Not only are we creating data at an unprecedented rate, but we are also consuming it at an\n",
      "accelerated pace as well. Just five years ago, in 2013, the average cell phone user used under\n",
      "1 GB of data a month. Today, that number is estimated to be well over 2 GB a month. We\n",
      "aren't just looking for the next personality quiz —what we are looking for is insight. With all\n",
      "of this data out there, some of it has to be useful to me! And it can be!\n",
      "So we, in the twenty-fir st century, are left with a problem. We have so much data and we\n",
      "keep making more. We have built insanely tiny machines that collect data 24/7, and it's our\n",
      "job to make sense of it all. Enter the D ata Age . This is the age when we take machines\n",
      "dreamed up by our nineteenth century ancestors and the data created by our twentieth\n",
      "century counterparts and create insights and sources of knowledge that every human on\n",
      "Earth can benefit from. The United States created an entirely new role in the government of\n",
      "chief data scientist. Many companies are now investing in data science departments and\n",
      "hiring data scientists. The benefit is quite obvious —using data to make accurate predictions\n",
      "and simulations gives us insight into our world like never before.\n",
      "Sounds great, but what's the catch?\n",
      "This chapter will explore the terminology and vocabulary of the modern data scientist. We\n",
      "will learn keywords and phrases that will be essential in our discussion of data science\n",
      "throughout this book. We will also learn why we use data science and learn about the three\n",
      "key domains that data science is derived from before we begin to look at the code in\n",
      "Python, the primary language used in this book. This chapter will cover the following\n",
      "topics:\n",
      "The basic terminology of data science\n",
      "The three domains of data science\n",
      "The basic Python syntax\n"
     ]
    }
   ],
   "source": [
    "print(pruned_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_texts_to_pinecone(pruned_documents, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28c9f36450ba7f7a78fcf29f2e4e9909\t0.84\tZ-scores are an effective way to standardize  data\n",
      "2a8a0bb77991e8040e16f9a02b82703b\t0.84\tLet's begin by learning a very  important value  i\n",
      "268922260e7eabb5ed6170d07ec4585a\t0.83\tThe preceding code gives us this graph:\n",
      "Now, our d\n",
      "7da124bb8c927e0c392cf75d4bfb2c76\t0.82\t\n",
      "Basic Statistics\n",
      "This chapter will focus on the s\n",
      "e1d5467e3658041aa16113edf0d3ebec\t0.81\t\n",
      "This is no coincidence! When we standardize the d\n"
     ]
    }
   ],
   "source": [
    "query = 'How do z scores work?'\n",
    "\n",
    "results_from_pinecone = query_from_pinecone(query=query, top_k=5)\n",
    "for result_from_pinecone in results_from_pinecone:\n",
    "    print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "This example computes the score between a query and all possible sentences in a corpus using a Cross-Encoder for semantic textual similarity (STS). It outputs then the most similar sentences for the given query.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# pre-trained cross encoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_pinecone(query, top_k=3, re_rank=False, verbose=True):\n",
    "    \n",
    "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
    "    if not results_from_pinecone:\n",
    "        return []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Query: \", query)\n",
    "        \n",
    "    final_results = []\n",
    "    \n",
    "    if re_rank:\n",
    "        if verbose:\n",
    "            print(\"Document ID (Hash)\\t\\tRetrieval Score\\tCE Score\\tText\")\n",
    "        \n",
    "        sentence_combinations = [[query, result_from_pinecone['metadata']['text']] for result_from_pinecone in results_from_pinecone]\n",
    "        \n",
    "        # compute the similarity scores for these combinations\n",
    "        similarity_scores = cross_encoder.predict(sentence_combinations, activation_fct=nn.Sigmoid())\n",
    "        \n",
    "        # sort the scores in decreasing order\n",
    "        sim_scores_argsort = reversed(np.argsort(similarity_scores))\n",
    "        \n",
    "        # print the scores\n",
    "        for idx in sim_scores_argsort:\n",
    "            result_from_pinecone = results_from_pinecone[idx]\n",
    "            final_results.append(result_from_pinecone)\n",
    "            if verbose:\n",
    "                print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{similarity_scores[idx]:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "        return final_results\n",
    "    \n",
    "    if verbose:\n",
    "        print('Document ID (Hash)\\t\\tRetrieval Score\\tText')\n",
    "    for result_from_pinecone in results_from_pinecone:\n",
    "        final_results.append(result_from_pinecone)\n",
    "        if verbose:\n",
    "            print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "            \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  How do z scores work?\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dc747cb43a42dc8e47def05ccfd961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a8a0bb77991e8040e16f9a02b82703b\t0.84\t0.99\tLet's begin by learning a very  important value  i\n",
      "28c9f36450ba7f7a78fcf29f2e4e9909\t0.84\t0.99\tZ-scores are an effective way to standardize  data\n",
      "268922260e7eabb5ed6170d07ec4585a\t0.83\t0.68\tThe preceding code gives us this graph:\n",
      "Now, our d\n"
     ]
    }
   ],
   "source": [
    "final_results = get_results_from_pinecone(query, top_k=3, re_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  How do z scores work?\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596dc16434294f2c95152233aa6fb107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a8a0bb77991e8040e16f9a02b82703b\t0.84\t0.99\tLet's begin by learning a very  important value  i\n",
      "28c9f36450ba7f7a78fcf29f2e4e9909\t0.84\t0.99\tZ-scores are an effective way to standardize  data\n",
      "e1d5467e3658041aa16113edf0d3ebec\t0.81\t0.97\t\n",
      "This is no coincidence! When we standardize the d\n",
      "7da124bb8c927e0c392cf75d4bfb2c76\t0.82\t0.93\t\n",
      "Basic Statistics\n",
      "This chapter will focus on the s\n",
      "268922260e7eabb5ed6170d07ec4585a\t0.83\t0.68\tThe preceding code gives us this graph:\n",
      "Now, our d\n",
      "75cf0bcd29070579356e3c50e9440d94\t0.80\t0.01\tThe following is the probability distribution of o\n",
      "e9ec4bdefba2f80157ffce04812a1cf4\t0.80\t0.00\t\n",
      "Let's look at each of the elements in this formul\n",
      "f90c995652f29ac9c2a4ca94f0e6809c\t0.81\t0.00\t\n",
      "We can think of this problem like as follows:\n",
      "The\n",
      "5bf0b775d7e41ee065e79ef1d2ac9f2c\t0.80\t0.00\tThe empirical rule\n",
      "Recall that a normal distributi\n",
      "0fdfad6a76d2dafdcc309cf732e744fe\t0.79\t0.00\tFirst, take a minute and convince yourself that yo\n"
     ]
    }
   ],
   "source": [
    "final_results = get_results_from_pinecone(query, top_k=10, re_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_texts_from_pinecone(pruned_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "dataset = load_dataset(\"boolq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'does ethanol take more energy make that produces',\n",
       " 'answer': False,\n",
       " 'passage': \"All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is a garbanzo bean and a chickpea the same thing\n",
      "Query:  is a garbanzo bean and a chickpea the same thing\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd32754b0654b729787ccc24f9ef8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3180d42f8e2598e9247dac0a5cac23f\t0.86\t1.00\tThe chickpea or chick pea (Cicer arietinum) is a l\n",
      "cf784f1c35b6e06c62e49be2fa08320f\t0.85\t1.00\tThe chickpea or chick pea (Cicer arietinum) is a l\n",
      "d2e2c2b3d5c70978fb6b9afc0a33c9ac\t0.78\t0.00\tCultivated cowpeas are known by the common names b\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "query = sample(dataset['validation']['question'], 1)[0]\n",
    "print(query)\n",
    "final_results = get_results_from_pinecone(query, top_k=3, re_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cf784f1c35b6e06c62e49be2fa08320f'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_to_hash = {data['question']: my_hash(data['passage']) for data in dataset['validation']}\n",
    "q_to_hash[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the performance re-ranking against 1000 of our validation datapoints\n",
    "# Note we could not use Pinecone here to speed things up\n",
    "# but it's also a good time to test latency of the pipeline with Pinecone\n",
    "val_sample = dataset['validation']#[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4078f7cf29c47f39fad4de07f1f3d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without re-ranking: 0.8486238532110092\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Note we will keep top_k the same so latency from Pinecone is consistent\n",
    "# and the only major time difference will be in the re-ranking\n",
    "\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash = get_results_from_pinecone(question, top_k=1, re_rank=False, verbose=False)[0]['id']\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    \n",
    "accuracy = sum(predictions)/len(predictions)\n",
    "print(f'Accuracy without re-ranking: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8769bbd79584468bb0d0b6ad26a0a885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with re-ranking: 0.8422018348623853\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Note we will keep top_k the same as latency from Pinecone is consistent\n",
    "# and the only major time difference will be in the re-ranking\n",
    "\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash = get_results_from_pinecone(question, top_k=3, re_rank=True, verbose=False)[0]['id']\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    \n",
    "accuracy = sum(predictions) / len(predictions)\n",
    "print(f'Accuracy with re-ranking: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the time differences between with and without re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ranking(query, cross_encoder, top_k=3):\n",
    "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
    "    sentence_combinations = [[query, result_from_pinecone['metadata']['text']] for result_from_pinecone in results_from_pinecone]\n",
    "    similarity_scores = cross_encoder.predict(sentence_combinations)\n",
    "    sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
    "    re_ranked_final_result = results_from_pinecone[sim_scores_argsort[0]]\n",
    "    return results_from_pinecone[0]['id'], re_ranked_final_result['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# trying another pre-trained cross encoder\n",
    "# sentence-transformers/mullti-qu-mpnet-base-cos-v1\n",
    "newer_cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d923bd63df4de59d79c358277d6754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50\n",
      "Accuracy without re-ranking: 0.88\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 100\n",
      "Accuracy without re-ranking: 0.85\n",
      "Accuracy with re-ranking: 0.85\n",
      "Step 150\n",
      "Accuracy without re-ranking: 0.86\n",
      "Accuracy with re-ranking: 0.8466666666666667\n",
      "Step 200\n",
      "Accuracy without re-ranking: 0.865\n",
      "Accuracy with re-ranking: 0.845\n",
      "Step 250\n",
      "Accuracy without re-ranking: 0.872\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 300\n",
      "Accuracy without re-ranking: 0.85\n",
      "Accuracy with re-ranking: 0.8433333333333334\n",
      "Step 350\n",
      "Accuracy without re-ranking: 0.8628571428571429\n",
      "Accuracy with re-ranking: 0.8485714285714285\n",
      "Step 400\n",
      "Accuracy without re-ranking: 0.865\n",
      "Accuracy with re-ranking: 0.8475\n",
      "Step 450\n",
      "Accuracy without re-ranking: 0.86\n",
      "Accuracy with re-ranking: 0.8422222222222222\n",
      "Step 500\n",
      "Accuracy without re-ranking: 0.852\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 550\n",
      "Accuracy without re-ranking: 0.84\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 600\n",
      "Accuracy without re-ranking: 0.8366666666666667\n",
      "Accuracy with re-ranking: 0.8333333333333334\n",
      "Step 650\n",
      "Accuracy without re-ranking: 0.8353846153846154\n",
      "Accuracy with re-ranking: 0.8292307692307692\n",
      "Step 700\n",
      "Accuracy without re-ranking: 0.8371428571428572\n",
      "Accuracy with re-ranking: 0.83\n",
      "Step 750\n",
      "Accuracy without re-ranking: 0.8306666666666667\n",
      "Accuracy with re-ranking: 0.828\n",
      "Step 800\n",
      "Accuracy without re-ranking: 0.83375\n",
      "Accuracy with re-ranking: 0.83\n",
      "Step 850\n",
      "Accuracy without re-ranking: 0.8341176470588235\n",
      "Accuracy with re-ranking: 0.8294117647058824\n",
      "Step 900\n",
      "Accuracy without re-ranking: 0.8333333333333334\n",
      "Accuracy with re-ranking: 0.8277777777777777\n",
      "Step 950\n",
      "Accuracy without re-ranking: 0.8336842105263158\n",
      "Accuracy with re-ranking: 0.8263157894736842\n",
      "Step 1000\n",
      "Accuracy without re-ranking: 0.834\n",
      "Accuracy with re-ranking: 0.827\n",
      "Step 1050\n",
      "Accuracy without re-ranking: 0.8342857142857143\n",
      "Accuracy with re-ranking: 0.8266666666666667\n",
      "Step 1100\n",
      "Accuracy without re-ranking: 0.8363636363636363\n",
      "Accuracy with re-ranking: 0.8281818181818181\n",
      "Step 1150\n",
      "Accuracy without re-ranking: 0.8382608695652174\n",
      "Accuracy with re-ranking: 0.831304347826087\n",
      "Step 1200\n",
      "Accuracy without re-ranking: 0.8408333333333333\n",
      "Accuracy with re-ranking: 0.8333333333333334\n",
      "Step 1250\n",
      "Accuracy without re-ranking: 0.844\n",
      "Accuracy with re-ranking: 0.836\n",
      "Step 1300\n",
      "Accuracy without re-ranking: 0.8446153846153847\n",
      "Accuracy with re-ranking: 0.8369230769230769\n",
      "Step 1350\n",
      "Accuracy without re-ranking: 0.8481481481481481\n",
      "Accuracy with re-ranking: 0.8407407407407408\n",
      "Step 1400\n",
      "Accuracy without re-ranking: 0.8464285714285714\n",
      "Accuracy with re-ranking: 0.8392857142857143\n",
      "Step 1450\n",
      "Accuracy without re-ranking: 0.8448275862068966\n",
      "Accuracy with re-ranking: 0.8351724137931035\n",
      "Step 1500\n",
      "Accuracy without re-ranking: 0.8426666666666667\n",
      "Accuracy with re-ranking: 0.832\n",
      "Step 1550\n",
      "Accuracy without re-ranking: 0.8432258064516129\n",
      "Accuracy with re-ranking: 0.8329032258064516\n",
      "Step 1600\n",
      "Accuracy without re-ranking: 0.8425\n",
      "Accuracy with re-ranking: 0.8325\n",
      "Step 1650\n",
      "Accuracy without re-ranking: 0.8418181818181818\n",
      "Accuracy with re-ranking: 0.8327272727272728\n",
      "Step 1700\n",
      "Accuracy without re-ranking: 0.8441176470588235\n",
      "Accuracy with re-ranking: 0.8341176470588235\n",
      "Step 1750\n",
      "Accuracy without re-ranking: 0.844\n",
      "Accuracy with re-ranking: 0.8337142857142857\n",
      "Step 1800\n",
      "Accuracy without re-ranking: 0.8444444444444444\n",
      "Accuracy with re-ranking: 0.8361111111111111\n",
      "Step 1850\n",
      "Accuracy without re-ranking: 0.8437837837837838\n",
      "Accuracy with re-ranking: 0.8362162162162162\n",
      "Step 1900\n",
      "Accuracy without re-ranking: 0.8457894736842105\n",
      "Accuracy with re-ranking: 0.838421052631579\n",
      "Step 1950\n",
      "Accuracy without re-ranking: 0.8456410256410256\n",
      "Accuracy with re-ranking: 0.838974358974359\n",
      "Step 2000\n",
      "Accuracy without re-ranking: 0.8475\n",
      "Accuracy with re-ranking: 0.8395\n",
      "Step 2050\n",
      "Accuracy without re-ranking: 0.8492682926829268\n",
      "Accuracy with re-ranking: 0.8419512195121951\n",
      "Step 2100\n",
      "Accuracy without re-ranking: 0.8485714285714285\n",
      "Accuracy with re-ranking: 0.840952380952381\n",
      "Step 2150\n",
      "Accuracy without re-ranking: 0.8474418604651163\n",
      "Accuracy with re-ranking: 0.8418604651162791\n",
      "Step 2200\n",
      "Accuracy without re-ranking: 0.8477272727272728\n",
      "Accuracy with re-ranking: 0.8409090909090909\n",
      "Step 2250\n",
      "Accuracy without re-ranking: 0.8475555555555555\n",
      "Accuracy with re-ranking: 0.8404444444444444\n",
      "Step 2300\n",
      "Accuracy without re-ranking: 0.8473913043478261\n",
      "Accuracy with re-ranking: 0.8386956521739131\n",
      "Step 2350\n",
      "Accuracy without re-ranking: 0.8476595744680852\n",
      "Accuracy with re-ranking: 0.8395744680851064\n",
      "Step 2400\n",
      "Accuracy without re-ranking: 0.8479166666666667\n",
      "Accuracy with re-ranking: 0.8395833333333333\n",
      "Step 2450\n",
      "Accuracy without re-ranking: 0.8493877551020408\n",
      "Accuracy with re-ranking: 0.8420408163265306\n",
      "Step 2500\n",
      "Accuracy without re-ranking: 0.8492\n",
      "Accuracy with re-ranking: 0.842\n",
      "Step 2550\n",
      "Accuracy without re-ranking: 0.847843137254902\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 2600\n",
      "Accuracy without re-ranking: 0.8465384615384616\n",
      "Accuracy with re-ranking: 0.8396153846153847\n",
      "Step 2650\n",
      "Accuracy without re-ranking: 0.8471698113207548\n",
      "Accuracy with re-ranking: 0.8392452830188679\n",
      "Step 2700\n",
      "Accuracy without re-ranking: 0.8474074074074074\n",
      "Accuracy with re-ranking: 0.8396296296296296\n",
      "Step 2750\n",
      "Accuracy without re-ranking: 0.8472727272727273\n",
      "Accuracy with re-ranking: 0.8389090909090909\n",
      "Step 2800\n",
      "Accuracy without re-ranking: 0.8467857142857143\n",
      "Accuracy with re-ranking: 0.8389285714285715\n",
      "Step 2850\n",
      "Accuracy without re-ranking: 0.847719298245614\n",
      "Accuracy with re-ranking: 0.84\n",
      "Step 2900\n",
      "Accuracy without re-ranking: 0.8482758620689655\n",
      "Accuracy with re-ranking: 0.8396551724137931\n",
      "Step 2950\n",
      "Accuracy without re-ranking: 0.847457627118644\n",
      "Accuracy with re-ranking: 0.8396610169491525\n",
      "Step 3000\n",
      "Accuracy without re-ranking: 0.848\n",
      "Accuracy with re-ranking: 0.8413333333333334\n",
      "Step 3050\n",
      "Accuracy without re-ranking: 0.8485245901639344\n",
      "Accuracy with re-ranking: 0.8422950819672131\n",
      "Step 3100\n",
      "Accuracy without re-ranking: 0.8493548387096774\n",
      "Accuracy with re-ranking: 0.8425806451612903\n",
      "Step 3150\n",
      "Accuracy without re-ranking: 0.8498412698412698\n",
      "Accuracy with re-ranking: 0.8431746031746031\n",
      "Step 3200\n",
      "Accuracy without re-ranking: 0.849375\n",
      "Accuracy with re-ranking: 0.8425\n",
      "Step 3250\n",
      "Accuracy without re-ranking: 0.8498461538461538\n",
      "Accuracy with re-ranking: 0.8418461538461538\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print_every = 50\n",
    "predictions = []\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash, reranked_hash = eval_ranking(question, newer_cross_encoder, top_k=3)\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append((retrieved_hash == correct_hash, reranked_hash == correct_hash))\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "        print(f'Step {i}')\n",
    "        raw_accuracy = sum([p[0] for p in predictions]) / len(predictions)\n",
    "        reranked_accuracy = sum([p[1] for p in predictions]) / len(predictions)\n",
    "        \n",
    "        print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "        print(f'Accuracy with re-ranking: {reranked_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-encoder: cross-encoder/ms-marco-MiniLM-L-12-v2\n",
      "Accuracy without re-ranking: 0.8495412844036697\n",
      "Accuracy with re-ranking: 0.8422018348623853\n"
     ]
    }
   ],
   "source": [
    "raw_accuracy = sum([p[0] for p in predictions]) / len(predictions)\n",
    "reranked_accuracy = sum([p[1] for p in predictions]) / len(predictions)\n",
    "\n",
    "print(f'Using cross-encoder: {newer_cross_encoder.config._name_or_path}')\n",
    "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "print(f'Accuracy with re-ranking: {reranked_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/ms_marco/train_cross-encoder_scratch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'do good samaritan laws protect those who help at an accident',\n",
       " 'answer': True,\n",
       " 'passage': \"Good Samaritan laws offer legal protection to people who give reasonable assistance to those who are, or who they believe to be, injured, ill, in peril, or otherwise incapacitated. The protection is intended to reduce bystanders' hesitation to assist, for fear of being sued or prosecuted for unintentional injury or wrongful death. An example of such a law in common-law areas of Canada: a good Samaritan doctrine is a legal principle that prevents a rescuer who has voluntarily helped a victim in distress from being successfully sued for wrongdoing. Its purpose is to keep people from being reluctant to help a stranger in need for fear of legal repercussions should they make some mistake in treatment. By contrast, a duty to rescue law requires people to offer assistance and holds those who fail to do so liable.\"}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from random import shuffle\n",
    "\n",
    "shuffled_training_passages = dataset['train']['passage'].copy()\n",
    "shuffle(shuffled_training_passages)\n",
    "\n",
    "train_samples = [\n",
    "    InputExample(texts=[d['question'], d['passage']], label=1) for d in dataset['train']\n",
    "]\n",
    "\n",
    "# add some negative samples\n",
    "train_samples += [\n",
    "    InputExample(texts=[d['question'] ,shuffled_training_passages[i]], label=0) for i, d in enumerate(dataset['train'])\n",
    "]\n",
    "\n",
    "shuffle(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18854"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model = CrossEncoder('cross-encoder/ms-macro-MiniLM-L-12-v2', num_labels=1)\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': '',\n",
       " 'texts': ['was there a group called the five heartbeats',\n",
       "  \"On May 17, 2010, the Hawaii Five-O remake was picked up by CBS, which scheduled it for Monday nights in the 10--11 p.m. time slot. The news was good for the state of Hawaii, which hoped that the remake would pump new life into the economy. Production of the remainder of the first season started in June 2010. On June 24, 2010, the producers announced that it would use the warehouse at the former Honolulu Advertiser building as the official soundstage studio for the series starting in July 2010. Exteriors representing Five-0 headquarters in the series are located at the Ali'iolani Hale in Honolulu, directly across the street from Iolani Palace, which represented Five-O headquarters in the original series.\"],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5349435e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_samples[0].texts, activation_fct=nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup-steps: 95\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator, CEBinaryClassificationEvaluator\n",
    "import math\n",
    "import torch\n",
    "from random import sample\n",
    "\n",
    "logger.setLevel(logging.DEBUG)          # just to get some logs\n",
    "num_epochs = 2\n",
    "model_save_path = './fine_tuned_ir_cross_encoder'\n",
    "\n",
    "# train_samples = sample(train_samples, 1000)\n",
    "# int(len(train_samples)*.8)\n",
    "train_dataloader = DataLoader(train_samples[:int(len(train_samples)*.8)], shuffle=True, batch_size=32)\n",
    "\n",
    "# An evaluator for training performance\n",
    "evaluator = CEBinaryClassificationEvaluator.from_input_examples(train_samples[-int(len(train_samples)*.8):], name='test')\n",
    "\n",
    "# rule of thumb for warmup step\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "print(f\"Warmup-steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\llm\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c82e0f3953643acb2c8a843fac61731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556b87fe11d0494cb4b94c0c781e2de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # #### Load model and eval on test set\n",
    "# print(evaluator(model))\n",
    "from sentence_transformers.SentenceTransformer import SentenceTransformer\n",
    "from torch import nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    # loss_fct=losses.nn.CrossEntropyLoss(),\n",
    "    # loss_fct=losses.SoftmaxLoss(model=SentenceTransformer, sentence_embedding_dimension=2, num_labels=2, loss_fct=nn.CrossEntropyLoss()),\n",
    "    loss_fct=criterion,\n",
    "    activation_fct=nn.Sigmoid(),\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    "    use_amp=True\n",
    ")\n",
    "\n",
    "# #### Load model and eval on test set\n",
    "# print(evaluator(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the more fine tuned version on open source as well to match??\n",
    "# depend if it does better here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = CrossEncoder(model_save_path)\n",
    "\n",
    "print(finetuned.predict(['hello', 'hi'], activation_fct=nn.Sigmoid()))\n",
    "print(finetuned.predict(['hellp', 'hi'], activation_fct=nn.Identity()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
